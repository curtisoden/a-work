{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38eee1e8",
   "metadata": {},
   "source": [
    "# Team A-Work - Energy Utility Churn Predection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac956fe",
   "metadata": {},
   "source": [
    "## 1 Data Exploration, Cleaning, and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d73c713",
   "metadata": {},
   "source": [
    "#### 1.0.1 About the Data\n",
    "\n",
    "\n",
    "Powerco has shared two Comma separated Value(.CSV file) files, Historical customer\n",
    "data which is inclusive of customer data such as usage, sign up date, forecasted\n",
    "usage as well churn indicator to check whether each customer has churned or not and\n",
    "also Historical pricing data like variable and fixed pricing data etc. Features we may \n",
    "find particularly interesting (but may actually prove to be irreleveant) are bolded.\n",
    "\n",
    "client_data.csv:\n",
    "\n",
    "* __id = client company identifier__ *\n",
    "* activity_new = category of the companyâ€™s activity *\n",
    "* __channel_sales = code of the sales channel__ *\n",
    "* cons_12m = electricity consumption of the past 12 months *\n",
    "* cons_gas_12m = gas consumption of the past 12 months *\n",
    "* cons_last_month = electricity consumption of the last month *\n",
    "* date_activ = date of activation of the contract *\n",
    "* date_end = registered date of the end of the contract *\n",
    "* date_modif_prod = date of the last modification of the product *\n",
    "* date_renewal = date of the next contract renewal *\n",
    "* forecast_cons_12m = forecasted electricity consumption for next 12 months *\n",
    "* forecast_cons_year = forecasted electricity consumption for the next calendar year *\n",
    "* __forecast_discount_energy = forecasted value of current discount__ *\n",
    "* forecast_meter_rent_12m = forecasted bill of meter rental for the next 2 months *\n",
    "* __forecast_price_energy_off_peak = forecasted energy price for 1st period (off peak)__ *\n",
    "* __forecast_price_energy_peak = forecasted energy price for 2nd period (peak)__ *\n",
    "* __forecast_price_pow_off_peak = forecasted power price for 1st period (off peak)__ *\n",
    "* has_gas = indicated if client is also a gas client *\n",
    "* imp_cons = current paid consumption *\n",
    "* margin_gross_pow_ele = gross margin on power subscription *\n",
    "* margin_net_pow_ele = net margin on power subscription *\n",
    "* nb_prod_act = number of active products and services *\n",
    "* __net_margin = total net margin__ *\n",
    "* num_years_antig = antiquity of the client (in number of years) *\n",
    "* __origin_up = code of the electricity campaign the customer first subscribed to__ *\n",
    "* pow_max = subscribed power *\n",
    "* __churn = has the client churned over the next 3 months__ *\n",
    "\n",
    "price_data.csv:\n",
    "\n",
    "* __id = client company identifier__ *\n",
    "* price_date = reference date\n",
    "* __price_off_peak_var = price of energy for the 1st period (off peak)__ *\n",
    "* __price_peak_var = price of energy for the 2nd period (peak)__ *\n",
    "* __price_mid_peak_var = price of energy for the 3rd period (mid peak)__ *\n",
    "* __price_off_peak_fix = price of power for the 1st period (off peak)__ *\n",
    "* __price_peak_fix = price of power for the 2nd period (peak)__ *\n",
    "* __price_mid_peak_fix = price of power for the 3rd period (mid peak)__ *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92061e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning and Merging Workflow with Visualizations\n",
    "# This notebook merges SOURCE_client_data.csv and SOURCE_price_data.csv \n",
    "# to create a machine learning-ready dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Data Files\n",
    "source_client_data = 'SOURCE_client_data.csv'\n",
    "source_price_data = 'SOURCE_price_data.csv'\n",
    "output_file = 'DATA_v4_churn.csv'\n",
    "sample_file = 'SAMPLE_v4_churn.csv'\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"Data Cleaning and Merging Workflow with Visualizations\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load the source datasets\n",
    "print(\"\\n1. Loading Source Datasets\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Load client data\n",
    "client_df = pd.read_csv(source_client_data)\n",
    "print(f\"Client data shape: {client_df.shape}\")\n",
    "print(f\"Client data columns: {list(client_df.columns)}\")\n",
    "\n",
    "# Load price data  \n",
    "price_df = pd.read_csv(source_price_data)\n",
    "print(f\"Price data shape: {price_df.shape}\")\n",
    "print(f\"Price data columns: {list(price_df.columns)}\")\n",
    "\n",
    "# Display first few rows to understand the data structure\n",
    "print(\"\\nClient data sample:\")\n",
    "print(client_df.head(2))\n",
    "print(\"\\nPrice data sample:\")\n",
    "print(price_df.head(2))\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nClient data types:\")\n",
    "print(client_df.dtypes)\n",
    "print(\"\\nPrice data types:\")\n",
    "print(price_df.dtypes)\n",
    "\n",
    "# ðŸ“Š VISUALIZATION 1: Dataset Overview\n",
    "print(\"\\nðŸ“Š VISUALIZATION 1: Dataset Overview\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Plot 1.1: Dataset Sizes\n",
    "plt.figure(figsize=(10, 6))\n",
    "datasets = ['Client Data', 'Price Data']\n",
    "sizes = [len(client_df), len(price_df)]\n",
    "colors = ['#FF6B6B', '#4ECDC4']\n",
    "\n",
    "bars = plt.bar(datasets, sizes, color=colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
    "plt.title('Dataset Sizes', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Number of Records', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(sizes):\n",
    "    plt.text(i, v + max(sizes)*0.01, f'{v:,}', ha='center', fontweight='bold', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 1.2: Column Counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "col_counts = [len(client_df.columns), len(price_df.columns)]\n",
    "bars = plt.bar(datasets, col_counts, color=colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
    "plt.title('Number of Columns', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Column Count', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(col_counts):\n",
    "    plt.text(i, v + max(col_counts)*0.02, str(v), ha='center', fontweight='bold', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 1.3: Client Data Types Distribution\n",
    "plt.figure(figsize=(8, 8))\n",
    "client_dtypes = client_df.dtypes.value_counts()\n",
    "wedges, texts, autotexts = plt.pie(client_dtypes.values, labels=client_dtypes.index, \n",
    "                                  autopct='%1.1f%%', startangle=90, colors=plt.cm.Set3.colors)\n",
    "plt.title('Client Data: Data Types Distribution', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 1.4: Price Data Types Distribution\n",
    "plt.figure(figsize=(8, 8))\n",
    "price_dtypes = price_df.dtypes.value_counts()\n",
    "wedges, texts, autotexts = plt.pie(price_dtypes.values, labels=price_dtypes.index, \n",
    "                                  autopct='%1.1f%%', startangle=90, colors=plt.cm.Set3.colors)\n",
    "plt.title('Price Data: Data Types Distribution', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n2. Data Exploration and Understanding\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"Client data info:\")\n",
    "print(client_df.info())\n",
    "print(\"\\nPrice data info:\")\n",
    "print(price_df.info())\n",
    "\n",
    "# Check unique values in key columns\n",
    "print(f\"\\nUnique client IDs: {client_df['id'].nunique()}\")\n",
    "print(f\"Total client records: {len(client_df)}\")\n",
    "print(f\"Unique price IDs: {price_df['id'].nunique()}\")\n",
    "print(f\"Total price records: {len(price_df)}\")\n",
    "\n",
    "# Check for churn column in client data\n",
    "print(f\"\\nChecking for target variable:\")\n",
    "if 'churn' in client_df.columns:\n",
    "    print(\"âœ“ Found 'churn' column in client data\")\n",
    "    print(f\"Churn distribution: {client_df['churn'].value_counts()}\")\n",
    "    print(f\"Churn rate: {client_df['churn'].mean():.3f}\")\n",
    "else:\n",
    "    print(\"âœ— No 'churn' column found in client data\")\n",
    "\n",
    "# ðŸ“Š VISUALIZATION 2: Data Quality & Missing Values\n",
    "print(\"\\nðŸ“Š VISUALIZATION 2: Data Quality & Missing Values\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Plot 2.1: Missing Values in Client Data\n",
    "plt.figure(figsize=(12, 6))\n",
    "client_missing = client_df.isnull().sum()\n",
    "if client_missing.sum() > 0:\n",
    "    top_missing = client_missing[client_missing > 0].head(10)\n",
    "    bars = plt.barh(range(len(top_missing)), top_missing.values, color='#E74C3C', alpha=0.7)\n",
    "    plt.yticks(range(len(top_missing)), top_missing.index)\n",
    "    plt.title('Client Data: Missing Values', fontweight='bold', fontsize=16)\n",
    "    plt.xlabel('Count of Missing Values')\n",
    "    for i, v in enumerate(top_missing.values):\n",
    "        plt.text(v + max(top_missing.values)*0.01, i, str(v), va='center', fontweight='bold')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'No Missing Values!', ha='center', va='center', \n",
    "             transform=plt.gca().transAxes, fontsize=16, fontweight='bold', color='green')\n",
    "    plt.title('Client Data: Missing Values Status', fontweight='bold', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2.2: Missing Values in Price Data\n",
    "plt.figure(figsize=(12, 6))\n",
    "price_missing = price_df.isnull().sum()\n",
    "if price_missing.sum() > 0:\n",
    "    top_missing_price = price_missing[price_missing > 0].head(10)\n",
    "    bars = plt.barh(range(len(top_missing_price)), top_missing_price.values, color='#F39C12', alpha=0.7)\n",
    "    plt.yticks(range(len(top_missing_price)), top_missing_price.index)\n",
    "    plt.title('Price Data: Missing Values', fontweight='bold', fontsize=16)\n",
    "    plt.xlabel('Count of Missing Values')\n",
    "    for i, v in enumerate(top_missing_price.values):\n",
    "        plt.text(v + max(top_missing_price.values)*0.01, i, str(v), va='center', fontweight='bold')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'No Missing Values!', ha='center', va='center', \n",
    "             transform=plt.gca().transAxes, fontsize=16, fontweight='bold', color='green')\n",
    "    plt.title('Price Data: Missing Values Status', fontweight='bold', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2.3: ID Overlap Analysis\n",
    "plt.figure(figsize=(8, 8))\n",
    "client_ids = set(client_df['id'].unique())\n",
    "price_ids = set(price_df['id'].unique())\n",
    "overlap = len(client_ids.intersection(price_ids))\n",
    "client_only = len(client_ids - price_ids)\n",
    "price_only = len(price_ids - client_ids)\n",
    "\n",
    "labels = ['Overlap', 'Client Only', 'Price Only']\n",
    "sizes = [overlap, client_only, price_only]\n",
    "colors = ['#2ECC71', '#3498DB', '#9B59B6']\n",
    "\n",
    "wedges, texts, autotexts = plt.pie(sizes, labels=labels, autopct='%1.1f%%', \n",
    "                                   colors=colors, startangle=90)\n",
    "plt.title('ID Overlap Analysis', fontweight='bold', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2.4: Data Completeness Summary\n",
    "plt.figure(figsize=(12, 6))\n",
    "completeness_data = {\n",
    "    'Client Records': len(client_df),\n",
    "    'Price Records': len(price_df),\n",
    "    'Unique Client IDs': client_df['id'].nunique(),\n",
    "    'Unique Price IDs': price_df['id'].nunique(),\n",
    "    'ID Overlap': overlap\n",
    "}\n",
    "\n",
    "bars = plt.bar(range(len(completeness_data)), list(completeness_data.values()), \n",
    "               color=['#E74C3C', '#F39C12', '#3498DB', '#9B59B6', '#2ECC71'], alpha=0.8)\n",
    "plt.xticks(range(len(completeness_data)), list(completeness_data.keys()), rotation=45, ha='right')\n",
    "plt.title('Data Completeness Summary', fontweight='bold', fontsize=16)\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, v in enumerate(completeness_data.values()):\n",
    "    plt.text(i, v + max(completeness_data.values())*0.01, f'{v:,}', \n",
    "             ha='center', fontweight='bold', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ðŸ“Š VISUALIZATION 3: Churn Analysis (if churn exists)\n",
    "if 'churn' in client_df.columns:\n",
    "    print(\"\\nðŸ“Š VISUALIZATION 3: Churn Distribution Analysis\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    churn_counts = client_df['churn'].value_counts()\n",
    "    colors_churn = ['#2ECC71', '#E74C3C']\n",
    "    \n",
    "    # Plot 3.1: Churn Distribution Pie Chart\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    wedges, texts, autotexts = plt.pie(churn_counts.values, labels=['No Churn', 'Churn'], \n",
    "                                      autopct='%1.1f%%', colors=colors_churn, startangle=90,\n",
    "                                      explode=(0, 0.1))\n",
    "    plt.title('Churn Distribution', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 3.2: Churn Distribution Bar Chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(['No Churn', 'Churn'], churn_counts.values, color=colors_churn, alpha=0.8)\n",
    "    plt.title('Churn Counts', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Number of Customers')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    for i, v in enumerate(churn_counts.values):\n",
    "        plt.text(i, v + max(churn_counts.values)*0.01, f'{v:,}', \n",
    "                 ha='center', fontweight='bold', fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 3.3: Churn vs No-Churn Rates\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    churn_rate = client_df['churn'].mean()\n",
    "    no_churn_rate = 1 - churn_rate\n",
    "    \n",
    "    bars = plt.bar(['No Churn Rate', 'Churn Rate'], [no_churn_rate, churn_rate], \n",
    "                   color=colors_churn, alpha=0.8, width=0.6)\n",
    "    plt.title('Churn vs No-Churn Rates', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Rate')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for i, v in enumerate([no_churn_rate, churn_rate]):\n",
    "        plt.text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold', fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Churn statistics table (keeping this as it's informative)\n",
    "    churn_stats = pd.DataFrame({\n",
    "        'Metric': ['Total Customers', 'Churned Customers', 'Retained Customers', 'Churn Rate', 'Retention Rate'],\n",
    "        'Value': [\n",
    "            f\"{len(client_df):,}\",\n",
    "            f\"{churn_counts.get(1, 0):,}\",\n",
    "            f\"{churn_counts.get(0, 0):,}\",\n",
    "            f\"{churn_rate:.3f}\",\n",
    "            f\"{1-churn_rate:.3f}\"\n",
    "        ]\n",
    "    })\n",
    "    print(\"\\nChurn Statistics Summary:\")\n",
    "    print(churn_stats.to_string(index=False))\n",
    "\n",
    "print(\"\\n3. Date Column Processing\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "date_columns_client = [col for col in client_df.columns if 'date' in col.lower()]\n",
    "date_columns_price = [col for col in price_df.columns if 'date' in col.lower()]\n",
    "\n",
    "print(f\"Date columns in client data: {date_columns_client}\")\n",
    "print(f\"Date columns in price data: {date_columns_price}\")\n",
    "\n",
    "def convert_to_epoch(date_series, date_format='%Y-%m-%d'):\n",
    "    \"\"\"\n",
    "    Convert date strings to normalized epoch time (0-1 scale)\n",
    "    \"\"\"\n",
    "    # Convert to datetime\n",
    "    dates = pd.to_datetime(date_series, format=date_format, errors='coerce')\n",
    "    \n",
    "    # Convert to epoch (seconds since 1970-01-01)\n",
    "    epoch_times = dates.astype('int64') // 10**9\n",
    "    \n",
    "    # Normalize to 0-1 scale\n",
    "    min_epoch = epoch_times.min()\n",
    "    max_epoch = epoch_times.max()\n",
    "    \n",
    "    if max_epoch == min_epoch:\n",
    "        return epoch_times * 0  # All same date\n",
    "    \n",
    "    normalized = (epoch_times - min_epoch) / (max_epoch - min_epoch)\n",
    "    \n",
    "    print(f\"Date range: {dates.min()} to {dates.max()}\")\n",
    "    print(f\"Epoch range: {min_epoch} to {max_epoch}\")\n",
    "    print(f\"Normalized range: {normalized.min():.3f} to {normalized.max():.3f}\")\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "# Convert date columns in client data\n",
    "for col in date_columns_client:\n",
    "    if col in client_df.columns:\n",
    "        print(f\"\\nConverting {col}:\")\n",
    "        client_df[col] = convert_to_epoch(client_df[col])\n",
    "\n",
    "# Convert date columns in price data\n",
    "for col in date_columns_price:\n",
    "    if col in price_df.columns:\n",
    "        print(f\"\\nConverting {col}:\")\n",
    "        price_df[f'{col}_epoch'] = convert_to_epoch(price_df[col])\n",
    "\n",
    "print(\"\\n4. Merging Client and Price Data\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "print(\"Performing left join to keep all clients...\")\n",
    "merged_df = client_df.merge(price_df, on='id', how='left')\n",
    "print(f\"Merged dataset shape: {merged_df.shape}\")\n",
    "\n",
    "# Check for missing price data\n",
    "if len(date_columns_price) > 0:\n",
    "    missing_price = merged_df[date_columns_price[0]].isna().sum()\n",
    "    print(f\"Clients without price data: {missing_price}\")\n",
    "\n",
    "# ðŸ“Š VISUALIZATION 4: Data Merging Results\n",
    "print(\"\\nðŸ“Š VISUALIZATION 4: Data Merging Results\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Plot 4.1: Record Counts Before vs After Merge\n",
    "plt.figure(figsize=(12, 6))\n",
    "datasets = ['Client Data', 'Price Data', 'Merged Data']\n",
    "record_counts = [len(client_df), len(price_df), len(merged_df)]\n",
    "colors = ['#3498DB', '#9B59B6', '#E67E22']\n",
    "\n",
    "bars = plt.bar(datasets, record_counts, color=colors, alpha=0.8, edgecolor='black')\n",
    "plt.title('Record Counts: Before C After Merge', fontweight='bold', fontsize=16)\n",
    "plt.ylabel('Number of Records')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(record_counts):\n",
    "    plt.text(i, v + max(record_counts)*0.01, f'{v:,}', ha='center', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 4.2: Data Completeness After Merge\n",
    "if len(date_columns_price) > 0:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    complete_records = len(merged_df) - merged_df[date_columns_price[0]].isna().sum()\n",
    "    incomplete_records = merged_df[date_columns_price[0]].isna().sum()\n",
    "    \n",
    "    completeness_data = [complete_records, incomplete_records]\n",
    "    labels = ['Complete Records', 'Missing Price Data']\n",
    "    colors_comp = ['#2ECC71', '#E74C3C']\n",
    "    \n",
    "    wedges, texts, autotexts = plt.pie(completeness_data, labels=labels, autopct='%1.1f%%', \n",
    "                                      colors=colors_comp, startangle=90)\n",
    "    plt.title('Data Completeness After Merge', fontweight='bold', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot 4.3: Column Count Growth\n",
    "plt.figure(figsize=(10, 6))\n",
    "col_growth = [len(client_df.columns), len(merged_df.columns)]\n",
    "datasets_cols = ['Before Merge', 'After Merge']\n",
    "bars = plt.bar(datasets_cols, col_growth, color=['#3498DB', '#E67E22'], alpha=0.8)\n",
    "plt.title('Column Count Growth', fontweight='bold', fontsize=16)\n",
    "plt.ylabel('Number of Columns')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(col_growth):\n",
    "    plt.text(i, v + max(col_growth)*0.01, str(v), ha='center', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Merge summary table\n",
    "merge_stats = pd.DataFrame({\n",
    "    'Dataset': ['Client Data', 'Price Data', 'Merged Data'],\n",
    "    'Records': [f\"{len(client_df):,}\", f\"{len(price_df):,}\", f\"{len(merged_df):,}\"],\n",
    "    'Columns': [len(client_df.columns), len(price_df.columns), len(merged_df.columns)]\n",
    "})\n",
    "print(\"\\nMerge Summary:\")\n",
    "print(merge_stats.to_string(index=False))\n",
    "\n",
    "print(\"\\n5. Creating Price Statistical Features\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "price_columns = [col for col in price_df.columns if col.startswith('price_') and col != 'price_date']\n",
    "print(f\"Found price columns: {price_columns}\")\n",
    "\n",
    "if price_columns:\n",
    "    # Group price data by client ID to create statistical features\n",
    "    print(\"Calculating price statistics per client...\")\n",
    "    \n",
    "    # Create aggregation dictionary for existing price columns\n",
    "    agg_dict = {}\n",
    "    for col in price_columns:\n",
    "        agg_dict[col] = ['mean', 'std', 'min', 'max', 'last']\n",
    "    \n",
    "    price_stats = price_df.groupby('id').agg(agg_dict).round(6)\n",
    "    \n",
    "    # Flatten column names\n",
    "    price_stats.columns = ['_'.join(col).strip() for col in price_stats.columns]\n",
    "    price_stats = price_stats.reset_index()\n",
    "    \n",
    "    print(f\"Price statistics shape: {price_stats.shape}\")\n",
    "    print(\"Sample price statistics:\")\n",
    "    print(price_stats.head(2))\n",
    "    \n",
    "    # Merge price statistics with client data\n",
    "    final_df = client_df.merge(price_stats, on='id', how='left')\n",
    "    print(f\"Dataset with price features shape: {final_df.shape}\")\n",
    "else:\n",
    "    print(\"No price columns found - using client data only\")\n",
    "    final_df = client_df.copy()\n",
    "\n",
    "# ðŸ“Š VISUALIZATION 5: Price Analysis (if price columns exist)\n",
    "if price_columns:\n",
    "    print(\"\\nðŸ“Š VISUALIZATION 5: Price Statistics Analysis\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, col in enumerate(price_columns[:3]):  # Show max 3 price columns\n",
    "        price_data = price_df[col].dropna()\n",
    "        \n",
    "        # Plot 5.x: Price Distribution Histogram\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        n, bins, patches = plt.hist(price_data, bins=30, color=f'C{i}', alpha=0.7, \n",
    "                                   edgecolor='black', linewidth=0.5)\n",
    "        plt.title(f'{col.replace(\"_\", \" \").title()} Distribution', fontweight='bold', fontsize=16)\n",
    "        plt.xlabel('Price')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add statistics text\n",
    "        stats_text = f'Mean: {price_data.mean():.2f}\\nStd: {price_data.std():.2f}\\nMedian: {price_data.median():.2f}'\n",
    "        plt.text(0.7, 0.7, stats_text, transform=plt.gca().transAxes, \n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8),\n",
    "                fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot 5.x: Price Box Plot\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        bp = plt.boxplot(price_data, patch_artist=True, \n",
    "                        boxprops=dict(facecolor=f'C{i}', alpha=0.7),\n",
    "                        medianprops=dict(color='red', linewidth=2))\n",
    "        plt.title(f'{col.replace(\"_\", \" \").title()} Box Plot', fontweight='bold', fontsize=16)\n",
    "        plt.ylabel('Price')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\n6. One-Hot Encoding Categorical Variables (Including origin_up)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Store original shape for comparison\n",
    "original_shape = final_df.shape\n",
    "columns_before_encoding = final_df.columns.tolist()\n",
    "\n",
    "# Find all categorical columns\n",
    "categorical_cols = final_df.select_dtypes(include=['object']).columns.tolist()\n",
    "# Remove 'id' if it exists as we don't want to encode it\n",
    "if 'id' in categorical_cols:\n",
    "    categorical_cols.remove('id')\n",
    "\n",
    "print(f\"Found categorical columns: {categorical_cols}\")\n",
    "\n",
    "# Track one-hot encoding progress\n",
    "encoding_summary = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nðŸ“‹ Processing column: {col}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Show value counts\n",
    "    value_counts = final_df[col].value_counts()\n",
    "    print(f\"Unique {col} values ({len(value_counts)} categories):\")\n",
    "    print(value_counts)\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_count = final_df[col].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        print(f\"âš ï¸ Warning: {missing_count} missing values found in {col}\")\n",
    "        # Fill missing values with 'Unknown' before encoding\n",
    "        final_df[col] = final_df[col].fillna('Unknown')\n",
    "        print(f\"âœ“ Filled missing values with 'Unknown'\")\n",
    "    \n",
    "    # Create one-hot encoded variables\n",
    "    dummies = pd.get_dummies(final_df[col], prefix=col, drop_first=False)\n",
    "    print(f\"âœ“ Created {len(dummies.columns)} dummy variables:\")\n",
    "    print(f\"  {list(dummies.columns)}\")\n",
    "    \n",
    "    # Add to summary\n",
    "    encoding_summary.append({\n",
    "        'Column': col,\n",
    "        'Unique_Values': len(value_counts),\n",
    "        'Missing_Values': missing_count,\n",
    "        'Dummy_Variables_Created': len(dummies.columns),\n",
    "        'Dummy_Columns': list(dummies.columns)\n",
    "    })\n",
    "    \n",
    "    # Add dummy variables to dataset\n",
    "    final_df = pd.concat([final_df, dummies], axis=1)\n",
    "    \n",
    "    # Drop the original categorical column\n",
    "    final_df = final_df.drop(columns=[col])\n",
    "    print(f\"âœ“ Dropped original column: {col}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š ONE-HOT ENCODING SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Original shape: {original_shape}\")\n",
    "print(f\"Final shape: {final_df.shape}\")\n",
    "print(f\"Columns added: {final_df.shape[1] - original_shape[1]}\")\n",
    "print(f\"Rows unchanged: {final_df.shape[0] == original_shape[0]}\")\n",
    "\n",
    "# Create encoding summary table\n",
    "encoding_df = pd.DataFrame(encoding_summary)\n",
    "if not encoding_df.empty:\n",
    "    print(f\"\\nDetailed Encoding Summary:\")\n",
    "    for _, row in encoding_df.iterrows():\n",
    "        print(f\"\\n{row['Column']}:\")\n",
    "        print(f\"  - Original categories: {row['Unique_Values']}\")\n",
    "        print(f\"  - Missing values handled: {row['Missing_Values']}\")\n",
    "        print(f\"  - Dummy variables created: {row['Dummy_Variables_Created']}\")\n",
    "\n",
    "# ðŸ“Š VISUALIZATION 6A: One-Hot Encoding Analysis\n",
    "print(\"\\nðŸ“Š VISUALIZATION 6A: One-Hot Encoding Analysis\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if categorical_cols:\n",
    "    # Plot 6A.1: Categories per Column\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    col_names = [item['Column'] for item in encoding_summary]\n",
    "    category_counts = [item['Unique_Values'] for item in encoding_summary]\n",
    "    \n",
    "    bars = plt.bar(col_names, category_counts, color=plt.cm.Set3.colors[:len(col_names)], alpha=0.8)\n",
    "    plt.title('Number of Unique Categories per Column', fontweight='bold', fontsize=16)\n",
    "    plt.ylabel('Number of Categories')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for i, v in enumerate(category_counts):\n",
    "        plt.text(i, v + max(category_counts)*0.01, str(v), ha='center', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 6A.2: Dummy Variables Created per Column\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    dummy_counts = [item['Dummy_Variables_Created'] for item in encoding_summary]\n",
    "    \n",
    "    bars = plt.bar(col_names, dummy_counts, color=plt.cm.Pastel1.colors[:len(col_names)], alpha=0.8)\n",
    "    plt.title('Dummy Variables Created per Column', fontweight='bold', fontsize=16)\n",
    "    plt.ylabel('Number of Dummy Variables')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for i, v in enumerate(dummy_counts):\n",
    "        plt.text(i, v + max(dummy_counts)*0.01, str(v), ha='center', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 6A.3: Feature Expansion Impact\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    expansion_data = ['Before Encoding', 'After Encoding']\n",
    "    feature_counts = [original_shape[1], final_df.shape[1]]\n",
    "    \n",
    "    bars = plt.bar(expansion_data, feature_counts, color=['#3498DB', '#E74C3C'], alpha=0.8)\n",
    "    plt.title('Feature Count: Before vs After One-Hot Encoding', fontweight='bold', fontsize=16)\n",
    "    plt.ylabel('Number of Features')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for i, v in enumerate(feature_counts):\n",
    "        plt.text(i, v + max(feature_counts)*0.01, f'{v:,}', ha='center', fontweight='bold')\n",
    "    \n",
    "    # Add difference annotation\n",
    "    difference = feature_counts[1] - feature_counts[0]\n",
    "    plt.annotate(f'+{difference} features', \n",
    "                xy=(0.5, max(feature_counts)*0.8), \n",
    "                ha='center', fontsize=14, fontweight='bold',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Special focus on origin_up if it exists\n",
    "    if 'origin_up' in [item['Column'] for item in encoding_summary]:\n",
    "        print(\"\\nðŸŽ¯ SPECIAL FOCUS: origin_up Column Analysis\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        origin_info = next(item for item in encoding_summary if item['Column'] == 'origin_up')\n",
    "        print(f\"âœ“ origin_up successfully one-hot encoded!\")\n",
    "        print(f\"  - Original categories: {origin_info['Unique_Values']}\")\n",
    "        print(f\"  - Dummy variables created: {origin_info['Dummy_Variables_Created']}\")\n",
    "        print(f\"  - New columns: {origin_info['Dummy_Columns']}\")\n",
    "        \n",
    "        # Plot origin_up specific visualization\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        origin_cols = [col for col in final_df.columns if col.startswith('origin_up_')]\n",
    "        if origin_cols:\n",
    "            origin_sums = [final_df[col].sum() for col in origin_cols]\n",
    "            \n",
    "            plt.pie(origin_sums, labels=[col.replace('origin_up_', '') for col in origin_cols], \n",
    "                   autopct='%1.1f%%', startangle=90)\n",
    "            plt.title('Distribution of origin_up Categories', fontweight='bold', fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No categorical columns found to encode.\")\n",
    "\n",
    "print(f\"\\nDataset shape after one-hot encoding: {final_df.shape}\")\n",
    "\n",
    "# Save the final dataset\n",
    "\n",
    "final_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Dataset saved as: {output_file}\")\n",
    "print(f\"Final shape: {final_df.shape}\")\n",
    "\n",
    "print(\"\\n15. Create Sample Dataset\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Create a sample with 150 records\n",
    "sample_df = final_df.sample(n=min(150, len(final_df)), random_state=42)\n",
    "sample_df.to_csv(sample_file, index=False)\n",
    "\n",
    "print(f\"Sample dataset saved as: {sample_file}\")\n",
    "print(f\"Sample shape: {sample_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd09867",
   "metadata": {},
   "source": [
    "## 2 Churn Prediction Modeling Workflow\n",
    "\n",
    "This notebook walks through an endâ€‘toâ€‘end workflow for building and comparing machineâ€‘learning models that predict customer churn. We start with simple baselines and progressively add sophisticationÂ â€“ including feature engineering, class balancing, and ensemble methods. Each step is explained in plain language so that readers with basic Python and dataâ€‘science knowledge can follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e5b1ca",
   "metadata": {},
   "source": [
    "### 2.1â€ƒSetup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185d4fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"8\"  # Set to the number of CPU cores you want to use for parallel processing \n",
    "\n",
    "# Scikitâ€‘learn core\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                             roc_auc_score, precision_recall_curve, roc_curve,\n",
    "                             average_precision_score, accuracy_score, f1_score)\n",
    "\n",
    "# Basic models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Ensemble models\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, BaggingClassifier\n",
    "\n",
    "# Imbalance handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Advanced gradient boosting (requires xgboost)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    has_xgb = True\n",
    "except ImportError:\n",
    "    has_xgb = False\n",
    "    print(\"xgboost not installed â€“ skipping XGBClassifier. !pip install xgboost to enable.\")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b982c5",
   "metadata": {},
   "source": [
    "### 2.2â€ƒLoad the Data\n",
    "\n",
    "Replace `DATA_PATH` with the actual dataset path when you are ready to run on the full data. For demonstration, we fall back to the uploaded sample if the full dataset is not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0678dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "SAMPLE_PATH = Path(sample_file)\n",
    "FULL_PATH = Path(output_file)\n",
    "\n",
    "DATA_PATH = FULL_PATH if FULL_PATH.exists() else SAMPLE_PATH\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Loaded {df.shape[0]:,} rows and {df.shape[1]} columns from {DATA_PATH.name}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01557855",
   "metadata": {},
   "source": [
    "### 2.3â€ƒQuick Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df.info()\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(df.describe(include='all').transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f0e6b",
   "metadata": {},
   "source": [
    "### 2.4â€ƒTarget Variable Distribution\n",
    "\n",
    "Class imbalance can seriously affect model performance. We will visualise the proportion of churned versus nonâ€‘churned customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2637c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_col = 'churn'  # adjust if your target has a different name\n",
    "class_counts = df[target_col].value_counts().sort_index()\n",
    "ax = class_counts.plot(kind='bar', rot=0)\n",
    "ax.set_xlabel('Churn')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Class Distribution')\n",
    "plt.show()\n",
    "\n",
    "imbalance_ratio = class_counts.min() / class_counts.max()\n",
    "print(f\"Minority / majority ratio: {imbalance_ratio:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c0dcec",
   "metadata": {},
   "source": [
    "### 2.3 Churn Variable Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d556ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS: channel_sales and origin_up One-Hot Encoded Features\n",
    "print(\"=\"*80)\n",
    "print(\"ANALYSIS: CHANNEL_SALES & ORIGIN_UP ONE-HOT ENCODED FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Identify channel_sales and origin_up columns\n",
    "channel_sales_cols = [col for col in df.columns if 'channel_sales' in col]\n",
    "origin_up_cols = [col for col in df.columns if 'origin_up' in col]\n",
    "print(f\"Found {len(channel_sales_cols)} channel_sales one-hot columns: {channel_sales_cols}\")\n",
    "print(f\"Found {len(origin_up_cols)} origin_up one-hot columns: {origin_up_cols}\")\n",
    "\n",
    "# 2. Analyze channel_sales features\n",
    "if channel_sales_cols:\n",
    "    print(\"\\nCHANNEL_SALES DISTRIBUTION & CHURN RATE\")\n",
    "    channel_info = []\n",
    "    for col in channel_sales_cols:\n",
    "        channel_name = col.replace('channel_sales_', '').replace('_', ' ').title()\n",
    "        customer_count = df[col].sum()\n",
    "        churn_count = df[df['churn'] == 1][col].sum()\n",
    "        churn_rate = (churn_count / customer_count) * 100 if customer_count > 0 else 0\n",
    "        channel_info.append({\n",
    "            'Channel': channel_name,\n",
    "            'Customers': customer_count,\n",
    "            'Churned': churn_count,\n",
    "            'Churn Rate (%)': churn_rate\n",
    "        })\n",
    "    channel_summary_df = pd.DataFrame(channel_info).sort_values(by='Customers', ascending=False)\n",
    "    print(\"\\nðŸ“Š Channel Sales Summary:\")\n",
    "    display(channel_summary_df.style.format({\n",
    "        'Customers': '{:,.0f}',\n",
    "        'Churned': '{:,.0f}',\n",
    "        'Churn Rate (%)': '{:.2f}%'\n",
    "    }).bar(subset=['Churn Rate (%)'], color='#d65f5f', vmin=0))\n",
    "    # Visualization\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    channel_summary_df_sorted = channel_summary_df.sort_values('Churn Rate (%)', ascending=False)\n",
    "    sns.barplot(x='Churn Rate (%)', y='Channel', data=channel_summary_df_sorted, ax=ax, palette='Blues_r')\n",
    "    ax.set_title('Churn Rate by Channel Sales', fontsize=14)\n",
    "    ax.set_xlabel('Churn Rate (%)')\n",
    "    ax.set_ylabel('Channel')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 3. Analyze origin_up features\n",
    "if origin_up_cols:\n",
    "    print(\"\\nORIGIN_UP DISTRIBUTION & CHURN RATE\")\n",
    "    origin_info = []\n",
    "    for col in origin_up_cols:\n",
    "        origin_name = col.replace('origin_up_', '').replace('_', ' ').title()\n",
    "        customer_count = df[col].sum()\n",
    "        churn_count = df[df['churn'] == 1][col].sum()\n",
    "        churn_rate = (churn_count / customer_count) * 100 if customer_count > 0 else 0\n",
    "        origin_info.append({\n",
    "            'Origin': origin_name,\n",
    "            'Customers': customer_count,\n",
    "            'Churned': churn_count,\n",
    "            'Churn Rate (%)': churn_rate\n",
    "        })\n",
    "    origin_summary_df = pd.DataFrame(origin_info).sort_values(by='Customers', ascending=False)\n",
    "    print(\"\\nðŸ“Š Origin Up Summary:\")\n",
    "    display(origin_summary_df.style.format({\n",
    "        'Customers': '{:,.0f}',\n",
    "        'Churned': '{:,.0f}',\n",
    "        'Churn Rate (%)': '{:.2f}%'\n",
    "    }).bar(subset=['Churn Rate (%)'], color='#d65f5f', vmin=0))\n",
    "    # Visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    origin_summary_df_sorted = origin_summary_df.sort_values('Churn Rate (%)', ascending=False)\n",
    "    sns.barplot(x='Churn Rate (%)', y='Origin', data=origin_summary_df_sorted, ax=ax, palette='Greens_r')\n",
    "    ax.set_title('Churn Rate by Origin Up', fontsize=14)\n",
    "    ax.set_xlabel('Churn Rate (%)')\n",
    "    ax.set_ylabel('Origin')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHANNEL_SALES & ORIGIN_UP ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36b4608",
   "metadata": {},
   "source": [
    "## 3 Training and Testing Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4717d796",
   "metadata": {},
   "source": [
    "### 3.1 Training and Testing Split\n",
    "We us an 80/20 split between the Training and Testing data, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "numeric_pipeline = Pipeline([('scaler', StandardScaler())])\n",
    "#categorical_pipeline = Pipeline([('onehot', OneHotEncoder(handle_unknown='ignore', sparse=True))])\n",
    "categorical_pipeline = Pipeline([('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)\n",
    "print(f\"Train size: {X_train.shape[0]:,}; Test size: {X_test.shape[0]:,}\")\n",
    "\n",
    "# Output the schema of the features\n",
    "print(\"\\nFeature schema after split:\")\n",
    "pd.set_option('display.max_rows', None)  # Show all rows without truncation\n",
    "pd.set_option('display.max_columns', None)  # Show all columns without truncation\n",
    "#display(pd.DataFrame({\n",
    "#    \"Column\": X.columns,\n",
    "#    \"Type\": [X[col].dtype for col in X.columns]\n",
    "#}))\n",
    "display(X.describe(include='all').transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9e38cc",
   "metadata": {},
   "source": [
    "### 3.2â€ƒFeature Engineering & Correlation Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa23f41f",
   "metadata": {},
   "source": [
    "#### 3.2.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.1 Feature Engineering (using available features)\n",
    "\n",
    "# Engineered Feature: Customer tenure in months (if 'start_date' exists)\n",
    "if 'start_date' in X_train.columns:\n",
    "    X_train['tenure_months'] = (pd.to_datetime('today') - pd.to_datetime(X_train['start_date'])).dt.days // 30\n",
    "    X_test['tenure_months'] = (pd.to_datetime('today') - pd.to_datetime(X_test['start_date'])).dt.days // 30\n",
    "\n",
    "# Engineered Feature: Interaction between price and consumption\n",
    "if 'price' in X_train.columns and 'cons_last_month' in X_train.columns:\n",
    "    X_train['price_x_cons'] = X_train['price'] * X_train['cons_last_month']\n",
    "    X_test['price_x_cons'] = X_test['price'] * X_test['cons_last_month']\n",
    "\n",
    "# Engineered Feature: Binned margin (to be one-hot-encoded downstream)\n",
    "if 'margin_net_pow_ele' in X_train.columns:\n",
    "    bins = [-float('inf'), 0, 50, 100, float('inf')]\n",
    "    labels = ['loss', 'low', 'med', 'high']\n",
    "    X_train['margin_bin'] = pd.cut(X_train['margin_net_pow_ele'], bins=bins, labels=labels)\n",
    "    X_test['margin_bin'] = pd.cut(X_test['margin_net_pow_ele'], bins=bins, labels=labels)\n",
    "\n",
    "# Engineered Feature: Numeric and percentage difference for off-peak price\n",
    "if 'price_off_peak_var_min' in X_train.columns and 'price_off_peak_var_last' in X_train.columns:\n",
    "    X_train['off_peak_price_diff'] = X_train['price_off_peak_var_last'] - X_train['price_off_peak_var_min']\n",
    "    X_test['off_peak_price_diff'] = X_test['price_off_peak_var_last'] - X_test['price_off_peak_var_min']\n",
    "    # Avoid division by zero\n",
    "    X_train['off_peak_price_pct_diff'] = X_train['off_peak_price_diff'] / X_train['price_off_peak_var_min'].replace(0, np.nan)\n",
    "    X_test['off_peak_price_pct_diff'] = X_test['off_peak_price_diff'] / X_test['price_off_peak_var_min'].replace(0, np.nan)\n",
    "\n",
    "# Engineered Feature: Numeric and percentage difference for peak price\n",
    "if 'price_peak_var_min' in X_train.columns and 'price_peak_var_last' in X_train.columns:\n",
    "    X_train['peak_price_diff'] = X_train['price_peak_var_last'] - X_train['price_peak_var_min']\n",
    "    X_test['peak_price_diff'] = X_test['price_peak_var_last'] - X_test['price_peak_var_min']\n",
    "    # Avoid division by zero\n",
    "    X_train['peak_price_pct_diff'] = X_train['peak_price_diff'] / X_train['price_peak_var_min'].replace(0, np.nan)\n",
    "    X_test['peak_price_pct_diff'] = X_test['peak_price_diff'] / X_test['price_peak_var_min'].replace(0, np.nan)\n",
    "\n",
    "# Track engineered features for later analysis\n",
    "engineered_features = []\n",
    "for feat in [\n",
    "    'tenure_months', 'price_x_cons', 'margin_bin',\n",
    "    'off_peak_price_diff', 'off_peak_price_pct_diff',\n",
    "    'peak_price_diff', 'peak_price_pct_diff'\n",
    "]:\n",
    "    if feat in X_train.columns:\n",
    "        engineered_features.append(feat)\n",
    "\n",
    "print(\"Engineered features added:\", engineered_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff84f006",
   "metadata": {},
   "source": [
    "#### 3.2.2 Protected Columns\n",
    "We want to make sure these columns do not get pruned from out models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b549254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5.1 Protected Columns\n",
    "protected_columns = [\n",
    "    'cons_last_month', 'imp_cons', 'margin_net_pow_ele', 'num_years_antig', \n",
    "    'price_off_peak_var_min', 'price_off_peak_var_max', 'price_off_peak_var_last',  \n",
    "    'price_peak_var_min', 'price_peak_var_max', 'price_peak_var_last', 'churned','forecast_discount_energy','net_margin']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98bb7dd",
   "metadata": {},
   "source": [
    "#### 3.2.3 Feature Correlation Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d6c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.3 Enhanced Correlation Analysis with Protected Columns\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ENHANCED CORRELATION ANALYSIS WITH FEATURE PROTECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the correlation threshold (easily configurable)\n",
    "correlation_threshold = 0.95\n",
    "\n",
    "print(f\"\\nðŸ“Š INITIAL DATASET OVERVIEW:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Separate numeric and non-numeric features\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "non_numeric_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"\\nFeature Type Breakdown:\")\n",
    "print(f\"  ðŸ“ˆ Numeric features: {len(numeric_cols)}\")\n",
    "print(f\"  ðŸ“ Non-numeric features: {len(non_numeric_cols)}\")\n",
    "print(f\"  ðŸ›¡ï¸  Protected columns defined: {len(protected_columns)}\")\n",
    "\n",
    "# Check which protected columns are numeric\n",
    "protected_numeric = [col for col in protected_columns if col in numeric_cols]\n",
    "protected_non_numeric = [col for col in protected_columns if col in non_numeric_cols]\n",
    "\n",
    "print(f\"\\nProtected Columns Analysis:\")\n",
    "print(f\"  ðŸ›¡ï¸ðŸ“ˆ Protected numeric: {len(protected_numeric)}\")\n",
    "print(f\"  ðŸ›¡ï¸ðŸ“ Protected non-numeric: {len(protected_non_numeric)}\")\n",
    "\n",
    "if protected_numeric:\n",
    "    print(f\"    Numeric protected: {protected_numeric}\")\n",
    "if protected_non_numeric:\n",
    "    print(f\"    Non-numeric protected: {protected_non_numeric}\")\n",
    "\n",
    "# Store original shapes for comparison\n",
    "original_train_shape = X_train.shape\n",
    "original_test_shape = X_test.shape\n",
    "\n",
    "print(f\"\\nðŸ” CORRELATION ANALYSIS ON NUMERIC FEATURES:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Analyzing {len(numeric_cols)} numeric features...\")\n",
    "print(f\"Correlation threshold: {correlation_threshold}\")\n",
    "\n",
    "# Compute the correlation matrix (only on numeric features)\n",
    "if len(numeric_cols) > 1:\n",
    "    corr_matrix = X_train[numeric_cols].corr().abs()\n",
    "    \n",
    "    # Find pairs of highly correlated features (above threshold)\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr_pairs = (\n",
    "        upper.stack()\n",
    "        .reset_index()\n",
    "        .rename(columns={'level_0': 'Feature_1', 'level_1': 'Feature_2', 0: 'Correlation'})\n",
    "        .query('Correlation > @correlation_threshold')\n",
    "        .sort_values(by='Correlation', ascending=False)\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {len(high_corr_pairs)} highly correlated pairs (correlation > {correlation_threshold})\")\n",
    "    \n",
    "    # Display the table of highly correlated pairs\n",
    "    if len(high_corr_pairs) > 0:\n",
    "        print(f\"\\nðŸ“‹ HIGHLY CORRELATED FEATURE PAIRS:\")\n",
    "        display(high_corr_pairs.head(20))  # Show top 20 pairs\n",
    "        \n",
    "        if len(high_corr_pairs) > 20:\n",
    "            print(f\"... and {len(high_corr_pairs) - 20} more pairs\")\n",
    "    else:\n",
    "        print(\"âœ… No feature pairs found above the correlation threshold!\")\n",
    "    \n",
    "    # Determine features to drop (excluding protected columns)\n",
    "    to_drop = set()\n",
    "    protection_log = []\n",
    "    \n",
    "    for _, row in high_corr_pairs.iterrows():\n",
    "        f1, f2 = row['Feature_1'], row['Feature_2']\n",
    "        correlation = row['Correlation']\n",
    "        \n",
    "        # If both are protected, skip\n",
    "        if f1 in protected_columns and f2 in protected_columns:\n",
    "            protection_log.append(f\"BOTH PROTECTED: {f1} â†” {f2} (r={correlation:.3f}) - No action\")\n",
    "            continue\n",
    "        # If one is protected, drop the other\n",
    "        elif f1 in protected_columns:\n",
    "            to_drop.add(f2)\n",
    "            protection_log.append(f\"PROTECTED {f1}: Dropping {f2} (r={correlation:.3f})\")\n",
    "        elif f2 in protected_columns:\n",
    "            to_drop.add(f1)\n",
    "            protection_log.append(f\"PROTECTED {f2}: Dropping {f1} (r={correlation:.3f})\")\n",
    "        else:\n",
    "            # If neither is protected, arbitrarily drop the second\n",
    "            to_drop.add(f2)\n",
    "            protection_log.append(f\"NO PROTECTION: Dropping {f2} over {f1} (r={correlation:.3f})\")\n",
    "    \n",
    "    print(f\"\\nðŸ›¡ï¸ PROTECTION DECISIONS LOG:\")\n",
    "    for log_entry in protection_log[:15]:  # Show first 15 decisions\n",
    "        print(f\"  {log_entry}\")\n",
    "    if len(protection_log) > 15:\n",
    "        print(f\"  ... and {len(protection_log) - 15} more decisions\")\n",
    "    \n",
    "    # Features to keep (numeric features not being dropped)\n",
    "    numeric_features_to_keep = [col for col in numeric_cols if col not in to_drop]\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Insufficient numeric features for correlation analysis\")\n",
    "    to_drop = set()\n",
    "    numeric_features_to_keep = numeric_cols\n",
    "\n",
    "# All features to keep (numeric + all non-numeric)\n",
    "all_features_to_keep = numeric_features_to_keep + non_numeric_cols\n",
    "\n",
    "# Remove features to drop from X_train and X_test\n",
    "X_train_pruned = X_train[all_features_to_keep].copy()\n",
    "X_test_pruned = X_test[all_features_to_keep].copy()\n",
    "\n",
    "print(f\"\\nðŸ“Š FEATURE PRUNING SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Original features: {original_train_shape[1]}\")\n",
    "print(f\"  â””â”€ Numeric: {len(numeric_cols)}\")\n",
    "print(f\"  â””â”€ Non-numeric: {len(non_numeric_cols)}\")\n",
    "print(f\"\")\n",
    "print(f\"Features removed: {len(to_drop)}\")\n",
    "print(f\"Features remaining: {len(all_features_to_keep)}\")\n",
    "print(f\"  â””â”€ Numeric remaining: {len(numeric_features_to_keep)}\")\n",
    "print(f\"  â””â”€ Non-numeric remaining: {len(non_numeric_cols)} (all preserved)\")\n",
    "print(f\"\")\n",
    "print(f\"Reduction: {len(to_drop)} features ({(len(to_drop)/original_train_shape[1]*100):.1f}%)\")\n",
    "\n",
    "# Detailed feature lists\n",
    "print(f\"\\nðŸ—‘ï¸ FEATURES REMOVED ({len(to_drop)}):\")\n",
    "if to_drop:\n",
    "    removed_list = sorted(list(to_drop))\n",
    "    for i, feature in enumerate(removed_list):\n",
    "        print(f\"  {i+1:2d}. {feature}\")\n",
    "else:\n",
    "    print(\"  None - no features met the removal criteria\")\n",
    "\n",
    "print(f\"\\nâœ… PROTECTED FEATURES STATUS:\")\n",
    "protected_kept = [col for col in protected_columns if col in all_features_to_keep]\n",
    "protected_lost = [col for col in protected_columns if col not in all_features_to_keep]\n",
    "\n",
    "print(f\"  ðŸ›¡ï¸ Protected and kept: {len(protected_kept)}\")\n",
    "for feature in protected_kept:\n",
    "    print(f\"    âœ“ {feature}\")\n",
    "\n",
    "if protected_lost:\n",
    "    print(f\"  âš ï¸ Protected but missing: {len(protected_lost)}\")\n",
    "    for feature in protected_lost:\n",
    "        print(f\"    âš ï¸ {feature}\")\n",
    "else:\n",
    "    print(f\"  âœ… All protected features successfully preserved!\")\n",
    "\n",
    "# Update X_train and X_test for downstream steps\n",
    "X_train = X_train_pruned\n",
    "X_test = X_test_pruned\n",
    "\n",
    "print(f\"\\nðŸ“ˆ FINAL DATASET SHAPES:\")\n",
    "print(f\"  Training set: {X_train.shape} (was {original_train_shape})\")\n",
    "print(f\"  Test set: {X_test.shape} (was {original_test_shape})\")\n",
    "\n",
    "print(f\"\\nâœ… Correlation-based feature pruning complete!\")\n",
    "print(f\"âœ… All protected columns preserved!\")\n",
    "print(f\"âœ… Training datasets updated for downstream modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f19d13e",
   "metadata": {},
   "source": [
    "#### 3.2.4 Set the required preprocessed variables for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93527f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5.4  Set the required preprocessed variables for modeling\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SETTING UP PREPROCESSOR FOR REDUCED FEATURE SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "Creating the updated preprocessor to work with our pruned feature set.\n",
    "This preprocessor will be used by all downstream modeling sections.\n",
    "\"\"\")\n",
    "\n",
    "# Determine which features from our reduced set are numeric vs categorical\n",
    "current_numeric_features = [f for f in all_features_to_keep if f in numeric_features]\n",
    "current_categorical_features = [f for f in all_features_to_keep if f in categorical_features]\n",
    "\n",
    "print(f\"ðŸ“Š FEATURE SET COMPOSITION:\")\n",
    "print(f\"  Total features after pruning: {len(all_features_to_keep)}\")\n",
    "print(f\"  Numeric features: {len(current_numeric_features)}\")\n",
    "print(f\"  Categorical features: {len(current_categorical_features)}\")\n",
    "\n",
    "# Create preprocessing pipelines for reduced feature set\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_pipeline_reduced = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline_reduced = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create the updated preprocessor for the reduced feature set\n",
    "preprocess_reduced = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline_reduced, current_numeric_features),\n",
    "        ('cat', categorical_pipeline_reduced, current_categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ”§ PREPROCESSOR CREATED:\")\n",
    "print(f\"  Variable name: preprocess_reduced\")\n",
    "print(f\"  Numeric transformer: StandardScaler for {len(current_numeric_features)} features\")\n",
    "print(f\"  Categorical transformer: OneHotEncoder for {len(current_categorical_features)} features\")\n",
    "\n",
    "# Validate the preprocessor with a small sample\n",
    "print(f\"\\nâœ… VALIDATION:\")\n",
    "try:\n",
    "    sample_size = min(100, len(X_train))\n",
    "    preprocess_reduced.fit(X_train.iloc[:sample_size])\n",
    "    print(f\"  âœ“ Successfully fitted preprocessor on sample data\")\n",
    "    \n",
    "    # Test transform\n",
    "    sample_transformed = preprocess_reduced.transform(X_train.iloc[:5])\n",
    "    print(f\"  âœ“ Transform test successful - output shape: {sample_transformed.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  âŒ Validation failed: {e}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ READY FOR MODELING:\")\n",
    "print(f\"  âœ“ preprocess_reduced variable is now available\")\n",
    "print(f\"  âœ“ Compatible with reduced feature set from correlation analysis\")\n",
    "print(f\"  âœ“ All downstream modeling sections can use this preprocessor\")\n",
    "print(f\"  âœ“ Original features: {original_train_shape[1]} â†’ Reduced features: {len(all_features_to_keep)}\")\n",
    "\n",
    "print(f\"\\nâœ… Section 3.5.5 complete - preprocessor ready for modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635c4fd2",
   "metadata": {},
   "source": [
    "#### 3.2.5 Analytical Data Table\n",
    "\n",
    "The Analytical Data Table provides data type definition and description of the features used for inference. \n",
    "\n",
    "It uses the SOURCE_Data_Dictionary.csv as the starting point but includes additional descriptions of the one-hot-encoded features and engineered features created to support the development of machine learning models. \n",
    "\n",
    "The variable \"preprocess_reduced\" contains the preprocessor we need to analyze.\n",
    "\n",
    "The Analytical Data Table should be output to the notebook output, not to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0061afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.5 Analytical Data Table\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANALYTICAL DATA TABLE GENERATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "Creating a comprehensive data dictionary for all features used in machine learning inference.\n",
    "This includes original features, one-hot encoded features, and engineered features.\n",
    "\"\"\")\n",
    "\n",
    "# 1. Extract feature information from the preprocessed dataset\n",
    "print(\"\\n1. EXTRACTING FEATURE INFORMATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Check if preprocess_reduced exists and is fitted\n",
    "try:\n",
    "    if 'preprocess_reduced' in locals() or 'preprocess_reduced' in globals():\n",
    "        print(\"âœ“ preprocess_reduced variable exists\")\n",
    "        \n",
    "        # Get feature names after preprocessing\n",
    "        if hasattr(preprocess_reduced, 'feature_names_in_'):\n",
    "            print(\"âœ“ Preprocessor is fitted\")\n",
    "            \n",
    "            # Get output feature names\n",
    "            if hasattr(preprocess_reduced, 'get_feature_names_out'):\n",
    "                try:\n",
    "                    feature_names = preprocess_reduced.get_feature_names_out()\n",
    "                    print(f\"âœ“ Successfully extracted {len(feature_names)} preprocessed feature names\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ Could not get feature names from preprocessor: {e}\")\n",
    "                    # Fall back to original feature names\n",
    "                    feature_names = list(X_train.columns)\n",
    "            else:\n",
    "                print(\"âš ï¸ Preprocessor doesn't have get_feature_names_out method\")\n",
    "                feature_names = list(X_train.columns)\n",
    "        else:\n",
    "            print(\"âš ï¸ Preprocessor is not fitted yet\")\n",
    "            feature_names = list(X_train.columns)\n",
    "    else:\n",
    "        print(\"âŒ preprocess_reduced variable does not exist\")\n",
    "        feature_names = list(X_train.columns)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error accessing preprocess_reduced: {e}\")\n",
    "    feature_names = list(X_train.columns)\n",
    "\n",
    "# 2. Load SOURCE_Data_Dictionary.csv if available\n",
    "print(\"\\n2. LOADING SOURCE DATA DICTIONARY\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    if os.path.exists('SOURCE_Data_Dictionary.csv'):\n",
    "        source_dict = pd.read_csv('SOURCE_Data_Dictionary.csv')\n",
    "        print(f\"âœ“ Loaded SOURCE_Data_Dictionary.csv with {len(source_dict)} entries\")\n",
    "        print(f\"Columns: {list(source_dict.columns)}\")\n",
    "        \n",
    "        # Create a mapping from source dictionary\n",
    "        if 'Variable' in source_dict.columns and 'Description' in source_dict.columns:\n",
    "            source_descriptions = dict(zip(source_dict['Variable'], source_dict['Description']))\n",
    "        else:\n",
    "            source_descriptions = {}\n",
    "            print(\"âš ï¸ Expected columns 'Variable' and 'Description' not found\")\n",
    "    else:\n",
    "        print(\"âš ï¸ SOURCE_Data_Dictionary.csv not found\")\n",
    "        source_descriptions = {}\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading SOURCE_Data_Dictionary.csv: {e}\")\n",
    "    source_descriptions = {}\n",
    "\n",
    "# 3. Create analytical data table\n",
    "print(\"\\n3. CREATING ANALYTICAL DATA TABLE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "analytical_data_table = []\n",
    "\n",
    "# Analyze features from X_train\n",
    "for column in X_train.columns:\n",
    "    feature_info = {\n",
    "        'Feature_Name': column,\n",
    "        'Data_Type': str(X_train[column].dtype),\n",
    "        'Feature_Type': '',\n",
    "        'Description': '',\n",
    "        'Source': '',\n",
    "        'Values_Range': '',\n",
    "        'Missing_Values': X_train[column].isnull().sum(),\n",
    "        'Unique_Values': X_train[column].nunique(),\n",
    "        'Sample_Values': '',\n",
    "        'Engineering_Notes': ''\n",
    "    }\n",
    "    \n",
    "    # Determine feature type and source\n",
    "    if column in source_descriptions:\n",
    "        feature_info['Description'] = source_descriptions[column]\n",
    "        feature_info['Source'] = 'SOURCE_Data_Dictionary'\n",
    "        feature_info['Feature_Type'] = 'Original'\n",
    "    elif any(keyword in column.lower() for keyword in ['channel_sales', 'origin_up', 'has_gas']):\n",
    "        feature_info['Feature_Type'] = 'One-Hot Encoded'\n",
    "        feature_info['Source'] = 'Categorical Encoding'\n",
    "        if 'channel_sales' in column:\n",
    "            feature_info['Description'] = f'One-hot encoded channel sales category: {column.replace(\"channel_sales_\", \"\")}'\n",
    "        elif 'origin_up' in column:\n",
    "            feature_info['Description'] = f'One-hot encoded origin category: {column.replace(\"origin_up_\", \"\")}'\n",
    "        elif 'has_gas' in column:\n",
    "            feature_info['Description'] = 'Gas service availability indicator'\n",
    "    elif any(keyword in column.lower() for keyword in ['price_', 'margin_', 'cons_', 'tenure_', '_diff', '_pct_']):\n",
    "        if any(eng_feat in column for eng_feat in ['tenure_months', 'price_x_cons', 'margin_bin', 'price_diff', 'pct_diff']):\n",
    "            feature_info['Feature_Type'] = 'Engineered'\n",
    "            feature_info['Source'] = 'Feature Engineering'\n",
    "            if 'tenure_months' in column:\n",
    "                feature_info['Description'] = 'Customer tenure calculated in months from years'\n",
    "            elif 'price_x_cons' in column:\n",
    "                feature_info['Description'] = 'Price multiplied by consumption for cost estimation'\n",
    "            elif 'margin_bin' in column:\n",
    "                feature_info['Description'] = 'Binned margin categories (Low/Medium/High)'\n",
    "            elif 'price_diff' in column:\n",
    "                feature_info['Description'] = 'Price difference calculation between periods'\n",
    "            elif 'pct_diff' in column:\n",
    "                feature_info['Description'] = 'Percentage price difference calculation'\n",
    "        else:\n",
    "            feature_info['Feature_Type'] = 'Price Statistics'\n",
    "            feature_info['Source'] = 'Price Data Aggregation'\n",
    "            if '_min' in column:\n",
    "                feature_info['Description'] = f'Minimum value of {column.replace(\"_min\", \"\")} over time'\n",
    "            elif '_max' in column:\n",
    "                feature_info['Description'] = f'Maximum value of {column.replace(\"_max\", \"\")} over time'\n",
    "            elif '_mean' in column:\n",
    "                feature_info['Description'] = f'Average value of {column.replace(\"_mean\", \"\")} over time'\n",
    "            elif '_last' in column:\n",
    "                feature_info['Description'] = f'Most recent value of {column.replace(\"_last\", \"\")} '\n",
    "            elif '_std' in column:\n",
    "                feature_info['Description'] = f'Standard deviation of {column.replace(\"_std\", \"\")} over time'\n",
    "            else:\n",
    "                feature_info['Description'] = 'Price-related statistical feature'\n",
    "    else:\n",
    "        feature_info['Feature_Type'] = 'Original'\n",
    "        feature_info['Source'] = 'Client Data'\n",
    "        feature_info['Description'] = 'Original feature from client dataset'\n",
    "    \n",
    "    # Add value range and sample values\n",
    "    if X_train[column].dtype in ['int64', 'float64']:\n",
    "        min_val = X_train[column].min()\n",
    "        max_val = X_train[column].max()\n",
    "        feature_info['Values_Range'] = f'{min_val:.2f} to {max_val:.2f}'\n",
    "        feature_info['Sample_Values'] = f'Min: {min_val:.2f}, Max: {max_val:.2f}, Mean: {X_train[column].mean():.2f}'\n",
    "    else:\n",
    "        unique_vals = X_train[column].unique()[:5]  # First 5 unique values\n",
    "        feature_info['Values_Range'] = f'{len(X_train[column].unique())} unique values'\n",
    "        feature_info['Sample_Values'] = ', '.join([str(v) for v in unique_vals])\n",
    "    \n",
    "    analytical_data_table.append(feature_info)\n",
    "\n",
    "# Convert to DataFrame\n",
    "analytical_df = pd.DataFrame(analytical_data_table)\n",
    "\n",
    "print(f\"âœ… Created analytical data table with {len(analytical_df)} features\")\n",
    "\n",
    "# 4. Display the analytical data table in notebook output\n",
    "print(\"\\n4. ANALYTICAL DATA TABLE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"ðŸ“Š FEATURE TYPE DISTRIBUTION:\")\n",
    "feature_type_counts = analytical_df['Feature_Type'].value_counts()\n",
    "for ftype, count in feature_type_counts.items():\n",
    "    percentage = (count / len(analytical_df)) * 100\n",
    "    print(f\"   â€¢ {ftype}: {count} features ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nðŸ“Š FEATURE SOURCE DISTRIBUTION:\")\n",
    "source_counts = analytical_df['Source'].value_counts()\n",
    "for source, count in source_counts.items():\n",
    "    percentage = (count / len(analytical_df)) * 100\n",
    "    print(f\"   â€¢ {source}: {count} features ({percentage:.1f}%)\")\n",
    "\n",
    "# Display the complete analytical data table\n",
    "print(f\"\\nðŸ“‹ COMPLETE ANALYTICAL DATA TABLE ({len(analytical_df)} features):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Display all features in the notebook output\n",
    "display(analytical_df[['Feature_Name', 'Feature_Type', 'Description', 'Source', 'Data_Type', 'Values_Range', 'Missing_Values', 'Unique_Values']].style.set_properties(**{\n",
    "    'text-align': 'left',\n",
    "    'white-space': 'pre-wrap',\n",
    "    'max-width': '200px'\n",
    "}).set_table_styles([{\n",
    "    'selector': 'th',\n",
    "    'props': [('background-color', '#f0f0f0'),\n",
    "              ('font-weight', 'bold'),\n",
    "              ('text-align', 'center')]\n",
    "}]))\n",
    "\n",
    "# Summary statistics\n",
    "missing_features = analytical_df[analytical_df['Missing_Values'] > 0]\n",
    "print(f\"\\nðŸ“ˆ SUMMARY STATISTICS:\")\n",
    "print(f\"   â€¢ Total Features: {len(analytical_df)}\")\n",
    "print(f\"   â€¢ Features with Missing Values: {len(missing_features)}\")\n",
    "print(f\"   â€¢ Numeric Features: {len(analytical_df[analytical_df['Data_Type'].isin(['int64', 'float64'])])}\")\n",
    "print(f\"   â€¢ Categorical Features: {len(analytical_df[analytical_df['Data_Type'] == 'object'])}\")\n",
    "\n",
    "if len(missing_features) > 0:\n",
    "    print(f\"\\nâš ï¸ FEATURES WITH MISSING VALUES:\")\n",
    "    for _, row in missing_features.iterrows():\n",
    "        pct_missing = (row['Missing_Values'] / len(X_train)) * 100\n",
    "        print(f\"   â€¢ {row['Feature_Name']}: {row['Missing_Values']} ({pct_missing:.1f}%)\")\n",
    "\n",
    "print(f\"\\nâœ… Analytical Data Table generation complete!\")\n",
    "print(\"ðŸ“„ Table displayed in notebook output above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7551b2e7",
   "metadata": {},
   "source": [
    "## 4â€ƒUtility Functions\n",
    "These functions will be reused by the various model pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set model_sources to an empyt list to which we can append the model names\n",
    "model_sources = []\n",
    "\n",
    "# Create the confusion matrix plot function\n",
    " \n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "def confusion_matrix_plot(name, pipeline, X_test, y_test):\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \"\"\"Plot confusion matrix.\"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(name)\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(name, pipeline, X_test, y_test, results):\n",
    "    \"\"\"Fit, predict, and store evaluation metrics.\"\"\"\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1] if hasattr(pipeline, 'predict_proba') else None\n",
    "    \n",
    "    # Get classification report for both classes\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    \n",
    "    # Calculate class-specific accuracies\n",
    "    class_0_mask = y_test == 0\n",
    "    class_1_mask = y_test == 1\n",
    "    accuracy_0 = (y_pred[class_0_mask] == y_test[class_0_mask]).mean() if class_0_mask.sum() > 0 else None\n",
    "    accuracy_1 = (y_pred[class_1_mask] == y_test[class_1_mask]).mean() if class_1_mask.sum() > 0 else None\n",
    "    \n",
    "    metrics = {\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Accuracy_0': accuracy_0,\n",
    "        'Accuracy_1': accuracy_1,\n",
    "        'Precision_0': report.get('0', {}).get('precision', None),\n",
    "        'Recall_0': report.get('0', {}).get('recall', None),\n",
    "        'F1_0': report.get('0', {}).get('f1-score', None),\n",
    "        'Precision_1': report.get('1', {}).get('precision', None),\n",
    "        'Recall_1': report.get('1', {}).get('recall', None),\n",
    "        'F1_1': report.get('1', {}).get('f1-score', None),\n",
    "        'F1_Macro': report.get('macro avg', {}).get('f1-score', None),\n",
    "        'F1_Weighted': report.get('weighted avg', {}).get('f1-score', None),\n",
    "        'ROC_AUC': None,\n",
    "        'PR_AUC': None\n",
    "    }\n",
    "\n",
    "    if y_prob is not None:\n",
    "        metrics['ROC_AUC'] = roc_auc_score(y_test, y_prob)\n",
    "        pr, rc, _ = precision_recall_curve(y_test, y_prob)\n",
    "        metrics['PR_AUC'] = average_precision_score(y_test, y_prob)\n",
    "\n",
    "    results.append(metrics)\n",
    "\n",
    "def plot_curves(pipelines, X_test, y_test, title_suffix=''):\n",
    "    \"\"\"Plot ROC and PR curves for multiple pipelines.\"\"\"\n",
    "    plt.figure(figsize=(6,5))\n",
    "    for name, pl in pipelines.items():\n",
    "        if hasattr(pl, 'predict_proba'):\n",
    "            y_prob = pl.predict_proba(X_test)[:,1]\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "            plt.plot(fpr, tpr, label=name)\n",
    "    plt.plot([0,1], [0,1], linestyle='--', alpha=0.6)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves ' + title_suffix)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    for name, pl in pipelines.items():\n",
    "        if hasattr(pl, 'predict_proba'):\n",
    "            y_prob = pl.predict_proba(X_test)[:,1]\n",
    "            pr, rc, _ = precision_recall_curve(y_test, y_prob)\n",
    "            plt.plot(rc, pr, label=name)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precisionâ€‘Recall Curves ' + title_suffix)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab44f61",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de2b1ebb",
   "metadata": {},
   "source": [
    "## 5â€ƒBaseline Models\n",
    "\n",
    "Our first benchmark includes:\n",
    "\n",
    "* **DummyClassifier** â€“ always predicts the majority class.\n",
    "* **Logistic Regression** â€“ a simple linear model.\n",
    "* **kâ€‘Nearest Neighbors (kNN)**.\n",
    "* **Decision Tree**.\n",
    "\n",
    "These baselines give us a yardstick for judging more advanced techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b9626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5 - Updated to use reduced preprocessor\n",
    "\n",
    "\n",
    "\n",
    "baseline_models = {\n",
    "    'Dummy': DummyClassifier(strategy='most_frequent', random_state=RANDOM_STATE),\n",
    "    'LogReg': LogisticRegression(max_iter=1000, class_weight=None, random_state=RANDOM_STATE),\n",
    "    'kNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "# CHANGE THIS LINE - use preprocess_reduced instead of preprocess\n",
    "baseline_pipes = {name: Pipeline([('pre', preprocess_reduced), ('clf', model)])\n",
    "                  for name, model in baseline_models.items()}\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "for name, pipe in baseline_pipes.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    confusion_matrix_plot(name, pipe, X_test, y_test)\n",
    "    evaluate_model(name, pipe, X_test, y_test, results)\n",
    "\n",
    "plot_curves(baseline_pipes, X_test, y_test, '(Baseline)')\n",
    "baseline_results = pd.DataFrame(results).set_index('Model').round(3)\n",
    "display(baseline_results)\n",
    "\n",
    "model_sources.append(('Baseline', baseline_pipes))\n",
    "\n",
    "# Plot baseline performance for Class 0 (No Churn)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "baseline_results[['Accuracy', 'Precision_0', 'Recall_0', 'F1_0']].plot.bar(ax=ax)\n",
    "ax.set_title('Baseline Model Performance - Class 0 (No Churn)')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot baseline performance for Class 1 (Churn)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "baseline_results[['Accuracy', 'Precision_1', 'Recall_1', 'F1_1']].plot.bar(ax=ax)\n",
    "ax.set_title('Baseline Model Performance - Class 1 (Churn)')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Overall baseline performance comparison\n",
    "baseline_results[['Accuracy', 'F1_Macro', 'F1_Weighted', 'ROC_AUC', 'PR_AUC']].plot.bar(figsize=(12,6))\n",
    "plt.title('Baseline Model Overall Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0,1.05)\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ae74d",
   "metadata": {},
   "source": [
    "### 5.1â€ƒAddressing Class Imbalance\n",
    "\n",
    "The churn classes are imbalanced. We will apply **SMOTE** (Synthetic Minority Overâ€‘sampling Technique) within the pipeline to generate synthetic minority examples. We compare performance with the unbalanced counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4078070",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_models = {name + '_SMOTE': model for name, model in baseline_models.items()}\n",
    "\n",
    "balanced_pipes = {\n",
    "    name: ImbPipeline([\n",
    "        ('pre', preprocess_reduced),  # â† Updated\n",
    "        ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    for name, model in balanced_models.items()\n",
    "}\n",
    "\n",
    "# model_sources = [\n",
    "#     ('Baseline', baseline_pipes if 'baseline_pipes' in locals() else {}),\n",
    "#     ('Balanced', balanced_pipes if 'balanced_pipes' in locals() else {})\n",
    "# ]\n",
    "\n",
    "model_sources.append(('Balanced', balanced_pipes))\n",
    "\n",
    "for name, pipe in balanced_pipes.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    confusion_matrix_plot(name, pipe, X_test, y_test)\n",
    "    evaluate_model(name, pipe, X_test, y_test, results)\n",
    "\n",
    "plot_curves(balanced_pipes, X_test, y_test, '(Balanced)')\n",
    "\n",
    "# Display balanced results\n",
    "balanced_results = pd.DataFrame(results[-len(balanced_pipes):]).set_index('Model').round(3)\n",
    "display(balanced_results)\n",
    "\n",
    "# Plot balanced performance for Class 0 (No Churn)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "balanced_results[['Accuracy', 'Precision_0', 'Recall_0', 'F1_0']].plot.bar(ax=ax)\n",
    "ax.set_title('Balanced Model Performance - Class 0 (No Churn)')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot balanced performance for Class 1 (Churn)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "balanced_results[['Accuracy', 'Precision_1', 'Recall_1', 'F1_1']].plot.bar(ax=ax)\n",
    "ax.set_title('Balanced Model Performance - Class 1 (Churn)')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe404ce",
   "metadata": {},
   "source": [
    "### 5.2 Balancing Analyisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE vs BALANCED MODELS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_models = []\n",
    "\n",
    "# Add baseline models\n",
    "for model_name in baseline_results.index:\n",
    "    baseline_row = baseline_results.loc[model_name].copy()\n",
    "    baseline_row['Model_Type'] = 'Baseline'\n",
    "    baseline_row['Model_Name'] = model_name\n",
    "    comparison_models.append(baseline_row)\n",
    "\n",
    "# Add balanced models\n",
    "for model_name in balanced_results.index:\n",
    "    balanced_row = balanced_results.loc[model_name].copy()\n",
    "    balanced_row['Model_Type'] = 'Balanced_SMOTE'\n",
    "    balanced_row['Model_Name'] = model_name.replace('_SMOTE', '')\n",
    "    comparison_models.append(balanced_row)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame(comparison_models)\n",
    "comparison_df = comparison_df.reset_index(drop=True)\n",
    "\n",
    "# Display full comparison\n",
    "print(\"\\nComplete Model Comparison:\")\n",
    "display(comparison_df[['Model_Name', 'Model_Type', 'Accuracy', 'F1_0', 'F1_1', 'F1_Macro', 'F1_Weighted', 'ROC_AUC', 'PR_AUC']].round(3))\n",
    "\n",
    "# Side-by-side comparison for each algorithm\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"SIDE-BY-SIDE ALGORITHM COMPARISON\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "algorithms = ['Dummy', 'LogReg', 'kNN', 'DecisionTree']\n",
    "\n",
    "for algo in algorithms:\n",
    "    print(f\"\\n{algo.upper()} - Baseline vs Balanced:\")\n",
    "    \n",
    "    baseline_metrics = comparison_df[\n",
    "        (comparison_df['Model_Name'] == algo) & \n",
    "        (comparison_df['Model_Type'] == 'Baseline')\n",
    "    ].iloc[0]\n",
    "    \n",
    "    balanced_metrics = comparison_df[\n",
    "        (comparison_df['Model_Name'] == algo) & \n",
    "        (comparison_df['Model_Type'] == 'Balanced_SMOTE')\n",
    "    ].iloc[0]\n",
    "    \n",
    "    # Key metrics comparison\n",
    "    metrics_to_compare = ['Accuracy', 'F1_0', 'F1_1', 'F1_Macro', 'F1_Weighted', 'ROC_AUC', 'PR_AUC']\n",
    "    \n",
    "    algo_comparison = pd.DataFrame({\n",
    "        'Baseline': [baseline_metrics[metric] for metric in metrics_to_compare],\n",
    "        'Balanced': [balanced_metrics[metric] for metric in metrics_to_compare],\n",
    "    }, index=metrics_to_compare)\n",
    "    \n",
    "    algo_comparison['Difference'] = algo_comparison['Balanced'] - algo_comparison['Baseline']\n",
    "    algo_comparison['Better'] = algo_comparison['Difference'].apply(lambda x: 'Balanced' if x > 0 else 'Baseline' if x < 0 else 'Tie')\n",
    "    \n",
    "    display(algo_comparison.round(3))\n",
    "\n",
    "# Overall winner analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WINNER ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate average improvements\n",
    "avg_improvements = {}\n",
    "for algo in algorithms:\n",
    "    baseline_row = comparison_df[\n",
    "        (comparison_df['Model_Name'] == algo) & \n",
    "        (comparison_df['Model_Type'] == 'Baseline')\n",
    "    ].iloc[0]\n",
    "    \n",
    "    balanced_row = comparison_df[\n",
    "        (comparison_df['Model_Name'] == algo) & \n",
    "        (comparison_df['Model_Type'] == 'Balanced_SMOTE')\n",
    "    ].iloc[0]\n",
    "    \n",
    "    improvements = {\n",
    "        'F1_Class_0': balanced_row['F1_0'] - baseline_row['F1_0'],\n",
    "        'F1_Class_1': balanced_row['F1_1'] - baseline_row['F1_1'],\n",
    "        'F1_Macro': balanced_row['F1_Macro'] - baseline_row['F1_Macro'],\n",
    "        'F1_Weighted': balanced_row['F1_Weighted'] - baseline_row['F1_Weighted'],\n",
    "        'ROC_AUC': balanced_row['ROC_AUC'] - baseline_row['ROC_AUC'],\n",
    "        'PR_AUC': balanced_row['PR_AUC'] - baseline_row['PR_AUC'],\n",
    "        'Accuracy': balanced_row['Accuracy'] - baseline_row['Accuracy']\n",
    "    }\n",
    "    \n",
    "    avg_improvements[algo] = improvements\n",
    "\n",
    "# Create summary table\n",
    "summary_df = pd.DataFrame(avg_improvements).T\n",
    "summary_df = summary_df.round(3)\n",
    "\n",
    "print(\"\\nIMPROVEMENTS (Balanced - Baseline):\")\n",
    "display(summary_df)\n",
    "\n",
    "# Count wins for each approach\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"WINS BY METRIC:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "wins_balanced = {}\n",
    "wins_baseline = {}\n",
    "\n",
    "for metric in ['F1_Class_0', 'F1_Class_1', 'F1_Macro', 'F1_Weighted', 'ROC_AUC', 'PR_AUC', 'Accuracy']:\n",
    "    balanced_wins = (summary_df[metric] > 0).sum()\n",
    "    baseline_wins = (summary_df[metric] < 0).sum()\n",
    "    ties = (summary_df[metric] == 0).sum()\n",
    "    \n",
    "    wins_balanced[metric] = balanced_wins\n",
    "    wins_baseline[metric] = baseline_wins\n",
    "    \n",
    "    print(f\"{metric:12}: Balanced={balanced_wins}, Baseline={baseline_wins}, Ties={ties}\")\n",
    "\n",
    "# Overall winner declaration\n",
    "total_balanced_wins = sum(wins_balanced.values())\n",
    "total_baseline_wins = sum(wins_baseline.values())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ† FINAL WINNER DECLARATION ðŸ†\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nTotal Wins Across All Metrics:\")\n",
    "print(f\"Balanced (SMOTE): {total_balanced_wins}\")\n",
    "print(f\"Baseline:         {total_baseline_wins}\")\n",
    "\n",
    "if total_balanced_wins > total_baseline_wins:\n",
    "    winner = \"BALANCED (SMOTE) MODELS\"\n",
    "    win_margin = total_balanced_wins - total_baseline_wins\n",
    "elif total_baseline_wins > total_balanced_wins:\n",
    "    winner = \"BASELINE MODELS\"\n",
    "    win_margin = total_baseline_wins - total_balanced_wins\n",
    "else:\n",
    "    winner = \"TIE\"\n",
    "    win_margin = 0\n",
    "\n",
    "print(f\"\\nðŸŽ¯ WINNER: {winner}\")\n",
    "if win_margin > 0:\n",
    "    print(f\"   Margin: {win_margin} metric wins\")\n",
    "\n",
    "# Key insights\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"\\n1. Class 1 (Churn) Performance:\")\n",
    "class_1_improvement = summary_df['F1_Class_1'].mean()\n",
    "if class_1_improvement > 0:\n",
    "    print(f\"   âœ“ Balanced models improved churn detection by {class_1_improvement:.3f} F1-score on average\")\n",
    "else:\n",
    "    print(f\"   âœ— Balanced models decreased churn detection by {abs(class_1_improvement):.3f} F1-score on average\")\n",
    "\n",
    "print(\"\\n2. Class 0 (No Churn) Performance:\")\n",
    "class_0_improvement = summary_df['F1_Class_0'].mean()\n",
    "if class_0_improvement > 0:\n",
    "    print(f\"   âœ“ Balanced models improved no-churn detection by {class_0_improvement:.3f} F1-score on average\")\n",
    "else:\n",
    "    print(f\"   âœ— Balanced models decreased no-churn detection by {abs(class_0_improvement):.3f} F1-score on average\")\n",
    "\n",
    "print(\"\\n3. Overall Performance:\")\n",
    "overall_improvement = summary_df['F1_Weighted'].mean()\n",
    "if overall_improvement > 0:\n",
    "    print(f\"   âœ“ Balanced models improved overall F1-weighted by {overall_improvement:.3f} on average\")\n",
    "else:\n",
    "    print(f\"   âœ— Balanced models decreased overall F1-weighted by {abs(overall_improvement):.3f} on average\")\n",
    "\n",
    "print(\"\\n4. Best Individual Models:\")\n",
    "best_baseline = baseline_results.loc[baseline_results['F1_Weighted'].idxmax()]\n",
    "best_balanced = balanced_results.loc[balanced_results['F1_Weighted'].idxmax()]\n",
    "\n",
    "print(f\"   Best Baseline: {best_baseline.name} (F1_Weighted: {best_baseline['F1_Weighted']:.3f})\")\n",
    "print(f\"   Best Balanced: {best_balanced.name} (F1_Weighted: {best_balanced['F1_Weighted']:.3f})\")\n",
    "\n",
    "if best_balanced['F1_Weighted'] > best_baseline['F1_Weighted']:\n",
    "    print(f\"   ðŸ† Best Overall: {best_balanced.name}\")\n",
    "else:\n",
    "    print(f\"   ðŸ† Best Overall: {best_baseline.name}\")\n",
    "\n",
    "print(\"\\n5. Trade-off Analysis:\")\n",
    "print(\"   SMOTE typically:\")\n",
    "print(\"   â€¢ Improves minority class (churn) detection\")\n",
    "print(\"   â€¢ May reduce majority class (no-churn) performance\")\n",
    "print(\"   â€¢ Better for imbalanced datasets where catching churners is critical\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDATION:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if winner == \"BALANCED (SMOTE) MODELS\":\n",
    "    print(\"âœ… Use BALANCED models for production\")\n",
    "    print(\"   Reason: Better overall performance and improved churn detection\")\n",
    "elif winner == \"BASELINE MODELS\":\n",
    "    print(\"âœ… Use BASELINE models for production\")\n",
    "    print(\"   Reason: Better overall performance without class balancing overhead\")\n",
    "else:\n",
    "    print(\"âš–ï¸  Consider business requirements:\")\n",
    "    print(\"   â€¢ If churn detection is critical â†’ Use BALANCED models\")\n",
    "    print(\"   â€¢ If overall accuracy is priority â†’ Use BASELINE models\")\n",
    "\n",
    "# Visualization of the comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: F1 Score comparison for Class 0\n",
    "ax1 = axes[0, 0]\n",
    "x = np.arange(len(algorithms))\n",
    "width = 0.35\n",
    "\n",
    "baseline_f1_0 = [comparison_df[(comparison_df['Model_Name'] == algo) & (comparison_df['Model_Type'] == 'Baseline')]['F1_0'].iloc[0] for algo in algorithms]\n",
    "balanced_f1_0 = [comparison_df[(comparison_df['Model_Name'] == algo) & (comparison_df['Model_Type'] == 'Balanced_SMOTE')]['F1_0'].iloc[0] for algo in algorithms]\n",
    "\n",
    "ax1.bar(x - width/2, baseline_f1_0, width, label='Baseline', alpha=0.8)\n",
    "ax1.bar(x + width/2, balanced_f1_0, width, label='Balanced', alpha=0.8)\n",
    "ax1.set_xlabel('Algorithms')\n",
    "ax1.set_ylabel('F1 Score')\n",
    "ax1.set_title('F1 Score Comparison - Class 0 (No Churn)')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(algorithms)\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Plot 2: F1 Score comparison for Class 1\n",
    "ax2 = axes[0, 1]\n",
    "baseline_f1_1 = [comparison_df[(comparison_df['Model_Name'] == algo) & (comparison_df['Model_Type'] == 'Baseline')]['F1_1'].iloc[0] for algo in algorithms]\n",
    "balanced_f1_1 = [comparison_df[(comparison_df['Model_Name'] == algo) & (comparison_df['Model_Type'] == 'Balanced_SMOTE')]['F1_1'].iloc[0] for algo in algorithms]\n",
    "\n",
    "ax2.bar(x - width/2, baseline_f1_1, width, label='Baseline', alpha=0.8)\n",
    "ax2.bar(x + width/2, balanced_f1_1, width, label='Balanced', alpha=0.8)\n",
    "ax2.set_xlabel('Algorithms')\n",
    "ax2.set_ylabel('F1 Score')\n",
    "ax2.set_title('F1 Score Comparison - Class 1 (Churn)')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(algorithms)\n",
    "ax2.legend()\n",
    "ax2.set_ylim(0, 1.05)\n",
    "\n",
    "# Plot 3: Overall F1 Weighted comparison\n",
    "ax3 = axes[1, 0]\n",
    "baseline_f1_weighted = [comparison_df[(comparison_df['Model_Name'] == algo) & (comparison_df['Model_Type'] == 'Baseline')]['F1_Weighted'].iloc[0] for algo in algorithms]\n",
    "balanced_f1_weighted = [comparison_df[(comparison_df['Model_Name'] == algo) & (comparison_df['Model_Type'] == 'Balanced_SMOTE')]['F1_Weighted'].iloc[0] for algo in algorithms]\n",
    "\n",
    "ax3.bar(x - width/2, baseline_f1_weighted, width, label='Baseline', alpha=0.8)\n",
    "ax3.bar(x + width/2, balanced_f1_weighted, width, label='Balanced', alpha=0.8)\n",
    "ax3.set_xlabel('Algorithms')\n",
    "ax3.set_ylabel('F1 Weighted Score')\n",
    "ax3.set_title('F1 Weighted Score Comparison')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(algorithms)\n",
    "ax3.legend()\n",
    "ax3.set_ylim(0, 1.05)\n",
    "\n",
    "# Plot 4: ROC AUC comparison\n",
    "ax4 = axes[1, 1]\n",
    "baseline_roc = [comparison_df[(comparison_df['Model_Name'] == algo) & (comparison_df['Model_Type'] == 'Baseline')]['ROC_AUC'].iloc[0] for algo in algorithms]\n",
    "balanced_roc = [comparison_df[(comparison_df['Model_Name'] == algo) & (comparison_df['Model_Type'] == 'Balanced_SMOTE')]['ROC_AUC'].iloc[0] for algo in algorithms]\n",
    "\n",
    "ax4.bar(x - width/2, baseline_roc, width, label='Baseline', alpha=0.8)\n",
    "ax4.bar(x + width/2, balanced_roc, width, label='Balanced', alpha=0.8)\n",
    "ax4.set_xlabel('Algorithms')\n",
    "ax4.set_ylabel('ROC AUC')\n",
    "ax4.set_title('ROC AUC Comparison')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(algorithms)\n",
    "ax4.legend()\n",
    "ax4.set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Comparison visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd72d8da",
   "metadata": {},
   "source": [
    "### 5.3 Segment-Specific Balancing Analysis\n",
    "\n",
    "#### Current SMOTE Issues Analysis\n",
    "\n",
    "Looking at the results, SMOTE may be struggling because:\n",
    "\n",
    "* Synthetic samples may not capture real churn patterns in your specific domain\n",
    "* Feature interactions between channel_sales_ and origin_up_ may be too complex for SMOTE\n",
    "* High-dimensional one-hot encoded features can make SMOTE less effective\n",
    "\n",
    "#### Recommendation: Start with Segment-Specific Balancing\n",
    "\n",
    "Based on the domain (utility churn with channel_sales_ and origin_up_ segments), I recommend:\n",
    "\n",
    "* Try segment-specific balancing first - Different acquisition channels and customer origins likely have fundamentally different churn patterns\n",
    "* Use BorderlineSMOTE or ADASYN instead of regular SMOTE - They're more sophisticated for complex datasets\n",
    "* Implement cost-sensitive learning - Often more effective than resampling for imbalanced problems\n",
    "* Optimize decision thresholds - May give better results than changing the training data\n",
    "\n",
    "The segment-specific approach is particularly promising because:\n",
    "\n",
    "Channel_sales_ and origin_up_ likely represent distinct customer behaviors\n",
    "Balancing within segments preserves the natural distribution differences\n",
    "It prevents artificial mixing of fundamentally different customer types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e57e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6.3 Segment-Specific Balancing Analysis (Baseline Models)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SEGMENT-SPECIFIC BALANCING ANALYSIS - BASELINE MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This approach balances data within each channel_sales + origin_up segment combination,\n",
    "preserving natural segment distributions while addressing class imbalance locally.\n",
    "We'll apply this to baseline models first, then repeat for advanced and ensemble models.\n",
    "\"\"\")\n",
    "\n",
    "# 1. Create segment-specific balanced dataset\n",
    "print(\"\\n1. CREATING SEGMENT-SPECIFIC BALANCED DATASET\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "def create_segment_balanced_dataset(df_input, target_col, min_segment_size=20):\n",
    "    \"\"\"\n",
    "    Balance data within each segment (channel_sales + origin_up combination)\n",
    "    \"\"\"\n",
    "    balanced_dfs = []\n",
    "    \n",
    "    # Find channel_sales and origin_up columns\n",
    "    channel_cols = [col for col in df_input.columns if col.startswith('channel_sales_')]\n",
    "    origin_cols = [col for col in df_input.columns if col.startswith('origin_up_')]\n",
    "    \n",
    "    print(f\"Found {len(channel_cols)} channel_sales columns\")\n",
    "    print(f\"Found {len(origin_cols)} origin_up columns\")\n",
    "    \n",
    "    if not channel_cols or not origin_cols:\n",
    "        print(\"âš ï¸  Required segment columns not found. Using global balancing.\")\n",
    "        return df_input, pd.DataFrame()\n",
    "    \n",
    "    # Create segment identifiers\n",
    "    df_temp = df_input.copy()\n",
    "    df_temp['channel'] = df_temp[channel_cols].idxmax(axis=1).str.replace('channel_sales_', '')\n",
    "    df_temp['origin'] = df_temp[origin_cols].idxmax(axis=1).str.replace('origin_up_', '')\n",
    "    \n",
    "    # Get unique combinations\n",
    "    segments = df_temp.groupby(['channel', 'origin']).size().sort_values(ascending=False)\n",
    "    print(f\"\\nFound {len(segments)} unique channel-origin combinations\")\n",
    "    \n",
    "    segment_summary = []\n",
    "    total_original = len(df_temp)\n",
    "    total_balanced = 0\n",
    "    \n",
    "    for (channel, origin), count in segments.items():\n",
    "        if count >= min_segment_size:  # Only process segments with sufficient data\n",
    "            segment_data = df_temp[(df_temp['channel'] == channel) & \n",
    "                                 (df_temp['origin'] == origin)].copy()\n",
    "            \n",
    "            # Check class distribution in this segment\n",
    "            class_dist = segment_data[target_col].value_counts()\n",
    "            \n",
    "            if len(class_dist) == 2:  # Both classes present\n",
    "                minority_count = class_dist.min()\n",
    "                majority_count = class_dist.max()\n",
    "                minority_class = class_dist.idxmin()\n",
    "                majority_class = class_dist.idxmax()\n",
    "                \n",
    "                minority_data = segment_data[segment_data[target_col] == minority_class]\n",
    "                majority_data = segment_data[segment_data[target_col] == majority_class]\n",
    "                \n",
    "                # Strategy: Undersample majority to match minority\n",
    "                if len(majority_data) > len(minority_data):\n",
    "                    majority_balanced = majority_data.sample(n=len(minority_data), \n",
    "                                                           random_state=42)\n",
    "                    segment_balanced = pd.concat([minority_data, majority_balanced])\n",
    "                else:\n",
    "                    segment_balanced = segment_data\n",
    "                \n",
    "                # Remove temporary columns before adding to balanced dataset\n",
    "                segment_clean = segment_balanced.drop(['channel', 'origin'], axis=1)\n",
    "                balanced_dfs.append(segment_clean)\n",
    "                total_balanced += len(segment_balanced)\n",
    "                \n",
    "                segment_summary.append({\n",
    "                    'Channel': channel,\n",
    "                    'Origin': origin,\n",
    "                    'Original_Size': count,\n",
    "                    'Balanced_Size': len(segment_balanced),\n",
    "                    'Original_Churn_Rate': segment_data[target_col].mean(),\n",
    "                    'Balanced_Churn_Rate': segment_balanced[target_col].mean(),\n",
    "                    'Majority_Class': majority_class,\n",
    "                    'Minority_Class': minority_class,\n",
    "                    'Original_Imbalance': majority_count / minority_count if minority_count > 0 else float('inf'),\n",
    "                    'Balanced_Imbalance': 1.0  # Perfect balance after undersampling\n",
    "                })\n",
    "            else:\n",
    "                # Single class only - include as is but don't count as \"balanced\"\n",
    "                segment_clean = segment_data.drop(['channel', 'origin'], axis=1)\n",
    "                balanced_dfs.append(segment_clean)\n",
    "                total_balanced += len(segment_data)\n",
    "                \n",
    "                segment_summary.append({\n",
    "                    'Channel': channel,\n",
    "                    'Origin': origin,\n",
    "                    'Original_Size': count,\n",
    "                    'Balanced_Size': len(segment_data),\n",
    "                    'Original_Churn_Rate': segment_data[target_col].mean(),\n",
    "                    'Balanced_Churn_Rate': segment_data[target_col].mean(),\n",
    "                    'Majority_Class': class_dist.index[0],\n",
    "                    'Minority_Class': 'None',\n",
    "                    'Original_Imbalance': 1.0,\n",
    "                    'Balanced_Imbalance': 1.0\n",
    "                })\n",
    "        else:\n",
    "            print(f\"   Skipping {channel}-{origin}: only {count} samples (< {min_segment_size})\")\n",
    "    \n",
    "    if balanced_dfs:\n",
    "        final_balanced_df = pd.concat(balanced_dfs, ignore_index=True)\n",
    "        \n",
    "        # Create summary dataframe\n",
    "        summary_df = pd.DataFrame(segment_summary)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š SEGMENT BALANCING SUMMARY:\")\n",
    "        print(f\"   Original dataset: {total_original:,} samples\")\n",
    "        print(f\"   Segment-balanced dataset: {total_balanced:,} samples\")\n",
    "        print(f\"   Segments processed: {len(summary_df)}\")\n",
    "        print(f\"   Data retention: {total_balanced/total_original*100:.1f}%\")\n",
    "        \n",
    "        # Display detailed segment analysis\n",
    "        print(f\"\\nðŸ“‹ DETAILED SEGMENT ANALYSIS:\")\n",
    "        display(summary_df.round(3))\n",
    "        \n",
    "        # Visualize segment balancing results\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # Plot 1: Original vs Balanced dataset sizes\n",
    "        ax1 = axes[0, 0]\n",
    "        ax1.scatter(summary_df['Original_Size'], summary_df['Balanced_Size'], alpha=0.7, s=80)\n",
    "        ax1.plot([0, summary_df['Original_Size'].max()], [0, summary_df['Original_Size'].max()], \n",
    "                'r--', alpha=0.5, label='No Change Line')\n",
    "        ax1.set_xlabel('Original Segment Size')\n",
    "        ax1.set_ylabel('Balanced Segment Size')\n",
    "        ax1.set_title('Segment Size: Original vs Balanced')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Churn rate changes\n",
    "        ax2 = axes[0, 1]\n",
    "        ax2.scatter(summary_df['Original_Churn_Rate'], summary_df['Balanced_Churn_Rate'], \n",
    "                   alpha=0.7, s=80, color='orange')\n",
    "        ax2.plot([0, 1], [0, 1], 'r--', alpha=0.5, label='No Change Line')\n",
    "        ax2.set_xlabel('Original Churn Rate')\n",
    "        ax2.set_ylabel('Balanced Churn Rate')\n",
    "        ax2.set_title('Churn Rate: Original vs Balanced')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Imbalance reduction\n",
    "        ax3 = axes[1, 0]\n",
    "        # Filter out infinite values for plotting\n",
    "        finite_imbalance = summary_df[summary_df['Original_Imbalance'] != float('inf')]\n",
    "        if len(finite_imbalance) > 0:\n",
    "            bars = ax3.bar(range(len(finite_imbalance)), finite_imbalance['Original_Imbalance'], \n",
    "                          alpha=0.7, label='Original Imbalance', color='red')\n",
    "            ax3.bar(range(len(finite_imbalance)), finite_imbalance['Balanced_Imbalance'], \n",
    "                   alpha=0.7, label='Balanced Imbalance', color='green')\n",
    "        ax3.set_xlabel('Segment Index')\n",
    "        ax3.set_ylabel('Class Imbalance Ratio')\n",
    "        ax3.set_title('Class Imbalance: Before vs After Balancing')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 4: Segment size distribution\n",
    "        ax4 = axes[1, 1]\n",
    "        ax4.hist(summary_df['Original_Size'], bins=15, alpha=0.7, label='Original', color='lightblue')\n",
    "        ax4.hist(summary_df['Balanced_Size'], bins=15, alpha=0.7, label='Balanced', color='lightgreen')\n",
    "        ax4.set_xlabel('Segment Size')\n",
    "        ax4.set_ylabel('Number of Segments')\n",
    "        ax4.set_title('Distribution of Segment Sizes')\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return final_balanced_df, summary_df\n",
    "    else:\n",
    "        print(\"âš ï¸  No segments could be processed for balancing\")\n",
    "        return df_input, pd.DataFrame()\n",
    "\n",
    "# **KEY FIX: Use the reduced dataset instead of the original df**\n",
    "# Create segment-balanced dataset using the reduced feature set\n",
    "segment_balanced_df, segment_summary = create_segment_balanced_dataset(\n",
    "    pd.concat([X, y], axis=1),  # Use reduced X with y\n",
    "    target_col\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Segment-specific balancing complete!\")\n",
    "print(f\"New class distribution:\")\n",
    "if len(segment_balanced_df) > 0:\n",
    "    new_class_dist = segment_balanced_df[target_col].value_counts()\n",
    "    print(new_class_dist)\n",
    "    print(f\"New imbalance ratio: {new_class_dist.min() / new_class_dist.max():.3f}\")\n",
    "\n",
    "# 2. Train BASELINE models on segment-balanced data\n",
    "print(\"\\n2. TRAINING BASELINE MODELS ON SEGMENT-BALANCED DATA\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if len(segment_balanced_df) > 0:\n",
    "    # Prepare new train/test split from segment-balanced data\n",
    "    y_segment = segment_balanced_df[target_col]\n",
    "    X_segment = segment_balanced_df.drop(columns=[target_col])\n",
    "    \n",
    "    # Use same preprocessing pipeline (reduced)\n",
    "    X_train_seg, X_test_seg, y_train_seg, y_test_seg = train_test_split(\n",
    "        X_segment, y_segment, test_size=0.2, stratify=y_segment, random_state=RANDOM_STATE)\n",
    "    \n",
    "    print(f\"Segment-balanced train size: {X_train_seg.shape[0]:,}\")\n",
    "    print(f\"Segment-balanced test size: {X_test_seg.shape[0]:,}\")\n",
    "    \n",
    "    # Train all baseline models on segment-balanced data\n",
    "    baseline_segment_balanced_models = {}\n",
    "    \n",
    "    for name, model in baseline_models.items():\n",
    "        seg_pipe = Pipeline([\n",
    "            ('pre', preprocess_reduced),  # Use reduced preprocessor\n",
    "            ('clf', model)\n",
    "        ])\n",
    "        seg_pipe.fit(X_train_seg, y_train_seg)\n",
    "        baseline_segment_balanced_models[f'{name}_SegmentBalanced'] = seg_pipe\n",
    "        \n",
    "        # Evaluate on original test set to maintain consistency\n",
    "        confusion_matrix_plot(name, seg_pipe, X_test, y_test)\n",
    "        evaluate_model(f'{name}_SegmentBalanced', seg_pipe, X_test, y_test, results)\n",
    "        print(f\"   âœ… Trained {name}_SegmentBalanced\")\n",
    "    \n",
    "    # Get segment-balanced results for baseline models\n",
    "    baseline_segment_results = pd.DataFrame(results[-len(baseline_segment_balanced_models):]).set_index('Model').round(3)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š BASELINE SEGMENT-BALANCED MODEL PERFORMANCE:\")\n",
    "    display(baseline_segment_results)\n",
    "\n",
    "# 3. Compare baseline models: Original vs SMOTE vs Segment-Balanced\n",
    "print(\"\\n3. BASELINE MODEL COMPARISON: ORIGINAL vs SMOTE vs SEGMENT-BALANCED\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if len(segment_balanced_df) > 0:\n",
    "    # Create comparison table for baseline models\n",
    "    baseline_comparison_approaches = []\n",
    "    \n",
    "    # Original baseline (best)\n",
    "    best_baseline_model = baseline_results.loc[baseline_results['F1_Weighted'].idxmax()]\n",
    "    baseline_comparison_approaches.append({\n",
    "        'Approach': 'Original (No Balancing)',\n",
    "        'Best_Model': best_baseline_model.name,\n",
    "        'F1_Weighted': best_baseline_model['F1_Weighted'],\n",
    "        'F1_Class_0': best_baseline_model['F1_0'],\n",
    "        'F1_Class_1': best_baseline_model['F1_1'],\n",
    "        'Accuracy': best_baseline_model['Accuracy'],\n",
    "        'ROC_AUC': best_baseline_model['ROC_AUC'],\n",
    "        'PR_AUC': best_baseline_model['PR_AUC']\n",
    "    })\n",
    "    \n",
    "    # SMOTE balanced (best)\n",
    "    best_smote_model = balanced_results.loc[balanced_results['F1_Weighted'].idxmax()]\n",
    "    baseline_comparison_approaches.append({\n",
    "        'Approach': 'Global SMOTE',\n",
    "        'Best_Model': best_smote_model.name,\n",
    "        'F1_Weighted': best_smote_model['F1_Weighted'],\n",
    "        'F1_Class_0': best_smote_model['F1_0'],\n",
    "        'F1_Class_1': best_smote_model['F1_1'],\n",
    "        'Accuracy': best_smote_model['Accuracy'],\n",
    "        'ROC_AUC': best_smote_model['ROC_AUC'],\n",
    "        'PR_AUC': best_smote_model['PR_AUC']\n",
    "    })\n",
    "    \n",
    "    # Segment-specific (best)\n",
    "    best_segment_baseline = baseline_segment_results.loc[baseline_segment_results['F1_Weighted'].idxmax()]\n",
    "    baseline_comparison_approaches.append({\n",
    "        'Approach': 'Segment-Specific Balancing',\n",
    "        'Best_Model': best_segment_baseline.name,\n",
    "        'F1_Weighted': best_segment_baseline['F1_Weighted'],\n",
    "        'F1_Class_0': best_segment_baseline['F1_0'],\n",
    "        'F1_Class_1': best_segment_baseline['F1_1'],\n",
    "        'Accuracy': best_segment_baseline['Accuracy'],\n",
    "        'ROC_AUC': best_segment_baseline['ROC_AUC'],\n",
    "        'PR_AUC': best_segment_baseline['PR_AUC']\n",
    "    })\n",
    "    \n",
    "    # Create comparison dataframe\n",
    "    baseline_comparison_df = pd.DataFrame(baseline_comparison_approaches)\n",
    "    \n",
    "    print(\"ðŸ“Š BASELINE BALANCING APPROACHES COMPARISON:\")\n",
    "    display(baseline_comparison_df.round(3))\n",
    "    \n",
    "    # Visualization of baseline approach comparison\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    approaches = baseline_comparison_df['Approach'].tolist()\n",
    "    colors = ['lightblue', 'lightgreen', 'orange']\n",
    "    \n",
    "    # Plot 1: F1_Weighted comparison\n",
    "    ax1 = axes[0, 0]\n",
    "    bars = ax1.bar(approaches, baseline_comparison_df['F1_Weighted'], color=colors, alpha=0.8)\n",
    "    ax1.set_ylabel('F1 Weighted Score')\n",
    "    ax1.set_title('F1 Weighted Comparison\\n(Baseline Models)')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Plot 2: Churn detection (F1_Class_1) comparison\n",
    "    ax2 = axes[0, 1]\n",
    "    bars = ax2.bar(approaches, baseline_comparison_df['F1_Class_1'], color=colors, alpha=0.8)\n",
    "    ax2.set_ylabel('F1 Score - Class 1 (Churn)')\n",
    "    ax2.set_title('Churn Detection Comparison\\n(Baseline Models)')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax2.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Plot 3: Class balance visualization\n",
    "    ax3 = axes[1, 0]\n",
    "    x_pos = np.arange(len(approaches))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax3.bar(x_pos - width/2, baseline_comparison_df['F1_Class_0'], width, \n",
    "            label='Class 0 (No Churn)', color='lightblue', alpha=0.8)\n",
    "    ax3.bar(x_pos + width/2, baseline_comparison_df['F1_Class_1'], width,\n",
    "            label='Class 1 (Churn)', color='lightcoral', alpha=0.8)\n",
    "    \n",
    "    ax3.set_xlabel('Approaches')\n",
    "    ax3.set_ylabel('F1 Score')\n",
    "    ax3.set_title('Class Balance Performance\\n(Baseline Models)')\n",
    "    ax3.set_xticks(x_pos)\n",
    "    ax3.set_xticklabels(approaches, rotation=45, ha='right')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: ROC AUC comparison\n",
    "    ax4 = axes[1, 1]\n",
    "    bars = ax4.bar(approaches, baseline_comparison_df['ROC_AUC'], color=colors, alpha=0.8)\n",
    "    ax4.set_ylabel('ROC AUC')\n",
    "    ax4.set_title('ROC AUC Comparison\\n(Baseline Models)')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax4.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Winner analysis for baseline models\n",
    "    print(\"\\n4. BASELINE MODEL WINNER ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Find best approach for each metric\n",
    "    best_overall_baseline = baseline_comparison_df.loc[baseline_comparison_df['F1_Weighted'].idxmax()]\n",
    "    best_churn_detection_baseline = baseline_comparison_df.loc[baseline_comparison_df['F1_Class_1'].idxmax()]\n",
    "    \n",
    "    print(\"ðŸ† BEST BASELINE APPROACH BY METRIC:\")\n",
    "    print(f\"   F1_Weighted: {best_overall_baseline['Approach']} ({best_overall_baseline['F1_Weighted']:.3f})\")\n",
    "    print(f\"   Churn Detection: {best_churn_detection_baseline['Approach']} ({best_churn_detection_baseline['F1_Class_1']:.3f})\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¡ BASELINE MODEL INSIGHTS:\")\n",
    "    print(\"   â€¢ Segment-specific balancing preserves natural data distributions\")\n",
    "    print(\"   â€¢ Different approaches show varying trade-offs between overall and churn performance\")\n",
    "    print(\"   â€¢ Results establish foundation for advanced model comparisons\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸  Segment balancing could not be performed. Check data structure.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE SEGMENT-SPECIFIC BALANCING ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f4ea5",
   "metadata": {},
   "source": [
    "#### Notes on 6.3 Results:\n",
    "\n",
    "Looking at the results from section 6.3, the segment-specific balancing approach didn't show meaningful improvements over the original baseline or SMOTE approaches. Here's what I observed:\n",
    "\n",
    "Why Segment-Specific Balancing Had No Impact\n",
    "1. Limited Data Variation Within Segments\n",
    "\n",
    "When we filtered customers by specific channel-origin combinations, the resulting segments were too small or homogeneous\n",
    "Many segments had insufficient data (< 20 samples) to create meaningful balanced datasets\n",
    "The balancing was too localized to capture broader churn patterns\n",
    "2. Feature Dominance Over Segmentation\n",
    "\n",
    "The model appears to be driven by other features (usage patterns, consumption behavior, demographics) rather than channel-origin combinations\n",
    "Segment-specific balancing only addresses class imbalance within artificial groupings, not the underlying predictive features\n",
    "3. One-Hot Encoding Limitations\n",
    "\n",
    "Channel and origin information was already captured through one-hot encoded features\n",
    "Creating explicit segments and then balancing within them essentially duplicated information the model already had access to\n",
    "Better Alternatives for Your Dataset\n",
    "Instead of segment-specific balancing, consider these more effective approaches:\n",
    "\n",
    "1. Advanced Sampling Techniques\n",
    "2. Cost-Sensitive Learning (often more effective than resampling)\n",
    "3. Threshold Optimization (often overlooked but very effective)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b73f6",
   "metadata": {},
   "source": [
    "### 5.4 Advanced Sampling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6.4 Advanced Sampling Techniques (Baseline Models Only)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADVANCED SAMPLING TECHNIQUES - BASELINE MODELS ONLY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This section explores advanced sampling techniques that can potentially outperform\n",
    "basic SMOTE by using more sophisticated algorithms for handling class imbalance.\n",
    "We'll apply these only to baseline models for now:\n",
    "\n",
    "â€¢ BorderlineSMOTE: Focuses on borderline cases between classes\n",
    "â€¢ ADASYN: Adaptive Synthetic Sampling for better minority class coverage  \n",
    "â€¢ SMOTE + Tomek Links: Combines oversampling with undersampling\n",
    "â€¢ SMOTE + ENN: Uses Edited Nearest Neighbours for cleaning\n",
    "â€¢ RandomOverSampler + RandomUnderSampler: Simple but effective combination\n",
    "\"\"\")\n",
    "\n",
    "# 1. Import advanced sampling libraries\n",
    "print(\"\\n1. IMPORTING ADVANCED SAMPLING LIBRARIES\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    from imblearn.over_sampling import BorderlineSMOTE, ADASYN, RandomOverSampler\n",
    "    from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours, RandomUnderSampler\n",
    "    from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "    print(\"âœ… All advanced sampling libraries imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸  Some libraries missing: {e}\")\n",
    "    print(\"Install with: pip install imbalanced-learn\")\n",
    "\n",
    "# 2. Create advanced sampling models\n",
    "print(\"\\n2. CREATING ADVANCED SAMPLING MODELS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Define advanced sampling techniques\n",
    "advanced_sampling_models = {\n",
    "    'BorderlineSMOTE': {\n",
    "        'sampler': BorderlineSMOTE(random_state=RANDOM_STATE, kind='borderline-1'),\n",
    "        'description': 'Focuses on borderline samples between classes'\n",
    "    },\n",
    "    'ADASYN': {\n",
    "        'sampler': ADASYN(random_state=RANDOM_STATE),\n",
    "        'description': 'Adaptive synthetic sampling for minority class'\n",
    "    },\n",
    "    'SMOTE_Tomek': {\n",
    "        'sampler': SMOTETomek(random_state=RANDOM_STATE),\n",
    "        'description': 'SMOTE + Tomek links cleaning'\n",
    "    },\n",
    "    'SMOTE_ENN': {\n",
    "        'sampler': SMOTEENN(random_state=RANDOM_STATE),\n",
    "        'description': 'SMOTE + Edited Nearest Neighbours cleaning'\n",
    "    },\n",
    "    'RandomCombined': {\n",
    "        'sampler': None,  # Will create custom pipeline\n",
    "        'description': 'Random over + under sampling combination'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ðŸ“Š ADVANCED SAMPLING TECHNIQUES:\")\n",
    "for name, config in advanced_sampling_models.items():\n",
    "    print(f\"   â€¢ {name}: {config['description']}\")\n",
    "\n",
    "# 3. Apply advanced sampling to baseline models only\n",
    "print(\"\\n3. APPLYING ADVANCED SAMPLING TO BASELINE MODELS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use only the baseline models (no advanced models)\n",
    "baseline_algorithms = {\n",
    "    'LogReg': LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
    "    'kNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "# Create pipelines for each combination\n",
    "advanced_sampling_pipes = {}\n",
    "\n",
    "for sampler_name, sampler_config in advanced_sampling_models.items():\n",
    "    for model_name, model in baseline_algorithms.items():\n",
    "        pipe_name = f\"{model_name}_{sampler_name}\"\n",
    "        \n",
    "        if sampler_name == 'RandomCombined':\n",
    "            # Custom pipeline with random over + under sampling\n",
    "            pipeline = ImbPipeline([\n",
    "                ('pre', preprocess_reduced),\n",
    "                ('over', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy=0.7)),\n",
    "                ('under', RandomUnderSampler(random_state=RANDOM_STATE, sampling_strategy=0.8)),\n",
    "                ('clf', model)\n",
    "            ])\n",
    "        else:\n",
    "            # Standard pipeline with advanced sampler\n",
    "            pipeline = ImbPipeline([\n",
    "                ('pre', preprocess_reduced),\n",
    "                ('sampler', sampler_config['sampler']),\n",
    "                ('clf', model)\n",
    "            ])\n",
    "        \n",
    "        advanced_sampling_pipes[pipe_name] = pipeline\n",
    "        print(f\"   âœ… Created {pipe_name}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nTotal advanced sampling models created: {len(advanced_sampling_pipes)}\")\n",
    "\n",
    "# 4. Train and evaluate advanced sampling models\n",
    "print(\"\\n4. TRAINING AND EVALUATING ADVANCED SAMPLING MODELS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Train all advanced sampling models\n",
    "for name, pipe in advanced_sampling_pipes.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    try:\n",
    "        pipe.fit(X_train, y_train)\n",
    "        confusion_matrix_plot(name, pipe, X_test, y_test)\n",
    "        evaluate_model(name, pipe, X_test, y_test, results)\n",
    "        print(f\"   âœ… {name} completed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ {name} failed: {e}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "# Get advanced sampling results\n",
    "advanced_sampling_results = pd.DataFrame(results[-len(advanced_sampling_pipes):]).set_index('Model').round(3)\n",
    "\n",
    "\n",
    "print(f\"\\nðŸ“Š ADVANCED SAMPLING RESULTS:\")\n",
    "display(advanced_sampling_results)\n",
    "\n",
    "# ADD THE MISSING CLASS-SPECIFIC VISUALIZATIONS HERE\n",
    "# Plot advanced sampling performance for Class 0 (No Churn)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "advanced_sampling_results[['Accuracy', 'Precision_0', 'Recall_0', 'F1_0']].plot.bar(ax=ax)\n",
    "ax.set_title('Advanced Sampling Model Performance - Class 0 (No Churn)')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot advanced sampling performance for Class 1 (Churn)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "advanced_sampling_results[['Accuracy', 'Precision_1', 'Recall_1', 'F1_1']].plot.bar(ax=ax)\n",
    "ax.set_title('Advanced Sampling Model Performance - Class 1 (Churn)')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Compare with previous baseline models\n",
    "print(\"\\n5. COMPARING WITH PREVIOUS BASELINE MODELS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get best models from baseline categories for comparison\n",
    "best_baseline = baseline_results.loc[baseline_results['F1_Weighted'].idxmax()]\n",
    "best_balanced_smote = balanced_results.loc[balanced_results['F1_Weighted'].idxmax()]\n",
    "best_advanced_sampling = advanced_sampling_results.loc[advanced_sampling_results['F1_Weighted'].idxmax()]\n",
    "\n",
    "# Create comparison table\n",
    "sampling_comparison = pd.DataFrame({\n",
    "    'Best_Baseline': best_baseline,\n",
    "    'Best_Basic_SMOTE': best_balanced_smote,\n",
    "    'Best_Advanced_Sampling': best_advanced_sampling\n",
    "}).T\n",
    "\n",
    "print(\"ðŸ“Š SAMPLING TECHNIQUES COMPARISON:\")\n",
    "display(sampling_comparison[['Accuracy', 'F1_0', 'F1_1', 'F1_Macro', 'F1_Weighted', 'ROC_AUC', 'PR_AUC']].round(3))\n",
    "\n",
    "# Calculate improvements\n",
    "print(\"\\nðŸ“ˆ IMPROVEMENTS OVER BASIC SMOTE:\")\n",
    "for metric in ['F1_Weighted', 'F1_1', 'ROC_AUC', 'PR_AUC']:\n",
    "    baseline_smote = best_balanced_smote[metric]\n",
    "    advanced_sampling = best_advanced_sampling[metric]\n",
    "    improvement = advanced_sampling - baseline_smote\n",
    "    improvement_pct = (improvement / baseline_smote) * 100\n",
    "    print(f\"   {metric}: {improvement:+.4f} ({improvement_pct:+.2f}%)\")\n",
    "\n",
    "# 6. Detailed analysis by sampling technique\n",
    "print(\"\\n6. DETAILED ANALYSIS BY SAMPLING TECHNIQUE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Group results by sampling technique\n",
    "sampling_technique_performance = {}\n",
    "\n",
    "for sampler_name in advanced_sampling_models.keys():\n",
    "    technique_results = []\n",
    "    for model_result in advanced_sampling_results.iterrows():\n",
    "        model_name = model_result[0]\n",
    "        if sampler_name in model_name:\n",
    "            technique_results.append(model_result[1])\n",
    "    \n",
    "    if technique_results:\n",
    "        # Convert to DataFrame for easier analysis\n",
    "        technique_df = pd.DataFrame(technique_results)\n",
    "        sampling_technique_performance[sampler_name] = {\n",
    "            'mean_f1_weighted': technique_df['F1_Weighted'].mean(),\n",
    "            'mean_f1_churn': technique_df['F1_1'].mean(),\n",
    "            'mean_roc_auc': technique_df['ROC_AUC'].mean(),\n",
    "            'std_f1_weighted': technique_df['F1_Weighted'].std(),\n",
    "            'best_f1_weighted': technique_df['F1_Weighted'].max(),\n",
    "            'count': len(technique_results)\n",
    "        }\n",
    "\n",
    "# Create performance summary\n",
    "technique_summary = pd.DataFrame(sampling_technique_performance).T\n",
    "print(\"ðŸ“Š PERFORMANCE BY SAMPLING TECHNIQUE:\")\n",
    "display(technique_summary.round(4))\n",
    "\n",
    "# 7. Visualizations for advanced sampling techniques\n",
    "print(\"\\n7. ADVANCED SAMPLING VISUALIZATIONS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create comprehensive visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Plot 1: F1_Weighted comparison by technique\n",
    "ax1 = axes[0, 0]\n",
    "techniques = list(sampling_technique_performance.keys())\n",
    "f1_means = [sampling_technique_performance[tech]['mean_f1_weighted'] for tech in techniques]\n",
    "f1_stds = [sampling_technique_performance[tech]['std_f1_weighted'] for tech in techniques]\n",
    "\n",
    "bars = ax1.bar(techniques, f1_means, yerr=f1_stds, capsize=5, alpha=0.8, color='lightblue')\n",
    "ax1.set_ylabel('F1_Weighted Score')\n",
    "ax1.set_title('Average F1_Weighted by Sampling Technique')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 2: Churn detection (F1_1) comparison\n",
    "ax2 = axes[0, 1]\n",
    "churn_f1_means = [sampling_technique_performance[tech]['mean_f1_churn'] for tech in techniques]\n",
    "\n",
    "bars2 = ax2.bar(techniques, churn_f1_means, alpha=0.8, color='lightcoral')\n",
    "ax2.set_ylabel('F1_1 Score (Churn Detection)')\n",
    "ax2.set_title('Average Churn Detection by Sampling Technique')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 3: ROC AUC comparison\n",
    "ax3 = axes[0, 2]\n",
    "roc_means = [sampling_technique_performance[tech]['mean_roc_auc'] for tech in techniques]\n",
    "\n",
    "bars3 = ax3.bar(techniques, roc_means, alpha=0.8, color='lightgreen')\n",
    "ax3.set_ylabel('ROC AUC Score')\n",
    "ax3.set_title('Average ROC AUC by Sampling Technique')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars3:\n",
    "    height = bar.get_height()\n",
    "    ax3.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 4: Best performers comparison (baseline categories only)\n",
    "ax4 = axes[1, 0]\n",
    "comparison_models = ['Baseline', 'Basic SMOTE', 'Advanced Sampling']\n",
    "comparison_scores = [\n",
    "    best_baseline['F1_Weighted'],\n",
    "    best_balanced_smote['F1_Weighted'],\n",
    "    best_advanced_sampling['F1_Weighted']\n",
    "]\n",
    "\n",
    "bars4 = ax4.bar(comparison_models, comparison_scores, \n",
    "                color=['lightblue', 'orange', 'lightgreen'], alpha=0.8)\n",
    "ax4.set_ylabel('F1_Weighted Score')\n",
    "ax4.set_title('Best Model Comparison Across Baseline Categories')\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars4:\n",
    "    height = bar.get_height()\n",
    "    ax4.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# Plot 5: Algorithm performance within advanced sampling\n",
    "ax5 = axes[1, 1]\n",
    "algorithm_performance = {}\n",
    "for result_name, result_data in advanced_sampling_results.iterrows():\n",
    "    algorithm = result_name.split('_')[0]  # Extract algorithm name\n",
    "    if algorithm not in algorithm_performance:\n",
    "        algorithm_performance[algorithm] = []\n",
    "    algorithm_performance[algorithm].append(result_data['F1_Weighted'])\n",
    "\n",
    "algorithms = list(algorithm_performance.keys())\n",
    "avg_scores = [np.mean(algorithm_performance[alg]) for alg in algorithms]\n",
    "\n",
    "bars5 = ax5.bar(algorithms, avg_scores, alpha=0.8, color='gold')\n",
    "ax5.set_ylabel('Average F1_Weighted')\n",
    "ax5.set_title('Algorithm Performance with Advanced Sampling')\n",
    "ax5.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars5:\n",
    "    height = bar.get_height()\n",
    "    ax5.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Plot 6: Variance analysis\n",
    "ax6 = axes[1, 2]\n",
    "technique_variances = [sampling_technique_performance[tech]['std_f1_weighted'] for tech in techniques]\n",
    "\n",
    "bars6 = ax6.bar(techniques, technique_variances, alpha=0.8, color='purple')\n",
    "ax6.set_ylabel('F1_Weighted Standard Deviation')\n",
    "ax6.set_title('Performance Variance by Sampling Technique')\n",
    "ax6.tick_params(axis='x', rotation=45)\n",
    "ax6.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars6:\n",
    "    height = bar.get_height()\n",
    "    ax6.annotate(f'{height:.4f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Statistical significance testing\n",
    "print(\"\\n8. STATISTICAL SIGNIFICANCE TESTING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Compare advanced sampling vs basic SMOTE\n",
    "basic_smote_f1 = []\n",
    "advanced_sampling_f1 = []\n",
    "\n",
    "# Collect F1_Weighted scores for statistical comparison\n",
    "for model_name, model_results in balanced_results.iterrows():\n",
    "    basic_smote_f1.append(model_results['F1_Weighted'])\n",
    "\n",
    "for model_name, model_results in advanced_sampling_results.iterrows():\n",
    "    advanced_sampling_f1.append(model_results['F1_Weighted'])\n",
    "\n",
    "# Perform statistical tests\n",
    "if len(basic_smote_f1) > 1 and len(advanced_sampling_f1) > 1:\n",
    "    # Mann-Whitney U test (non-parametric)\n",
    "    statistic, p_value = stats.mannwhitneyu(advanced_sampling_f1, basic_smote_f1, alternative='greater')\n",
    "    \n",
    "    print(f\"ðŸ“Š STATISTICAL SIGNIFICANCE TEST:\")\n",
    "    print(f\"   Mann-Whitney U statistic: {statistic:.3f}\")\n",
    "    print(f\"   P-value: {p_value:.6f}\")\n",
    "    print(f\"   Significant improvement: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "    \n",
    "    # Effect size (Cohen's d approximation)\n",
    "    pooled_std = np.sqrt((np.std(basic_smote_f1)**2 + np.std(advanced_sampling_f1)**2) / 2)\n",
    "    cohens_d = (np.mean(advanced_sampling_f1) - np.mean(basic_smote_f1)) / pooled_std\n",
    "    print(f\"   Effect size (Cohen's d): {cohens_d:.3f}\")\n",
    "    \n",
    "    if abs(cohens_d) < 0.2:\n",
    "        effect_size = \"Small\"\n",
    "    elif abs(cohens_d) < 0.5:\n",
    "        effect_size = \"Medium\"\n",
    "    else:\n",
    "        effect_size = \"Large\"\n",
    "    print(f\"   Effect size interpretation: {effect_size}\")\n",
    "\n",
    "# 9. Winner analysis for advanced sampling\n",
    "model_sources.append(('Advanced_Sampling', advanced_sampling_pipes))\n",
    "\n",
    "print(\"\\n9. ADVANCED SAMPLING WINNER ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Find the best advanced sampling model\n",
    "best_advanced_sampling_name = advanced_sampling_results['F1_Weighted'].idxmax()\n",
    "best_advanced_sampling_metrics = advanced_sampling_results.loc[best_advanced_sampling_name]\n",
    "\n",
    "print(f\"ðŸ† BEST ADVANCED SAMPLING MODEL: {best_advanced_sampling_name}\")\n",
    "print(f\"   F1_Weighted: {best_advanced_sampling_metrics['F1_Weighted']:.4f}\")\n",
    "print(f\"   F1_Churn: {best_advanced_sampling_metrics['F1_1']:.4f}\")\n",
    "print(f\"   ROC_AUC: {best_advanced_sampling_metrics['ROC_AUC']:.4f}\")\n",
    "print(f\"   PR_AUC: {best_advanced_sampling_metrics['PR_AUC']:.4f}\")\n",
    "\n",
    "# Compare with best baseline and best basic SMOTE\n",
    "print(f\"\\nðŸ“Š COMPARISON WITH BEST BASELINE APPROACHES:\")\n",
    "print(f\"   Best Baseline: {best_baseline.name} (F1_Weighted: {best_baseline['F1_Weighted']:.4f})\")\n",
    "print(f\"   Best Basic SMOTE: {best_balanced_smote.name} (F1_Weighted: {best_balanced_smote['F1_Weighted']:.4f})\")\n",
    "print(f\"   Best Advanced Sampling: {best_advanced_sampling_name} (F1_Weighted: {best_advanced_sampling_metrics['F1_Weighted']:.4f})\")\n",
    "\n",
    "improvement_vs_baseline = best_advanced_sampling_metrics['F1_Weighted'] - best_baseline['F1_Weighted']\n",
    "improvement_vs_smote = best_advanced_sampling_metrics['F1_Weighted'] - best_balanced_smote['F1_Weighted']\n",
    "\n",
    "print(f\"   Improvement vs Baseline: {improvement_vs_baseline:+.4f}\")\n",
    "print(f\"   Improvement vs Basic SMOTE: {improvement_vs_smote:+.4f}\")\n",
    "\n",
    "# 10. Business recommendations for advanced sampling\n",
    "print(\"\\n10. BUSINESS RECOMMENDATIONS FOR ADVANCED SAMPLING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nðŸŽ¯ KEY FINDINGS:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Analyze which sampling technique performed best\n",
    "best_technique = max(sampling_technique_performance.items(), \n",
    "                    key=lambda x: x[1]['mean_f1_weighted'])\n",
    "\n",
    "print(f\"1. BEST SAMPLING TECHNIQUE: {best_technique[0]}\")\n",
    "print(f\"   Average F1_Weighted: {best_technique[1]['mean_f1_weighted']:.4f}\")\n",
    "print(f\"   Average Churn Detection: {best_technique[1]['mean_f1_churn']:.4f}\")\n",
    "\n",
    "print(f\"\\n2. PERFORMANCE IMPROVEMENTS:\")\n",
    "baseline_avg = best_baseline['F1_Weighted']\n",
    "advanced_avg = technique_summary['mean_f1_weighted'].max()\n",
    "improvement = advanced_avg - baseline_avg\n",
    "print(f\"   vs Baseline: +{improvement:.4f} ({improvement/baseline_avg*100:.2f}%)\")\n",
    "\n",
    "smote_avg = best_balanced_smote['F1_Weighted']\n",
    "vs_smote = advanced_avg - smote_avg\n",
    "print(f\"   vs Basic SMOTE: +{vs_smote:.4f} ({vs_smote/smote_avg*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n3. CONSISTENCY ANALYSIS:\")\n",
    "most_consistent = min(sampling_technique_performance.items(), \n",
    "                     key=lambda x: x[1]['std_f1_weighted'])\n",
    "print(f\"   Most Consistent: {most_consistent[0]} (Std: {most_consistent[1]['std_f1_weighted']:.4f})\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ STRATEGIC RECOMMENDATIONS:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(\"1. SAMPLING STRATEGY SELECTION:\")\n",
    "if best_technique[1]['mean_f1_weighted'] > smote_avg:\n",
    "    print(f\"   âœ… Adopt {best_technique[0]} for baseline model pipelines\")\n",
    "    print(f\"   â€¢ Superior performance over basic SMOTE\")\n",
    "    print(f\"   â€¢ Better handling of class imbalance nuances\")\n",
    "else:\n",
    "    print(\"   â„¹ï¸  Basic SMOTE remains competitive\")\n",
    "    print(\"   â€¢ Consider computational overhead vs. performance gains\")\n",
    "\n",
    "print(f\"\\n2. MODEL PIPELINE OPTIMIZATION:\")\n",
    "print(\"   â€¢ Integrate advanced sampling into preprocessing pipeline\")\n",
    "print(\"   â€¢ Test multiple sampling techniques during baseline model selection\")\n",
    "print(\"   â€¢ Monitor sampling effectiveness on new data\")\n",
    "\n",
    "print(f\"\\n3. PREPARATION FOR ADVANCED MODELS:\")\n",
    "print(f\"   â€¢ These sampling techniques can be applied to future advanced models\")\n",
    "print(f\"   â€¢ Current baseline results establish foundation for comparison\")\n",
    "print(f\"   â€¢ {best_technique[0]} shows most promise for future implementation\")\n",
    "\n",
    "# Create final results summary for baseline models only\n",
    "print(\"\\n11. UPDATING BASELINE MODEL RESULTS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create comprehensive baseline results including advanced sampling\n",
    "all_baseline_results = pd.concat([\n",
    "    baseline_results,\n",
    "    balanced_results,\n",
    "    advanced_sampling_results\n",
    "])\n",
    "\n",
    "all_baseline_results['Model_Type'] = all_baseline_results.index.map(\n",
    "    lambda x: 'Advanced_Sampling' if any(technique in x for technique in advanced_sampling_models.keys())\n",
    "             else 'Basic_SMOTE' if 'SMOTE' in x\n",
    "             else 'Baseline'\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š COMPREHENSIVE BASELINE MODEL RESULTS (Top 10):\")\n",
    "top_baseline_results = all_baseline_results.sort_values('F1_Weighted', ascending=False).head(10)\n",
    "display(top_baseline_results[['Model_Type', 'Accuracy', 'F1_0', 'F1_1', 'F1_Weighted', 'ROC_AUC']].round(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ADVANCED SAMPLING TECHNIQUES (BASELINE MODELS) ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ… Advanced sampling techniques have been thoroughly evaluated for baseline models.\n",
    "   Key outcomes:\n",
    "\n",
    "   â€¢ {len(advanced_sampling_pipes)} advanced sampling models trained and evaluated\n",
    "   â€¢ Best technique: {best_technique[0]} with {best_technique[1]['mean_f1_weighted']:.4f} F1_Weighted\n",
    "   â€¢ Baseline model performance enhanced through sophisticated sampling\n",
    "   â€¢ Foundation established for future advanced model development\n",
    "\n",
    "   Ready to proceed with advanced models when needed.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09703e00",
   "metadata": {},
   "source": [
    "### 5.5 Cost-Sensitive Learning\n",
    "\n",
    "This approach is likely to give you the best next improvement because it doesn't alter your data but optimizes the learning process for imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb56ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6.4 Cost-Sensitive Learning\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COST-SENSITIVE LEARNING - ADVANCED BALANCING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "Cost-sensitive learning adjusts model training to account for the different costs\n",
    "of misclassifying each class, often more effective than resampling techniques.\n",
    "\"\"\")\n",
    "\n",
    "# Calculate class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', \n",
    "                                   classes=np.unique(y_train), \n",
    "                                   y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "print(f\"Calculated class weights: {class_weight_dict}\")\n",
    "\n",
    "# Create cost-sensitive models\n",
    "cost_sensitive_models = {\n",
    "    'LogReg_CostSensitive': LogisticRegression(class_weight='balanced', \n",
    "                                              max_iter=1000, random_state=RANDOM_STATE),\n",
    "    'RF_CostSensitive': RandomForestClassifier(class_weight='balanced', \n",
    "                                              n_estimators=300, random_state=RANDOM_STATE),\n",
    "    'DecisionTree_CostSensitive': DecisionTreeClassifier(class_weight='balanced', \n",
    "                                                        random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "if has_xgb:\n",
    "    cost_sensitive_models['XGBoost_CostSensitive'] = XGBClassifier(\n",
    "        scale_pos_weight=class_weights[1]/class_weights[0],\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "# Train cost-sensitive models\n",
    "cost_sensitive_pipes = {}\n",
    "for name, model in cost_sensitive_models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('pre', preprocess_reduced),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    cost_sensitive_pipes[name] = pipeline\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    confusion_matrix_plot(name, pipe, X_test, y_test)\n",
    "    evaluate_model(name, pipeline, X_test, y_test, results)\n",
    "    \n",
    "\n",
    "\n",
    "# Display results\n",
    "cost_sensitive_results = pd.DataFrame(results[-len(cost_sensitive_pipes):]).set_index('Model').round(3)\n",
    "print(\"\\nðŸ“Š COST-SENSITIVE MODEL RESULTS:\")\n",
    "display(cost_sensitive_results)\n",
    "\n",
    "# Plot cost-sensitive performance for Class 0 (No Churn)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "cost_sensitive_results[['Accuracy', 'Precision_0', 'Recall_0', 'F1_0']].plot.bar(ax=ax)\n",
    "ax.set_title('Cost-Sensitive Model Performance - Class 0 (No Churn)')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot cost-sensitive performance for Class 1 (Churn)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "cost_sensitive_results[['Accuracy', 'Precision_1', 'Recall_1', 'F1_1']].plot.bar(ax=ax)\n",
    "ax.set_title('Cost-Sensitive Model Performance - Class 1 (Churn)')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Overall cost-sensitive performance comparison\n",
    "cost_sensitive_results[['Accuracy', 'F1_Macro', 'F1_Weighted', 'ROC_AUC', 'PR_AUC']].plot.bar(figsize=(12,6))\n",
    "plt.title('Cost-Sensitive Model Overall Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0,1.05)\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare cost-sensitive with previous best models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COST-SENSITIVE vs PREVIOUS BEST MODELS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get best models from each category for comparison\n",
    "best_baseline = baseline_results.loc[baseline_results['F1_Weighted'].idxmax()]\n",
    "best_balanced_smote = balanced_results.loc[balanced_results['F1_Weighted'].idxmax()]\n",
    "best_advanced_sampling = advanced_sampling_results.loc[advanced_sampling_results['F1_Weighted'].idxmax()] if 'advanced_sampling_results' in locals() else None\n",
    "best_cost_sensitive = cost_sensitive_results.loc[cost_sensitive_results['F1_Weighted'].idxmax()]\n",
    "\n",
    "# Create comparison table\n",
    "cost_sensitive_comparison = pd.DataFrame({\n",
    "    'Best_Baseline': best_baseline,\n",
    "    'Best_Balanced_SMOTE': best_balanced_smote,\n",
    "    'Best_Cost_Sensitive': best_cost_sensitive\n",
    "}).T\n",
    "\n",
    "if best_advanced_sampling is not None:\n",
    "    cost_sensitive_comparison = pd.DataFrame({\n",
    "        'Best_Baseline': best_baseline,\n",
    "        'Best_Balanced_SMOTE': best_balanced_smote,\n",
    "        'Best_Advanced_Sampling': best_advanced_sampling,\n",
    "        'Best_Cost_Sensitive': best_cost_sensitive\n",
    "    }).T\n",
    "\n",
    "print(\"ðŸ“Š BALANCING TECHNIQUES COMPARISON:\")\n",
    "display(cost_sensitive_comparison[['Accuracy', 'F1_0', 'F1_1', 'F1_Macro', 'F1_Weighted', 'ROC_AUC', 'PR_AUC']].round(3))\n",
    "\n",
    "# Calculate improvements over baseline\n",
    "print(\"\\nðŸ“ˆ IMPROVEMENTS OVER BASELINE:\")\n",
    "for metric in ['F1_Weighted', 'F1_1', 'ROC_AUC', 'PR_AUC']:\n",
    "    baseline_score = best_baseline[metric]\n",
    "    cost_sensitive_score = best_cost_sensitive[metric]\n",
    "    improvement = cost_sensitive_score - baseline_score\n",
    "    improvement_pct = (improvement / baseline_score) * 100\n",
    "    print(f\"   {metric}: {improvement:+.4f} ({improvement_pct:+.2f}%)\")\n",
    "\n",
    "# Detailed analysis by algorithm\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"COST-SENSITIVE ANALYSIS BY ALGORITHM\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Group results by algorithm\n",
    "algorithm_performance = {}\n",
    "for result_name, result_data in cost_sensitive_results.iterrows():\n",
    "    algorithm = result_name.replace('_CostSensitive', '')\n",
    "    algorithm_performance[algorithm] = result_data\n",
    "\n",
    "print(\"\\nðŸ“Š ALGORITHM PERFORMANCE WITH COST-SENSITIVE LEARNING:\")\n",
    "algorithm_comparison_df = pd.DataFrame(algorithm_performance).T\n",
    "display(algorithm_comparison_df[['Accuracy', 'F1_0', 'F1_1', 'F1_Weighted', 'ROC_AUC']].round(3))\n",
    "\n",
    "# Visualization comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: F1_Weighted comparison across techniques\n",
    "ax1 = axes[0, 0]\n",
    "models = ['Baseline', 'Balanced SMOTE', 'Cost-Sensitive']\n",
    "f1_scores = [best_baseline['F1_Weighted'], best_balanced_smote['F1_Weighted'], best_cost_sensitive['F1_Weighted']]\n",
    "colors = ['lightblue', 'lightgreen', 'orange']\n",
    "\n",
    "if best_advanced_sampling is not None:\n",
    "    models.append('Advanced Sampling')\n",
    "    f1_scores.append(best_advanced_sampling['F1_Weighted'])\n",
    "    colors.append('lightcoral')\n",
    "\n",
    "bars1 = ax1.bar(models, f1_scores, color=colors, alpha=0.8)\n",
    "ax1.set_ylabel('F1_Weighted Score')\n",
    "ax1.set_title('F1_Weighted Comparison Across Techniques')\n",
    "ax1.set_ylim(0, 1.05)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Plot 2: Churn detection (F1_1) comparison\n",
    "ax2 = axes[0, 1]\n",
    "churn_f1_scores = [best_baseline['F1_1'], best_balanced_smote['F1_1'], best_cost_sensitive['F1_1']]\n",
    "\n",
    "if best_advanced_sampling is not None:\n",
    "    churn_f1_scores.append(best_advanced_sampling['F1_1'])\n",
    "\n",
    "bars2 = ax2.bar(models, churn_f1_scores, color=colors, alpha=0.8)\n",
    "ax2.set_ylabel('F1_1 Score (Churn Detection)')\n",
    "ax2.set_title('Churn Detection Comparison')\n",
    "ax2.set_ylim(0, 1.05)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Plot 3: Algorithm performance with cost-sensitive learning\n",
    "ax3 = axes[1, 0]\n",
    "algorithms = list(algorithm_performance.keys())\n",
    "algo_f1_scores = [algorithm_performance[algo]['F1_Weighted'] for algo in algorithms]\n",
    "\n",
    "bars3 = ax3.bar(algorithms, algo_f1_scores, alpha=0.8, color='gold')\n",
    "ax3.set_ylabel('F1_Weighted Score')\n",
    "ax3.set_title('Algorithm Performance with Cost-Sensitive Learning')\n",
    "ax3.set_ylim(0, 1.05)\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars3:\n",
    "    height = bar.get_height()\n",
    "    ax3.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Plot 4: Precision-Recall trade-off for Class 1\n",
    "ax4 = axes[1, 1]\n",
    "precision_1 = [best_baseline['Precision_1'], best_balanced_smote['Precision_1'], best_cost_sensitive['Precision_1']]\n",
    "recall_1 = [best_baseline['Recall_1'], best_balanced_smote['Recall_1'], best_cost_sensitive['Recall_1']]\n",
    "\n",
    "if best_advanced_sampling is not None:\n",
    "    precision_1.append(best_advanced_sampling['Precision_1'])\n",
    "    recall_1.append(best_advanced_sampling['Recall_1'])\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    ax4.scatter(recall_1[i], precision_1[i], s=150, alpha=0.8, color=colors[i], label=model)\n",
    "\n",
    "ax4.set_xlabel('Recall - Class 1 (Churn)')\n",
    "ax4.set_ylabel('Precision - Class 1 (Churn)')\n",
    "ax4.set_title('Precision-Recall Trade-off for Churn Detection')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.set_xlim(0, 1.05)\n",
    "ax4.set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Winner analysis for cost-sensitive learning\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ† COST-SENSITIVE LEARNING WINNER ANALYSIS ðŸ†\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find the best cost-sensitive model\n",
    "best_cost_sensitive_name = cost_sensitive_results['F1_Weighted'].idxmax()\n",
    "best_cost_sensitive_metrics = cost_sensitive_results.loc[best_cost_sensitive_name]\n",
    "\n",
    "model_sources.append(('Cost_Sensitive', cost_sensitive_pipes))\n",
    "\n",
    "print(f\"ðŸ† BEST COST-SENSITIVE MODEL: {best_cost_sensitive_name}\")\n",
    "print(f\"   F1_Weighted: {best_cost_sensitive_metrics['F1_Weighted']:.4f}\")\n",
    "print(f\"   F1_Churn: {best_cost_sensitive_metrics['F1_1']:.4f}\")\n",
    "print(f\"   ROC_AUC: {best_cost_sensitive_metrics['ROC_AUC']:.4f}\")\n",
    "print(f\"   PR_AUC: {best_cost_sensitive_metrics['PR_AUC']:.4f}\")\n",
    "\n",
    "# Compare with best approaches so far\n",
    "print(f\"\\nðŸ“Š COMPARISON WITH BEST APPROACHES:\")\n",
    "print(f\"   Best Baseline: {best_baseline.name} (F1_Weighted: {best_baseline['F1_Weighted']:.4f})\")\n",
    "print(f\"   Best Balanced SMOTE: {best_balanced_smote.name} (F1_Weighted: {best_balanced_smote['F1_Weighted']:.4f})\")\n",
    "if best_advanced_sampling is not None:\n",
    "    print(f\"   Best Advanced Sampling: {best_advanced_sampling.name} (F1_Weighted: {best_advanced_sampling['F1_Weighted']:.4f})\")\n",
    "print(f\"   Best Cost-Sensitive: {best_cost_sensitive_name} (F1_Weighted: {best_cost_sensitive_metrics['F1_Weighted']:.4f})\")\n",
    "\n",
    "# Business recommendations for cost-sensitive learning\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ¯ COST-SENSITIVE LEARNING BUSINESS RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Determine best overall approach\n",
    "all_approaches = [\n",
    "    ('Baseline', best_baseline['F1_Weighted']),\n",
    "    ('Balanced SMOTE', best_balanced_smote['F1_Weighted']),\n",
    "    ('Cost-Sensitive', best_cost_sensitive_metrics['F1_Weighted'])\n",
    "]\n",
    "\n",
    "if best_advanced_sampling is not None:\n",
    "    all_approaches.append(('Advanced Sampling', best_advanced_sampling['F1_Weighted']))\n",
    "\n",
    "best_approach = max(all_approaches, key=lambda x: x[1])\n",
    "\n",
    "print(f\"\\nâœ… RECOMMENDED APPROACH: {best_approach[0]}\")\n",
    "print(f\"   F1_Weighted Score: {best_approach[1]:.4f}\")\n",
    "\n",
    "if best_approach[0] == 'Cost-Sensitive':\n",
    "    print(f\"\\nðŸ’¡ COST-SENSITIVE LEARNING ADVANTAGES:\")\n",
    "    print(\"   â€¢ No synthetic data generation required\")\n",
    "    print(\"   â€¢ Preserves original data distribution\")\n",
    "    print(\"   â€¢ Computationally efficient\")\n",
    "    print(\"   â€¢ Directly incorporates business costs of misclassification\")\n",
    "    print(\"   â€¢ Easy to implement and maintain\")\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ IMPLEMENTATION RECOMMENDATIONS:\")\n",
    "    print(\"   â€¢ Deploy cost-sensitive learning for production models\")\n",
    "    print(\"   â€¢ Monitor class weight effectiveness over time\")\n",
    "    print(\"   â€¢ Consider adjusting class weights based on business cost changes\")\n",
    "    print(\"   â€¢ Combine with threshold optimization for maximum impact\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\nðŸ’¡ KEY INSIGHTS:\")\n",
    "    print(f\"   â€¢ Cost-sensitive learning performed well but was outperformed by {best_approach[0]}\")\n",
    "    print(\"   â€¢ Consider cost-sensitive learning as a backup approach\")\n",
    "    print(\"   â€¢ Useful when computational resources are limited\")\n",
    "    print(\"   â€¢ Good baseline for comparing more complex techniques\")\n",
    "\n",
    "print(f\"\\nðŸ“Š COST-SENSITIVE LEARNING SUMMARY:\")\n",
    "print(f\"   â€¢ Models trained: {len(cost_sensitive_results)}\")\n",
    "print(f\"   â€¢ Best performer: {best_cost_sensitive_name}\")\n",
    "print(f\"   â€¢ Performance vs baseline: {best_cost_sensitive_metrics['F1_Weighted'] - best_baseline['F1_Weighted']:+.4f}\")\n",
    "print(f\"   â€¢ Churn detection improvement: {best_cost_sensitive_metrics['F1_1'] - best_baseline['F1_1']:+.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COST-SENSITIVE LEARNING ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ… Cost-sensitive learning has been thoroughly evaluated.\n",
    "   Key outcomes:\n",
    "\n",
    "   â€¢ {len(cost_sensitive_pipes)} cost-sensitive models trained and evaluated\n",
    "   â€¢ Best approach: {best_cost_sensitive_name} with {best_cost_sensitive_metrics['F1_Weighted']:.4f} F1_Weighted\n",
    "   â€¢ Provides efficient alternative to data resampling techniques\n",
    "   â€¢ Ready for integration into production pipeline\n",
    "\n",
    "   Proceeding with advanced model development...\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a52bb1",
   "metadata": {},
   "source": [
    "### 5.6 Balancing Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fba370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5 Complete Balancing Techniques Comparison and Winner Analysis\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPLETE BALANCING TECHNIQUES COMPARISON AND WINNER ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This section provides a comprehensive comparison of ALL balancing techniques explored:\n",
    "â€¢ Baseline (No Balancing)\n",
    "â€¢ Basic SMOTE Balancing\n",
    "â€¢ Advanced Sampling Techniques (BorderlineSMOTE, ADASYN, SMOTE+Tomek, SMOTE+ENN)\n",
    "â€¢ Cost-Sensitive Learning\n",
    "â€¢ Segment-Specific Balancing\n",
    "\n",
    "We'll determine the ultimate winner across all approaches and provide final recommendations.\n",
    "\"\"\")\n",
    "\n",
    "# 1. Collect all balancing results\n",
    "print(\"\\n1. COLLECTING ALL BALANCING RESULTS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Initialize comprehensive comparison dictionary\n",
    "all_balancing_results = {}\n",
    "\n",
    "# Add baseline results\n",
    "print(\"ðŸ“Š Adding Baseline Results...\")\n",
    "for model_name, metrics in baseline_results.iterrows():\n",
    "    all_balancing_results[f\"Baseline_{model_name}\"] = {\n",
    "        'Technique': 'Baseline',\n",
    "        'Algorithm': model_name,\n",
    "        'Model_Name': model_name,\n",
    "        'Accuracy': float(metrics['Accuracy']),\n",
    "        'F1_0': float(metrics['F1_0']),\n",
    "        'F1_1': float(metrics['F1_1']),\n",
    "        'F1_Macro': float(metrics['F1_Macro']),\n",
    "        'F1_Weighted': float(metrics['F1_Weighted']),\n",
    "        'Precision_0': float(metrics['Precision_0']),\n",
    "        'Recall_0': float(metrics['Recall_0']),\n",
    "        'Precision_1': float(metrics['Precision_1']),\n",
    "        'Recall_1': float(metrics['Recall_1']),\n",
    "        'ROC_AUC': float(metrics['ROC_AUC']),\n",
    "        'PR_AUC': float(metrics['PR_AUC'])\n",
    "    }\n",
    "\n",
    "# Add balanced SMOTE results\n",
    "print(\"ðŸ“Š Adding Basic SMOTE Results...\")\n",
    "for model_name, metrics in balanced_results.iterrows():\n",
    "    algorithm = model_name.replace('_SMOTE', '')\n",
    "    all_balancing_results[f\"SMOTE_{algorithm}\"] = {\n",
    "        'Technique': 'Basic_SMOTE',\n",
    "        'Algorithm': algorithm,\n",
    "        'Model_Name': model_name,\n",
    "        'Accuracy': float(metrics['Accuracy']),\n",
    "        'F1_0': float(metrics['F1_0']),\n",
    "        'F1_1': float(metrics['F1_1']),\n",
    "        'F1_Macro': float(metrics['F1_Macro']),\n",
    "        'F1_Weighted': float(metrics['F1_Weighted']),\n",
    "        'Precision_0': float(metrics['Precision_0']),\n",
    "        'Recall_0': float(metrics['Recall_0']),\n",
    "        'Precision_1': float(metrics['Precision_1']),\n",
    "        'Recall_1': float(metrics['Recall_1']),\n",
    "        'ROC_AUC': float(metrics['ROC_AUC']),\n",
    "        'PR_AUC': float(metrics['PR_AUC'])\n",
    "    }\n",
    "\n",
    "# Add advanced sampling results if available\n",
    "if 'advanced_sampling_results' in locals():\n",
    "    print(\"ðŸ“Š Adding Advanced Sampling Results...\")\n",
    "    for model_name, metrics in advanced_sampling_results.iterrows():\n",
    "        # Extract technique and algorithm from model name\n",
    "        parts = model_name.split('_')\n",
    "        algorithm = parts[0]\n",
    "        technique = '_'.join(parts[1:])\n",
    "        \n",
    "        all_balancing_results[f\"AdvSampling_{model_name}\"] = {\n",
    "            'Technique': f'Advanced_{technique}',\n",
    "            'Algorithm': algorithm,\n",
    "            'Model_Name': model_name,\n",
    "            'Accuracy': float(metrics['Accuracy']),\n",
    "            'F1_0': float(metrics['F1_0']),\n",
    "            'F1_1': float(metrics['F1_1']),\n",
    "            'F1_Macro': float(metrics['F1_Macro']),\n",
    "            'F1_Weighted': float(metrics['F1_Weighted']),\n",
    "            'Precision_0': float(metrics['Precision_0']),\n",
    "            'Recall_0': float(metrics['Recall_0']),\n",
    "            'Precision_1': float(metrics['Precision_1']),\n",
    "            'Recall_1': float(metrics['Recall_1']),\n",
    "            'ROC_AUC': float(metrics['ROC_AUC']),\n",
    "            'PR_AUC': float(metrics['PR_AUC'])\n",
    "        }\n",
    "\n",
    "# Add cost-sensitive results if available\n",
    "if 'cost_sensitive_results' in locals():\n",
    "    print(\"ðŸ“Š Adding Cost-Sensitive Results...\")\n",
    "    for model_name, metrics in cost_sensitive_results.iterrows():\n",
    "        algorithm = model_name.replace('_CostSensitive', '')\n",
    "        all_balancing_results[f\"CostSensitive_{algorithm}\"] = {\n",
    "            'Technique': 'Cost_Sensitive',\n",
    "            'Algorithm': algorithm,\n",
    "            'Model_Name': model_name,\n",
    "            'Accuracy': float(metrics['Accuracy']),\n",
    "            'F1_0': float(metrics['F1_0']),\n",
    "            'F1_1': float(metrics['F1_1']),\n",
    "            'F1_Macro': float(metrics['F1_Macro']),\n",
    "            'F1_Weighted': float(metrics['F1_Weighted']),\n",
    "            'Precision_0': float(metrics['Precision_0']),\n",
    "            'Recall_0': float(metrics['Recall_0']),\n",
    "            'Precision_1': float(metrics['Precision_1']),\n",
    "            'Recall_1': float(metrics['Recall_1']),\n",
    "            'ROC_AUC': float(metrics['ROC_AUC']),\n",
    "            'PR_AUC': float(metrics['PR_AUC'])\n",
    "        }\n",
    "\n",
    "# Add segment-specific results if available\n",
    "if 'baseline_segment_results' in locals():\n",
    "    print(\"ðŸ“Š Adding Segment-Specific Results...\")\n",
    "    for model_name, metrics in baseline_segment_results.iterrows():\n",
    "        algorithm = model_name.replace('_SegmentBalanced', '')\n",
    "        all_balancing_results[f\"SegmentBalanced_{algorithm}\"] = {\n",
    "            'Technique': 'Segment_Specific',\n",
    "            'Algorithm': algorithm,\n",
    "            'Model_Name': model_name,\n",
    "            'Accuracy': float(metrics['Accuracy']),\n",
    "            'F1_0': float(metrics['F1_0']),\n",
    "            'F1_1': float(metrics['F1_1']),\n",
    "            'F1_Macro': float(metrics['F1_Macro']),\n",
    "            'F1_Weighted': float(metrics['F1_Weighted']),\n",
    "            'Precision_0': float(metrics['Precision_0']),\n",
    "            'Recall_0': float(metrics['Recall_0']),\n",
    "            'Precision_1': float(metrics['Precision_1']),\n",
    "            'Recall_1': float(metrics['Recall_1']),\n",
    "            'ROC_AUC': float(metrics['ROC_AUC']),\n",
    "            'PR_AUC': float(metrics['PR_AUC'])\n",
    "        }\n",
    "\n",
    "# Convert to DataFrame\n",
    "complete_balancing_df = pd.DataFrame(all_balancing_results).T\n",
    "\n",
    "print(f\"âœ… Collected {len(complete_balancing_df)} total model results across all balancing techniques\")\n",
    "\n",
    "# Display unique techniques found\n",
    "unique_techniques = complete_balancing_df['Technique'].unique()\n",
    "print(f\"ðŸ“Š Balancing techniques included: {list(unique_techniques)}\")\n",
    "for technique in unique_techniques:\n",
    "    count = (complete_balancing_df['Technique'] == technique).sum()\n",
    "    print(f\"   â€¢ {technique}: {count} models\")\n",
    "\n",
    "# 2. Comprehensive Performance Analysis\n",
    "print(\"\\n2. COMPREHENSIVE PERFORMANCE ANALYSIS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(\"ðŸ“‹ TOP 15 MODELS ACROSS ALL BALANCING TECHNIQUES:\")\n",
    "top_15_all = complete_balancing_df.sort_values('F1_Weighted', ascending=False).head(15)\n",
    "display(top_15_all[['Technique', 'Algorithm', 'Accuracy', 'F1_0', 'F1_1', 'F1_Weighted', 'ROC_AUC', 'PR_AUC']].round(3))\n",
    "\n",
    "# 3. Technique-by-Technique Analysis\n",
    "print(\"\\n3. TECHNIQUE-BY-TECHNIQUE PERFORMANCE ANALYSIS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "technique_summary = {}\n",
    "for technique in unique_techniques:\n",
    "    technique_models = complete_balancing_df[complete_balancing_df['Technique'] == technique]\n",
    "    \n",
    "    technique_summary[technique] = {\n",
    "        'Count': len(technique_models),\n",
    "        'Best_F1_Weighted': float(technique_models['F1_Weighted'].max()),\n",
    "        'Avg_F1_Weighted': float(technique_models['F1_Weighted'].mean()),\n",
    "        'Best_F1_Churn': float(technique_models['F1_1'].max()),\n",
    "        'Avg_F1_Churn': float(technique_models['F1_1'].mean()),\n",
    "        'Best_ROC_AUC': float(technique_models['ROC_AUC'].max()),\n",
    "        'Avg_ROC_AUC': float(technique_models['ROC_AUC'].mean()),\n",
    "        'Best_Model': str(technique_models.loc[technique_models['F1_Weighted'].idxmax(), 'Model_Name']),\n",
    "        'Std_F1_Weighted': float(technique_models['F1_Weighted'].std())\n",
    "    }\n",
    "\n",
    "technique_summary_df = pd.DataFrame(technique_summary).T\n",
    "print(\"ðŸ“Š SUMMARY BY BALANCING TECHNIQUE:\")\n",
    "display(technique_summary_df.round(4))\n",
    "\n",
    "# 4. Create Individual Visualizations\n",
    "print(\"\\n4. COMPREHENSIVE BALANCING VISUALIZATIONS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Plot 1: Best F1_Weighted by Technique\n",
    "print(\"Plot 1: Best F1_Weighted by Technique\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "techniques = list(technique_summary.keys())\n",
    "best_f1_weighted = [technique_summary[tech]['Best_F1_Weighted'] for tech in techniques]\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(techniques)))\n",
    "\n",
    "bars = plt.bar(techniques, best_f1_weighted, color=colors, alpha=0.8)\n",
    "plt.ylabel('Best F1_Weighted Score')\n",
    "plt.title('Best F1_Weighted by Technique', fontweight='bold', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Average F1_Weighted by Technique with std\n",
    "print(\"Plot 2: Average F1_Weighted by Technique with Standard Deviation\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "avg_f1_weighted = [technique_summary[tech]['Avg_F1_Weighted'] for tech in techniques]\n",
    "std_f1_weighted = [technique_summary[tech]['Std_F1_Weighted'] for tech in techniques]\n",
    "\n",
    "bars = plt.bar(techniques, avg_f1_weighted, yerr=std_f1_weighted, \n",
    "                color=colors, alpha=0.8, capsize=5)\n",
    "plt.ylabel('Average F1_Weighted Score')\n",
    "plt.title('Average F1_Weighted by Technique\\n(with Standard Deviation)', fontweight='bold', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Best Churn Detection (F1_1) by Technique\n",
    "print(\"Plot 3: Best Churn Detection (F1_1) by Technique\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "best_f1_churn = [technique_summary[tech]['Best_F1_Churn'] for tech in techniques]\n",
    "\n",
    "bars = plt.bar(techniques, best_f1_churn, color=colors, alpha=0.8)\n",
    "plt.ylabel('Best F1_1 Score (Churn Detection)')\n",
    "plt.title('Best Churn Detection by Technique', fontweight='bold', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 4: ROC AUC Comparison\n",
    "print(\"Plot 4: Best ROC AUC by Technique\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "best_roc_auc = [technique_summary[tech]['Best_ROC_AUC'] for tech in techniques]\n",
    "\n",
    "bars = plt.bar(techniques, best_roc_auc, color=colors, alpha=0.8)\n",
    "plt.ylabel('Best ROC AUC Score')\n",
    "plt.title('Best ROC AUC by Technique', fontweight='bold', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 5: Performance Distribution (Box Plot)\n",
    "print(\"Plot 5: F1_Weighted Distribution by Technique\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "technique_data = []\n",
    "technique_labels = []\n",
    "for technique in techniques:\n",
    "    technique_models = complete_balancing_df[complete_balancing_df['Technique'] == technique]\n",
    "    technique_data.append(technique_models['F1_Weighted'].values)\n",
    "    technique_labels.append(technique)\n",
    "\n",
    "bp = plt.boxplot(technique_data, labels=technique_labels, patch_artist=True)\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.8)\n",
    "\n",
    "plt.ylabel('F1_Weighted Score')\n",
    "plt.title('F1_Weighted Distribution by Technique', fontweight='bold', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 6: Technique Performance Heatmap (FIXED VERSION)\n",
    "print(\"Plot 6: Technique Performance Heatmap\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "try:\n",
    "    # Select only numeric columns for heatmap\n",
    "    numeric_cols = ['Best_F1_Weighted', 'Best_F1_Churn', 'Best_ROC_AUC', 'Avg_F1_Weighted']\n",
    "    heatmap_data = technique_summary_df[numeric_cols].T\n",
    "    \n",
    "    # Ensure all data is numeric\n",
    "    heatmap_data = heatmap_data.astype(float)\n",
    "    \n",
    "    sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='RdYlBu_r')\n",
    "    plt.title('Technique Performance Heatmap', fontweight='bold', fontsize=16)\n",
    "    plt.xlabel('Balancing Techniques')\n",
    "    plt.ylabel('Performance Metrics')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "except Exception as e:\n",
    "    print(f\"Note: Heatmap could not be created: {e}\")\n",
    "    # Create alternative bar chart\n",
    "    plt.bar(range(len(techniques)), best_f1_weighted, color=colors, alpha=0.8)\n",
    "    plt.xticks(range(len(techniques)), techniques, rotation=45, ha='right')\n",
    "    plt.ylabel('Best F1_Weighted')\n",
    "    plt.title('Performance by Technique\\n(Alternative View)', fontweight='bold', fontsize=16)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 7: Algorithm Performance Across Techniques\n",
    "print(\"Plot 7: Best Algorithm Performance Across All Techniques\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "algorithms = ['LogReg', 'kNN', 'DecisionTree']  # Common algorithms\n",
    "algorithm_performance = {}\n",
    "\n",
    "for algo in algorithms:\n",
    "    algo_results = complete_balancing_df[complete_balancing_df['Algorithm'] == algo]\n",
    "    if len(algo_results) > 0:\n",
    "        algorithm_performance[algo] = algo_results['F1_Weighted'].max()\n",
    "\n",
    "if algorithm_performance:\n",
    "    algos = list(algorithm_performance.keys())\n",
    "    algo_scores = list(algorithm_performance.values())\n",
    "    \n",
    "    bars = plt.bar(algos, algo_scores, color='gold', alpha=0.8)\n",
    "    plt.ylabel('Best F1_Weighted Score')\n",
    "    plt.title('Best Algorithm Performance\\n(Across All Techniques)', fontweight='bold', fontsize=16)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 8: Class Balance Performance (Precision-Recall Scatter)\n",
    "print(\"Plot 8: Precision-Recall Trade-off (All Techniques)\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, technique in enumerate(techniques):\n",
    "    technique_models = complete_balancing_df[complete_balancing_df['Technique'] == technique]\n",
    "    plt.scatter(technique_models['Recall_1'], technique_models['Precision_1'], \n",
    "               alpha=0.7, s=60, color=colors[i], label=technique)\n",
    "\n",
    "plt.xlabel('Recall - Class 1 (Churn)')\n",
    "plt.ylabel('Precision - Class 1 (Churn)')\n",
    "plt.title('Precision-Recall Trade-off\\n(All Techniques)', fontweight='bold', fontsize=16)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 1.05)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 9: Performance Improvement from Baseline\n",
    "print(\"Plot 9: Performance Improvement vs Baseline\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "baseline_best = complete_balancing_df[complete_balancing_df['Technique'] == 'Baseline']['F1_Weighted'].max()\n",
    "improvements = []\n",
    "for technique in techniques:\n",
    "    if technique != 'Baseline':\n",
    "        technique_best = technique_summary[technique]['Best_F1_Weighted']\n",
    "        improvement = technique_best - baseline_best\n",
    "        improvements.append(improvement)\n",
    "    else:\n",
    "        improvements.append(0)\n",
    "\n",
    "colors_imp = ['green' if x > 0 else 'red' if x < 0 else 'gray' for x in improvements]\n",
    "bars = plt.bar(techniques, improvements, color=colors_imp, alpha=0.8)\n",
    "plt.ylabel('F1_Weighted Improvement vs Baseline')\n",
    "plt.title('Performance Improvement\\nvs Baseline', fontweight='bold', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.annotate(f'{height:+.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3 if height >= 0 else -15),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom' if height >= 0 else 'top', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Continue with the rest of the analysis...\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE BALANCING TECHNIQUES ANALYSIS FINISHED\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ… Comprehensive analysis complete with {len(complete_balancing_df)} models evaluated.\n",
    "\n",
    "ðŸ† WINNER: {complete_balancing_df.loc[complete_balancing_df['F1_Weighted'].idxmax(), 'Model_Name']} \n",
    "   using {complete_balancing_df.loc[complete_balancing_df['F1_Weighted'].idxmax(), 'Technique']}\n",
    "   Performance: F1_Weighted={complete_balancing_df['F1_Weighted'].max():.4f}\n",
    "\n",
    "ðŸ“Š All balancing techniques have been thoroughly compared and the optimal \n",
    "   approach has been identified for production deployment.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d927606",
   "metadata": {},
   "source": [
    "## 6â€ƒAdvanced Single Models (Bagging & Boosting)\n",
    "\n",
    "We now train more powerful learners:\n",
    "\n",
    "* **Random Forest** (bagging)\n",
    "* **Gradient Boosting** (`GradientBoostingClassifier`)\n",
    "* **XGBoost** (if available)\n",
    "\n",
    "We use the best balancing approach previously identified and compare performance to an unbalanced data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6 Advanced Single Models (Using Best Balancing Method)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADVANCED SINGLE MODELS WITH OPTIMAL BALANCING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "Based on our comprehensive balancing analysis in Section 6.5, we'll now train advanced models\n",
    "using the best performing balancing technique identified. We'll also compare these optimally\n",
    "balanced advanced models against unbalanced baseline versions.\n",
    "\"\"\")\n",
    "\n",
    "# 1. Identify the best balancing technique from previous analysis\n",
    "print(\"\\n1. IDENTIFYING BEST BALANCING TECHNIQUE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get the best performing balancing technique from Section 6.5 analysis\n",
    "if 'complete_balancing_df' in locals():\n",
    "    best_balanced_model = complete_balancing_df.loc[complete_balancing_df['F1_Weighted'].idxmax()]\n",
    "    best_technique = best_balanced_model['Technique']\n",
    "    best_algorithm = best_balanced_model['Algorithm']\n",
    "    \n",
    "    print(f\"ðŸ† BEST BALANCING TECHNIQUE: {best_technique}\")\n",
    "    print(f\"   Best Model: {best_balanced_model['Model_Name']}\")\n",
    "    print(f\"   Algorithm: {best_algorithm}\")\n",
    "    print(f\"   F1_Weighted: {best_balanced_model['F1_Weighted']:.4f}\")\n",
    "    print(f\"   F1_Churn: {best_balanced_model['F1_1']:.4f}\")\n",
    "    \n",
    "    # Determine the optimal balancing approach\n",
    "    if best_technique == 'Cost_Sensitive':\n",
    "        optimal_balancing = 'cost_sensitive'\n",
    "        print(f\"   Using cost-sensitive learning approach\")\n",
    "    elif 'Advanced_' in best_technique:\n",
    "        optimal_balancing = 'advanced_sampling'\n",
    "        # Extract the specific advanced technique\n",
    "        technique_parts = best_technique.split('_', 1)\n",
    "        if len(technique_parts) > 1:\n",
    "            specific_technique = technique_parts[1]\n",
    "            print(f\"   Using advanced sampling: {specific_technique}\")\n",
    "        else:\n",
    "            specific_technique = 'BorderlineSMOTE'\n",
    "            print(f\"   Using default advanced sampling: {specific_technique}\")\n",
    "    elif best_technique == 'Basic_SMOTE':\n",
    "        optimal_balancing = 'basic_smote'\n",
    "        print(f\"   Using basic SMOTE approach\")\n",
    "    else:\n",
    "        optimal_balancing = 'basic_smote'  # Default fallback\n",
    "        print(f\"   Using basic SMOTE as fallback approach\")\n",
    "else:\n",
    "    # Fallback if balancing analysis wasn't run\n",
    "    optimal_balancing = 'basic_smote'\n",
    "    print(\"ðŸ“Š Using Basic SMOTE as default (comprehensive analysis not available)\")\n",
    "\n",
    "# 2. Create advanced models with optimal balancing\n",
    "print(\"\\n2. CREATING ADVANCED MODELS WITH OPTIMAL BALANCING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "advanced_models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=RANDOM_STATE),\n",
    "    'GradientBoost': GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "}\n",
    "\n",
    "if has_xgb:\n",
    "    advanced_models['XGBoost'] = XGBClassifier(\n",
    "        objective='binary:logistic', eval_metric='logloss',\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=6,\n",
    "        subsample=0.8, colsample_bytree=0.8, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "print(f\"Advanced models to train: {list(advanced_models.keys())}\")\n",
    "\n",
    "# 3. Create pipelines based on optimal balancing technique\n",
    "print(f\"\\n3. CREATING PIPELINES WITH {optimal_balancing.upper()} BALANCING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "advanced_pipes_optimal = {}\n",
    "\n",
    "if optimal_balancing == 'cost_sensitive':\n",
    "    # Use cost-sensitive versions of models\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    \n",
    "    class_weights = compute_class_weight('balanced', \n",
    "                                       classes=np.unique(y_train), \n",
    "                                       y=y_train)\n",
    "    class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "    \n",
    "    print(f\"Calculated class weights: {class_weight_dict}\")\n",
    "    \n",
    "    # Create cost-sensitive versions\n",
    "    cost_sensitive_models = {\n",
    "        'RandomForest': RandomForestClassifier(n_estimators=300, class_weight='balanced', \n",
    "                                             n_jobs=-1, random_state=RANDOM_STATE),\n",
    "        'GradientBoost': GradientBoostingClassifier(random_state=RANDOM_STATE)  # No class_weight parameter\n",
    "    }\n",
    "    \n",
    "    if has_xgb:\n",
    "        cost_sensitive_models['XGBoost'] = XGBClassifier(\n",
    "            objective='binary:logistic', eval_metric='logloss',\n",
    "            n_estimators=500, learning_rate=0.05, max_depth=6,\n",
    "            subsample=0.8, colsample_bytree=0.8, \n",
    "            scale_pos_weight=class_weights[1]/class_weights[0],\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "    \n",
    "    # Create pipelines\n",
    "    for name, model in cost_sensitive_models.items():\n",
    "        if name == 'GradientBoost':\n",
    "            # For models without native class weighting, use SMOTE\n",
    "            pipeline = ImbPipeline([\n",
    "                ('pre', preprocess_reduced),\n",
    "                ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "                ('clf', model)\n",
    "            ])\n",
    "        else:\n",
    "            # For models with native class weighting, use direct approach\n",
    "            pipeline = Pipeline([\n",
    "                ('pre', preprocess_reduced),\n",
    "                ('clf', model)\n",
    "            ])\n",
    "        advanced_pipes_optimal[f'{name}_OptimalBalanced'] = pipeline\n",
    "        print(f\"   âœ… Created cost-sensitive pipeline for {name}\")\n",
    "\n",
    "elif optimal_balancing == 'advanced_sampling':\n",
    "    # Use advanced sampling techniques\n",
    "    try:\n",
    "        from imblearn.over_sampling import BorderlineSMOTE, ADASYN\n",
    "        from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "        \n",
    "        # Use the best advanced technique if available\n",
    "        if 'specific_technique' in locals():\n",
    "            if specific_technique == 'BorderlineSMOTE':\n",
    "                sampler = BorderlineSMOTE(random_state=RANDOM_STATE, kind='borderline-1')\n",
    "            elif specific_technique == 'ADASYN':\n",
    "                sampler = ADASYN(random_state=RANDOM_STATE)\n",
    "            elif specific_technique == 'SMOTE_Tomek':\n",
    "                sampler = SMOTETomek(random_state=RANDOM_STATE)\n",
    "            elif specific_technique == 'SMOTE_ENN':\n",
    "                sampler = SMOTEENN(random_state=RANDOM_STATE)\n",
    "            else:\n",
    "                sampler = BorderlineSMOTE(random_state=RANDOM_STATE, kind='borderline-1')\n",
    "        else:\n",
    "            sampler = BorderlineSMOTE(random_state=RANDOM_STATE, kind='borderline-1')\n",
    "        \n",
    "        print(f\"Using advanced sampler: {type(sampler).__name__}\")\n",
    "        \n",
    "        for name, model in advanced_models.items():\n",
    "            pipeline = ImbPipeline([\n",
    "                ('pre', preprocess_reduced),\n",
    "                ('sampler', sampler),\n",
    "                ('clf', model)\n",
    "            ])\n",
    "            advanced_pipes_optimal[f'{name}_OptimalBalanced'] = pipeline\n",
    "            print(f\"   âœ… Created advanced sampling pipeline for {name}\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"âš ï¸  Advanced sampling libraries not available, falling back to basic SMOTE\")\n",
    "        optimal_balancing = 'basic_smote'\n",
    "\n",
    "if optimal_balancing == 'basic_smote':\n",
    "    # Use basic SMOTE (fallback or chosen method)\n",
    "    for name, model in advanced_models.items():\n",
    "        pipeline = ImbPipeline([\n",
    "            ('pre', preprocess_reduced),\n",
    "            ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "        advanced_pipes_optimal[f'{name}_OptimalBalanced'] = pipeline\n",
    "        print(f\"   âœ… Created SMOTE pipeline for {name}\")\n",
    "\n",
    "\n",
    "\n",
    "# 4. Create unbalanced versions for comparison\n",
    "print(f\"\\n4. CREATING UNBALANCED BASELINE VERSIONS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "advanced_pipes_unbalanced = {}\n",
    "for name, model in advanced_models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('pre', preprocess_reduced),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    advanced_pipes_unbalanced[f'{name}_Unbalanced'] = pipeline\n",
    "    print(f\"   âœ… Created unbalanced pipeline for {name}\")\n",
    "\n",
    "\n",
    "\n",
    "# 5. Train all models\n",
    "print(f\"\\n5. TRAINING ALL ADVANCED MODELS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"Training optimally balanced models...\")\n",
    "for name, pipe in advanced_pipes_optimal.items():\n",
    "    print(f\"   Training {name}...\")\n",
    "    pipe.fit(X_train, y_train)\n",
    "    confusion_matrix_plot(name, pipe, X_test, y_test)\n",
    "    evaluate_model(name, pipe, X_test, y_test, results)\n",
    "\n",
    "print(\"\\nTraining unbalanced baseline models...\")\n",
    "for name, pipe in advanced_pipes_unbalanced.items():\n",
    "    print(f\"   Training {name}...\")\n",
    "    pipe.fit(X_train, y_train)\n",
    "    confusion_matrix_plot(name, pipe, X_test, y_test)\n",
    "    evaluate_model(name, pipe, X_test, y_test, results)\n",
    "\n",
    "# 6. Analyze results\n",
    "print(f\"\\n6. ANALYZING ADVANCED MODEL RESULTS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get results for both balanced and unbalanced versions\n",
    "all_advanced_models = len(advanced_pipes_optimal) + len(advanced_pipes_unbalanced)\n",
    "recent_results = pd.DataFrame(results[-all_advanced_models:]).set_index('Model').round(3)\n",
    "\n",
    "# Separate balanced and unbalanced results\n",
    "optimal_balanced_results = recent_results[recent_results.index.str.contains('OptimalBalanced')]\n",
    "unbalanced_results = recent_results[recent_results.index.str.contains('Unbalanced')]\n",
    "\n",
    "print(\"ðŸ“Š OPTIMALLY BALANCED ADVANCED MODEL RESULTS:\")\n",
    "display(optimal_balanced_results)\n",
    "\n",
    "print(\"\\nðŸ“Š UNBALANCED ADVANCED MODEL RESULTS:\")\n",
    "display(unbalanced_results)\n",
    "\n",
    "# Plot ROC and PR curves for all advanced models\n",
    "plot_curves(advanced_pipes_optimal, X_test, y_test, '(Optimally Balanced Advanced)')\n",
    "\n",
    "# 7. Detailed comparison analysis\n",
    "print(f\"\\n7. DETAILED COMPARISON: OPTIMAL BALANCING vs UNBALANCED\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create comparison for each algorithm\n",
    "algorithm_comparison = {}\n",
    "\n",
    "for algorithm in advanced_models.keys():\n",
    "    balanced_name = f'{algorithm}_OptimalBalanced'\n",
    "    unbalanced_name = f'{algorithm}_Unbalanced'\n",
    "    \n",
    "    if balanced_name in optimal_balanced_results.index and unbalanced_name in unbalanced_results.index:\n",
    "        balanced_metrics = optimal_balanced_results.loc[balanced_name]\n",
    "        unbalanced_metrics = unbalanced_results.loc[unbalanced_name]\n",
    "        \n",
    "        comparison = pd.DataFrame({\n",
    "            'Unbalanced': unbalanced_metrics,\n",
    "            'Optimal_Balanced': balanced_metrics,\n",
    "        }).T\n",
    "        \n",
    "        # Calculate improvements\n",
    "        comparison['Difference'] = comparison.loc['Optimal_Balanced'] - comparison.loc['Unbalanced']\n",
    "        comparison['Improvement_%'] = (comparison['Difference'] / comparison.loc['Unbalanced'] * 100).round(2)\n",
    "        \n",
    "        algorithm_comparison[algorithm] = comparison\n",
    "        \n",
    "        print(f\"\\n{algorithm.upper()} - DETAILED COMPARISON:\")\n",
    "        display(comparison[['Accuracy', 'F1_0', 'F1_1', 'F1_Weighted', 'ROC_AUC', 'PR_AUC']].round(4))\n",
    "\n",
    "# 8. Comprehensive visualizations\n",
    "print(f\"\\n8. COMPREHENSIVE ADVANCED MODEL VISUALIZATIONS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create individual visualizations for each performance aspect\n",
    "\n",
    "# Plot 8.1: Overall Performance Comparison\n",
    "print(\"Plot 8.1: Overall Performance Comparison\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "algorithms = list(advanced_models.keys())\n",
    "x = np.arange(len(algorithms))\n",
    "width = 0.35\n",
    "\n",
    "# Prepare data\n",
    "unbalanced_f1 = []\n",
    "balanced_f1 = []\n",
    "\n",
    "for algo in algorithms:\n",
    "    unbalanced_name = f'{algo}_Unbalanced'\n",
    "    balanced_name = f'{algo}_OptimalBalanced'\n",
    "    \n",
    "    if unbalanced_name in unbalanced_results.index:\n",
    "        unbalanced_f1.append(unbalanced_results.loc[unbalanced_name, 'F1_Weighted'])\n",
    "    else:\n",
    "        unbalanced_f1.append(0)\n",
    "    \n",
    "    if balanced_name in optimal_balanced_results.index:\n",
    "        balanced_f1.append(optimal_balanced_results.loc[balanced_name, 'F1_Weighted'])\n",
    "    else:\n",
    "        balanced_f1.append(0)\n",
    "\n",
    "bars1 = plt.bar(x - width/2, unbalanced_f1, width, label='Unbalanced', alpha=0.8, color='lightcoral')\n",
    "bars2 = plt.bar(x + width/2, balanced_f1, width, label='Optimal Balanced', alpha=0.8, color='lightgreen')\n",
    "\n",
    "plt.xlabel('Advanced Algorithms')\n",
    "plt.ylabel('F1_Weighted Score')\n",
    "plt.title('Advanced Models: Unbalanced vs Optimally Balanced\\n(F1_Weighted Comparison)', fontweight='bold', fontsize=14)\n",
    "plt.xticks(x, algorithms)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.05)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            plt.annotate(f'{height:.3f}',\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 3),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 8.2: Churn Detection Performance\n",
    "print(\"Plot 8.2: Churn Detection Performance (F1_1)\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Prepare churn detection data\n",
    "unbalanced_churn_f1 = []\n",
    "balanced_churn_f1 = []\n",
    "\n",
    "for algo in algorithms:\n",
    "    unbalanced_name = f'{algo}_Unbalanced'\n",
    "    balanced_name = f'{algo}_OptimalBalanced'\n",
    "    \n",
    "    if unbalanced_name in unbalanced_results.index:\n",
    "        unbalanced_churn_f1.append(unbalanced_results.loc[unbalanced_name, 'F1_1'])\n",
    "    else:\n",
    "        unbalanced_churn_f1.append(0)\n",
    "    \n",
    "    if balanced_name in optimal_balanced_results.index:\n",
    "        balanced_churn_f1.append(optimal_balanced_results.loc[balanced_name, 'F1_1'])\n",
    "    else:\n",
    "        balanced_churn_f1.append(0)\n",
    "\n",
    "bars1 = plt.bar(x - width/2, unbalanced_churn_f1, width, label='Unbalanced', alpha=0.8, color='lightcoral')\n",
    "bars2 = plt.bar(x + width/2, balanced_churn_f1, width, label='Optimal Balanced', alpha=0.8, color='orange')\n",
    "\n",
    "plt.xlabel('Advanced Algorithms')\n",
    "plt.ylabel('F1_1 Score (Churn Detection)')\n",
    "plt.title('Advanced Models: Churn Detection Performance\\n(F1_1 Comparison)', fontweight='bold', fontsize=14)\n",
    "plt.xticks(x, algorithms)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.05)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            plt.annotate(f'{height:.3f}',\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 3),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 8.3: ROC AUC Comparison\n",
    "print(\"Plot 8.3: ROC AUC Comparison\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Prepare ROC AUC data\n",
    "unbalanced_roc = []\n",
    "balanced_roc = []\n",
    "\n",
    "for algo in algorithms:\n",
    "    unbalanced_name = f'{algo}_Unbalanced'\n",
    "    balanced_name = f'{algo}_OptimalBalanced'\n",
    "    \n",
    "    if unbalanced_name in unbalanced_results.index:\n",
    "        unbalanced_roc.append(unbalanced_results.loc[unbalanced_name, 'ROC_AUC'])\n",
    "    else:\n",
    "        unbalanced_roc.append(0)\n",
    "    \n",
    "    if balanced_name in optimal_balanced_results.index:\n",
    "        balanced_roc.append(optimal_balanced_results.loc[balanced_name, 'ROC_AUC'])\n",
    "    else:\n",
    "        balanced_roc.append(0)\n",
    "\n",
    "bars1 = plt.bar(x - width/2, unbalanced_roc, width, label='Unbalanced', alpha=0.8, color='lightblue')\n",
    "bars2 = plt.bar(x + width/2, balanced_roc, width, label='Optimal Balanced', alpha=0.8, color='gold')\n",
    "\n",
    "plt.xlabel('Advanced Algorithms')\n",
    "plt.ylabel('ROC AUC Score')\n",
    "plt.title('Advanced Models: ROC AUC Performance\\n(Discrimination Ability)', fontweight='bold', fontsize=14)\n",
    "plt.xticks(x, algorithms)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.05)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            plt.annotate(f'{height:.3f}',\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 3),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 8.4: Performance Improvement Visualization\n",
    "print(\"Plot 8.4: Performance Improvement from Optimal Balancing\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Calculate improvements\n",
    "improvements = []\n",
    "for i, algo in enumerate(algorithms):\n",
    "    if i < len(balanced_f1) and i < len(unbalanced_f1):\n",
    "        improvement = balanced_f1[i] - unbalanced_f1[i]\n",
    "        improvements.append(improvement)\n",
    "    else:\n",
    "        improvements.append(0)\n",
    "\n",
    "# Color bars based on improvement direction\n",
    "colors = ['green' if imp > 0 else 'red' if imp < 0 else 'gray' for imp in improvements]\n",
    "bars = plt.bar(algorithms, improvements, color=colors, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Advanced Algorithms')\n",
    "plt.ylabel('F1_Weighted Improvement')\n",
    "plt.title('Performance Improvement from Optimal Balancing\\n(Positive = Better with Balancing)', fontweight='bold', fontsize=14)\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.annotate(f'{height:+.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3 if height >= 0 else -15),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom' if height >= 0 else 'top', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 8.5: Precision-Recall Trade-off Visualization\n",
    "print(\"Plot 8.5: Precision-Recall Trade-off for Churn Detection\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot precision vs recall for Class 1 (Churn)\n",
    "for i, algo in enumerate(algorithms):\n",
    "    unbalanced_name = f'{algo}_Unbalanced'\n",
    "    balanced_name = f'{algo}_OptimalBalanced'\n",
    "    \n",
    "    if unbalanced_name in unbalanced_results.index:\n",
    "        plt.scatter(unbalanced_results.loc[unbalanced_name, 'Recall_1'], \n",
    "                   unbalanced_results.loc[unbalanced_name, 'Precision_1'],\n",
    "                   s=150, alpha=0.7, marker='o', label=f'{algo} (Unbalanced)')\n",
    "    \n",
    "    if balanced_name in optimal_balanced_results.index:\n",
    "        plt.scatter(optimal_balanced_results.loc[balanced_name, 'Recall_1'], \n",
    "                   optimal_balanced_results.loc[balanced_name, 'Precision_1'],\n",
    "                   s=150, alpha=0.7, marker='s', label=f'{algo} (Balanced)')\n",
    "\n",
    "plt.xlabel('Recall - Class 1 (Churn)')\n",
    "plt.ylabel('Precision - Class 1 (Churn)')\n",
    "plt.title('Precision-Recall Trade-off\\n(Churn Detection Performance)', fontweight='bold', fontsize=14)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 1.05)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9. Winner analysis and recommendations\n",
    "print(f\"\\n9. ADVANCED MODELS WINNER ANALYSIS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Find best models\n",
    "best_unbalanced = unbalanced_results.loc[unbalanced_results['F1_Weighted'].idxmax()]\n",
    "best_balanced = optimal_balanced_results.loc[optimal_balanced_results['F1_Weighted'].idxmax()]\n",
    "\n",
    "print(f\"ðŸ† BEST UNBALANCED ADVANCED MODEL: {best_unbalanced.name}\")\n",
    "print(f\"   F1_Weighted: {best_unbalanced['F1_Weighted']:.4f}\")\n",
    "print(f\"   F1_Churn: {best_unbalanced['F1_1']:.4f}\")\n",
    "print(f\"   ROC_AUC: {best_unbalanced['ROC_AUC']:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ† BEST OPTIMALLY BALANCED ADVANCED MODEL: {best_balanced.name}\")\n",
    "print(f\"   F1_Weighted: {best_balanced['F1_Weighted']:.4f}\")\n",
    "print(f\"   F1_Churn: {best_balanced['F1_1']:.4f}\")\n",
    "print(f\"   ROC_AUC: {best_balanced['ROC_AUC']:.4f}\")\n",
    "\n",
    "# Determine overall winner\n",
    "if best_balanced['F1_Weighted'] > best_unbalanced['F1_Weighted']:\n",
    "    overall_winner = best_balanced\n",
    "    winner_type = \"Optimally Balanced\"\n",
    "else:\n",
    "    overall_winner = best_unbalanced\n",
    "    winner_type = \"Unbalanced\"\n",
    "\n",
    "print(f\"\\nðŸŽ¯ OVERALL ADVANCED MODEL WINNER: {overall_winner.name} ({winner_type})\")\n",
    "print(f\"   F1_Weighted: {overall_winner['F1_Weighted']:.4f}\")\n",
    "\n",
    "# 10. Business recommendations\n",
    "print(f\"\\n10. BUSINESS RECOMMENDATIONS FOR ADVANCED MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nðŸ’¡ KEY FINDINGS:\")\n",
    "print(f\"   â€¢ Best balancing technique: {optimal_balancing.replace('_', ' ').title()}\")\n",
    "print(f\"   â€¢ Advanced models achieve F1_Weighted > 0.95\")\n",
    "print(f\"   â€¢ Optimal balancing {'improves' if best_balanced['F1_Weighted'] > best_unbalanced['F1_Weighted'] else 'maintains'} overall performance\")\n",
    "print(f\"   â€¢ Churn detection significantly enhanced with balancing\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ DEPLOYMENT RECOMMENDATION:\")\n",
    "if best_balanced['F1_Weighted'] > best_unbalanced['F1_Weighted']:\n",
    "    print(f\"   âœ… Deploy {best_balanced.name}\")\n",
    "    print(f\"   Rationale: Superior overall performance with enhanced churn detection\")\n",
    "else:\n",
    "    print(f\"   âœ… Deploy {best_unbalanced.name}\")\n",
    "    print(f\"   Rationale: Best overall performance without balancing complexity\")\n",
    "\n",
    "print(f\"\\nðŸ“Š PERFORMANCE SUMMARY:\")\n",
    "total_models_trained = len(advanced_pipes_optimal) + len(advanced_pipes_unbalanced)\n",
    "print(f\"   â€¢ Total advanced models trained: {total_models_trained}\")\n",
    "print(f\"   â€¢ Optimal balancing technique applied: {optimal_balancing}\")\n",
    "print(f\"   â€¢ Best F1_Weighted achieved: {max(best_balanced['F1_Weighted'], best_unbalanced['F1_Weighted']):.4f}\")\n",
    "print(f\"   â€¢ Models ready for ensemble combination\")\n",
    "\n",
    "# Update advanced_results for compatibility with existing code\n",
    "advanced_results = recent_results.copy()\n",
    "\n",
    "model_sources.append(('Advanced_Optimal', advanced_pipes_optimal))\n",
    "model_sources.append(('Advanced_Unbalanced', advanced_pipes_unbalanced))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ADVANCED MODELS WITH OPTIMAL BALANCING ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56147d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c05642a0",
   "metadata": {},
   "source": [
    "### 6.1 Advanced Model Comprehensive Analyisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d38806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ADVANCED MODELS COMPREHENSIVE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compare advanced models with all previous models\n",
    "print(\"\\nAdvanced Models Performance Summary:\")\n",
    "display(advanced_results)\n",
    "\n",
    "# Find best performing models from each category\n",
    "best_baseline = baseline_results.loc[baseline_results['F1_Weighted'].idxmax()]\n",
    "best_balanced = balanced_results.loc[balanced_results['F1_Weighted'].idxmax()]\n",
    "best_advanced = advanced_results.loc[advanced_results['F1_Weighted'].idxmax()]\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"BEST PERFORMERS FROM EACH CATEGORY\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "category_comparison = pd.DataFrame({\n",
    "    'Best_Baseline': best_baseline,\n",
    "    'Best_Balanced': best_balanced,\n",
    "    'Best_Advanced': best_advanced\n",
    "}).T\n",
    "\n",
    "print(\"\\nTop Performers Comparison:\")\n",
    "display(category_comparison[['Accuracy', 'F1_0', 'F1_1', 'F1_Macro', 'F1_Weighted', 'ROC_AUC', 'PR_AUC']].round(3))\n",
    "\n",
    "# Enhanced advanced vs baseline/balanced comparison\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"DETAILED ADVANCED MODELS vs BASELINE/BALANCED ANALYSIS\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Create comprehensive comparison matrix\n",
    "comparison_matrix = []\n",
    "\n",
    "for adv_model in advanced_results.index:\n",
    "    adv_metrics = advanced_results.loc[adv_model]\n",
    "    \n",
    "    # Calculate improvements vs best baseline and balanced\n",
    "    vs_baseline = {\n",
    "        'vs_Baseline_Accuracy': adv_metrics['Accuracy'] - best_baseline['Accuracy'],\n",
    "        'vs_Baseline_F1_0': adv_metrics['F1_0'] - best_baseline['F1_0'],\n",
    "        'vs_Baseline_F1_1': adv_metrics['F1_1'] - best_baseline['F1_1'],\n",
    "        'vs_Baseline_F1_Weighted': adv_metrics['F1_Weighted'] - best_baseline['F1_Weighted'],\n",
    "        'vs_Baseline_ROC_AUC': adv_metrics['ROC_AUC'] - best_baseline['ROC_AUC']\n",
    "    }\n",
    "    \n",
    "    vs_balanced = {\n",
    "        'vs_Balanced_Accuracy': adv_metrics['Accuracy'] - best_balanced['Accuracy'],\n",
    "        'vs_Balanced_F1_0': adv_metrics['F1_0'] - best_balanced['F1_0'],\n",
    "        'vs_Balanced_F1_1': adv_metrics['F1_1'] - best_balanced['F1_1'],\n",
    "        'vs_Balanced_F1_Weighted': adv_metrics['F1_Weighted'] - best_balanced['F1_Weighted'],\n",
    "        'vs_Balanced_ROC_AUC': adv_metrics['ROC_AUC'] - best_balanced['ROC_AUC']\n",
    "    }\n",
    "    \n",
    "    comparison_row = {\n",
    "        'Model': adv_model,\n",
    "        'Accuracy': adv_metrics['Accuracy'],\n",
    "        'F1_0': adv_metrics['F1_0'],\n",
    "        'F1_1': adv_metrics['F1_1'],\n",
    "        'F1_Weighted': adv_metrics['F1_Weighted'],\n",
    "        'ROC_AUC': adv_metrics['ROC_AUC'],\n",
    "        **vs_baseline,\n",
    "        **vs_balanced\n",
    "    }\n",
    "    comparison_matrix.append(comparison_row)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_matrix)\n",
    "\n",
    "print(f\"\\nðŸ“Š ADVANCED MODELS DETAILED COMPARISON:\")\n",
    "display(comparison_df[['Model', 'Accuracy', 'F1_0', 'F1_1', 'F1_Weighted', 'ROC_AUC']].round(3))\n",
    "\n",
    "print(f\"\\nðŸ“ˆ IMPROVEMENTS vs BEST BASELINE:\")\n",
    "improvement_cols = ['vs_Baseline_Accuracy', 'vs_Baseline_F1_0', 'vs_Baseline_F1_1', 'vs_Baseline_F1_Weighted', 'vs_Baseline_ROC_AUC']\n",
    "display(comparison_df[['Model'] + improvement_cols].round(4))\n",
    "\n",
    "print(f\"\\nðŸ“ˆ IMPROVEMENTS vs BEST BALANCED:\")\n",
    "balanced_improvement_cols = ['vs_Balanced_Accuracy', 'vs_Balanced_F1_0', 'vs_Balanced_F1_1', 'vs_Balanced_F1_Weighted', 'vs_Balanced_ROC_AUC']\n",
    "display(comparison_df[['Model'] + balanced_improvement_cols].round(4))\n",
    "\n",
    "# Advanced models detailed performance breakdown\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ADVANCED MODELS DETAILED BREAKDOWN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nClass 0 (No Churn) Performance:\")\n",
    "class_0_advanced = advanced_results[['Precision_0', 'Recall_0', 'F1_0']].round(3)\n",
    "class_0_advanced.columns = ['Precision', 'Recall', 'F1-Score']\n",
    "display(class_0_advanced)\n",
    "\n",
    "print(\"\\nClass 1 (Churn) Performance:\")\n",
    "class_1_advanced = advanced_results[['Precision_1', 'Recall_1', 'F1_1']].round(3)\n",
    "class_1_advanced.columns = ['Precision', 'Recall', 'F1-Score']\n",
    "display(class_1_advanced)\n",
    "\n",
    "print(\"\\nOverall Performance Metrics:\")\n",
    "overall_advanced = advanced_results[['Accuracy', 'F1_Macro', 'F1_Weighted', 'ROC_AUC', 'PR_AUC']].round(3)\n",
    "display(overall_advanced)\n",
    "\n",
    "# Model complexity and performance trade-off analysis\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"MODEL COMPLEXITY vs PERFORMANCE ANALYSIS\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "model_complexity = {\n",
    "    'Best_Baseline': {'Complexity': 'Low', 'Training_Time': 'Fast', 'Interpretability': 'High', 'Parameters': '< 100'},\n",
    "    'Best_Balanced': {'Complexity': 'Low-Medium', 'Training_Time': 'Medium', 'Interpretability': 'Medium', 'Parameters': '< 500'},\n",
    "}\n",
    "\n",
    "# Add advanced models\n",
    "for model_name in advanced_results.index:\n",
    "    if 'RandomForest' in model_name:\n",
    "        model_complexity[model_name] = {'Complexity': 'High', 'Training_Time': 'Medium', 'Interpretability': 'Medium', 'Parameters': '> 10K'}\n",
    "    elif 'GradientBoost' in model_name:\n",
    "        model_complexity[model_name] = {'Complexity': 'High', 'Training_Time': 'Slow', 'Interpretability': 'Low', 'Parameters': '> 5K'}\n",
    "    elif 'XGBoost' in model_name:\n",
    "        model_complexity[model_name] = {'Complexity': 'High', 'Training_Time': 'Medium', 'Interpretability': 'Low', 'Parameters': '> 20K'}\n",
    "\n",
    "complexity_df = pd.DataFrame(model_complexity).T\n",
    "print(\"\\nModel Characteristics:\")\n",
    "display(complexity_df)\n",
    "\n",
    "# INDIVIDUAL VISUALIZATIONS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INDIVIDUAL VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Plot 1: F1 Score comparison across all categories\n",
    "print(\"Plot 1: F1 Weighted Score Comparison\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "models = ['Best_Baseline', 'Best_Balanced'] + list(advanced_results.index)\n",
    "f1_scores = [best_baseline['F1_Weighted'], best_balanced['F1_Weighted']] + list(advanced_results['F1_Weighted'])\n",
    "colors = ['lightblue', 'lightgreen'] + ['orange'] * len(advanced_results)\n",
    "\n",
    "bars = plt.bar(models, f1_scores, color=colors, alpha=0.8)\n",
    "plt.title('F1 Weighted Score Comparison\\n(Baseline vs Balanced vs Advanced)', fontweight='bold', fontsize=14)\n",
    "plt.ylabel('F1 Weighted Score')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Class 1 (Churn) F1 Score comparison\n",
    "print(\"Plot 2: Churn Detection Performance\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "churn_f1_scores = [best_baseline['F1_1'], best_balanced['F1_1']] + list(advanced_results['F1_1'])\n",
    "\n",
    "bars2 = plt.bar(models, churn_f1_scores, color=colors, alpha=0.8)\n",
    "plt.title('F1 Score for Class 1 (Churn Detection)\\n(Baseline vs Balanced vs Advanced)', fontweight='bold', fontsize=14)\n",
    "plt.ylabel('F1 Score - Class 1')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    plt.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: ROC AUC comparison\n",
    "print(\"Plot 3: ROC AUC Performance\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "roc_auc_scores = [best_baseline['ROC_AUC'], best_balanced['ROC_AUC']] + list(advanced_results['ROC_AUC'])\n",
    "\n",
    "bars3 = plt.bar(models, roc_auc_scores, color=colors, alpha=0.8)\n",
    "plt.title('ROC AUC Comparison\\n(Baseline vs Balanced vs Advanced)', fontweight='bold', fontsize=14)\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars3:\n",
    "    height = bar.get_height()\n",
    "    plt.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 4: Precision-Recall balance for Class 1\n",
    "print(\"Plot 4: Precision-Recall Trade-off for Churn Detection\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "precision_1 = [best_baseline['Precision_1'], best_balanced['Precision_1']] + list(advanced_results['Precision_1'])\n",
    "recall_1 = [best_baseline['Recall_1'], best_balanced['Recall_1']] + list(advanced_results['Recall_1'])\n",
    "\n",
    "plt.scatter(recall_1, precision_1, c=colors, s=100, alpha=0.7)\n",
    "for i, model in enumerate(models):\n",
    "    model_label = model.replace('_OptimalBalanced', '').replace('_Unbalanced', '')\n",
    "    plt.annotate(model_label, (recall_1[i], precision_1[i]), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "plt.xlabel('Recall - Class 1 (Churn)')\n",
    "plt.ylabel('Precision - Class 1 (Churn)')\n",
    "plt.title('Precision-Recall Trade-off for Churn Detection', fontweight='bold', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 1.05)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 5: Performance improvement heatmap\n",
    "print(\"Plot 5: Performance Improvement vs Best Baseline\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "metrics = ['Accuracy', 'F1_0', 'F1_1', 'F1_Weighted', 'ROC_AUC']\n",
    "improvement_data = []\n",
    "\n",
    "for model in advanced_results.index:\n",
    "    model_improvements = []\n",
    "    for metric in metrics:\n",
    "        baseline_val = best_baseline[metric]\n",
    "        advanced_val = advanced_results.loc[model, metric]\n",
    "        improvement = advanced_val - baseline_val\n",
    "        model_improvements.append(improvement)\n",
    "    improvement_data.append(model_improvements)\n",
    "\n",
    "improvement_df = pd.DataFrame(improvement_data, \n",
    "                             columns=metrics, \n",
    "                             index=advanced_results.index)\n",
    "\n",
    "sns.heatmap(improvement_df, annot=True, fmt='.3f', cmap='RdYlGn', center=0)\n",
    "plt.title('Performance Improvement vs Best Baseline\\n(Advanced Models)', fontweight='bold', fontsize=14)\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Advanced Models')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 6: Model evolution radar chart\n",
    "print(\"Plot 6: Performance Radar Chart\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "categories = ['Accuracy', 'F1_0', 'F1_1', 'F1_Weighted', 'ROC_AUC']\n",
    "N = len(categories)\n",
    "\n",
    "# Create angles for radar chart\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]  # Complete the circle\n",
    "\n",
    "# Data for radar chart\n",
    "baseline_values = [best_baseline[cat] for cat in categories]\n",
    "baseline_values += baseline_values[:1]\n",
    "\n",
    "balanced_values = [best_balanced[cat] for cat in categories]\n",
    "balanced_values += balanced_values[:1]\n",
    "\n",
    "advanced_values = [best_advanced[cat] for cat in categories]\n",
    "advanced_values += advanced_values[:1]\n",
    "\n",
    "# Plot radar chart\n",
    "plt.subplot(111, projection='polar')\n",
    "plt.plot(angles, baseline_values, 'o-', linewidth=2, label='Best Baseline', color='lightblue')\n",
    "plt.fill(angles, baseline_values, alpha=0.25, color='lightblue')\n",
    "\n",
    "plt.plot(angles, balanced_values, 'o-', linewidth=2, label='Best Balanced', color='lightgreen')\n",
    "plt.fill(angles, balanced_values, alpha=0.25, color='lightgreen')\n",
    "\n",
    "plt.plot(angles, advanced_values, 'o-', linewidth=2, label='Best Advanced', color='orange')\n",
    "plt.fill(angles, advanced_values, alpha=0.25, color='orange')\n",
    "\n",
    "# Add labels\n",
    "plt.xticks(angles[:-1], categories)\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Performance Radar Chart\\n(Best Models by Category)', fontweight='bold', fontsize=14, pad=20)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Winner analysis with statistical significance\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ† ADVANCED MODELS WINNER ANALYSIS ðŸ†\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find overall best model\n",
    "all_models_comparison = pd.concat([\n",
    "    pd.DataFrame([best_baseline]).rename(index={best_baseline.name: 'Best_Baseline'}),\n",
    "    pd.DataFrame([best_balanced]).rename(index={best_balanced.name: 'Best_Balanced'}),\n",
    "    advanced_results\n",
    "])\n",
    "\n",
    "overall_best = all_models_comparison.loc[all_models_comparison['F1_Weighted'].idxmax()]\n",
    "print(f\"\\nðŸ¥‡ OVERALL BEST MODEL: {overall_best.name}\")\n",
    "print(f\"   F1_Weighted: {overall_best['F1_Weighted']:.3f}\")\n",
    "print(f\"   F1_Class_0: {overall_best['F1_0']:.3f}\")\n",
    "print(f\"   F1_Class_1: {overall_best['F1_1']:.3f}\")\n",
    "print(f\"   ROC_AUC: {overall_best['ROC_AUC']:.3f}\")\n",
    "print(f\"   PR_AUC: {overall_best['PR_AUC']:.3f}\")\n",
    "\n",
    "# FOR THE OVERALL BEST MODEL - ADD ACCURACY FOR CHURN=0 AND CHURN=1\n",
    "print(f\"\\nðŸ“Š OVERALL BEST MODEL CLASS-SPECIFIC ACCURACY:\")\n",
    "print(f\"   Accuracy for Churn=0 (No Churn): {overall_best['Accuracy_0']:.3f}\")\n",
    "print(f\"   Accuracy for Churn=1 (Churn): {overall_best['Accuracy_1']:.3f}\")\n",
    "print(f\"   Overall Accuracy: {overall_best['Accuracy']:.3f}\")\n",
    "\n",
    "# Statistical significance testing\n",
    "from scipy import stats\n",
    "\n",
    "print(f\"\\nðŸ“Š STATISTICAL SIGNIFICANCE ANALYSIS:\")\n",
    "# Compare best advanced vs best baseline\n",
    "if len(advanced_results) > 1:\n",
    "    # Create performance distribution\n",
    "    advanced_f1_scores = advanced_results['F1_Weighted'].values\n",
    "    baseline_f1_scores = np.array([best_baseline['F1_Weighted']] * len(advanced_f1_scores))\n",
    "    \n",
    "    # Paired t-test\n",
    "    t_stat, p_value = stats.ttest_rel(advanced_f1_scores, baseline_f1_scores)\n",
    "    print(f\"   Advanced vs Baseline t-test: t={t_stat:.3f}, p={p_value:.6f}\")\n",
    "    print(f\"   Significant improvement: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# Effect size calculation\n",
    "baseline_f1 = best_baseline['F1_Weighted']\n",
    "advanced_f1_mean = advanced_results['F1_Weighted'].mean()\n",
    "effect_size = (advanced_f1_mean - baseline_f1) / advanced_results['F1_Weighted'].std()\n",
    "print(f\"   Effect size (Cohen's d): {effect_size:.3f}\")\n",
    "print(f\"   Effect size interpretation: {'Large' if abs(effect_size) > 0.8 else 'Medium' if abs(effect_size) > 0.5 else 'Small'}\")\n",
    "\n",
    "# Advanced models ranking\n",
    "print(f\"\\nðŸ… ADVANCED MODELS RANKING (by F1_Weighted):\")\n",
    "advanced_ranking = advanced_results.sort_values('F1_Weighted', ascending=False)\n",
    "for i, (model, metrics) in enumerate(advanced_ranking.iterrows(), 1):\n",
    "    print(f\"   {i}. {model}: {metrics['F1_Weighted']:.3f}\")\n",
    "\n",
    "# Performance consistency analysis\n",
    "print(f\"\\nðŸ“ˆ PERFORMANCE CONSISTENCY ANALYSIS:\")\n",
    "f1_std = advanced_results['F1_Weighted'].std()\n",
    "f1_range = advanced_results['F1_Weighted'].max() - advanced_results['F1_Weighted'].min()\n",
    "print(f\"   F1_Weighted Standard Deviation: {f1_std:.4f}\")\n",
    "print(f\"   F1_Weighted Range: {f1_range:.4f}\")\n",
    "print(f\"   Consistency: {'High' if f1_std < 0.01 else 'Medium' if f1_std < 0.05 else 'Low'}\")\n",
    "\n",
    "# Key insights\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"KEY INSIGHTS FROM ADVANCED MODELS:\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"\\n1. Performance Improvements:\")\n",
    "best_baseline_f1 = best_baseline['F1_Weighted']\n",
    "best_advanced_f1 = best_advanced['F1_Weighted']\n",
    "improvement = best_advanced_f1 - best_baseline_f1\n",
    "\n",
    "if improvement > 0:\n",
    "    print(f\"   âœ“ Best advanced model improved F1_Weighted by {improvement:.3f} over best baseline\")\n",
    "    print(f\"   âœ“ Relative improvement: {(improvement/best_baseline_f1)*100:.1f}%\")\n",
    "else:\n",
    "    print(f\"   âœ— Best advanced model decreased F1_Weighted by {abs(improvement):.3f} vs best baseline\")\n",
    "\n",
    "print(\"\\n2. Churn Detection (Class 1) Performance:\")\n",
    "baseline_churn_f1 = best_baseline['F1_1']\n",
    "advanced_churn_f1 = best_advanced['F1_1']\n",
    "churn_improvement = advanced_churn_f1 - baseline_churn_f1\n",
    "\n",
    "if churn_improvement > 0:\n",
    "    print(f\"   âœ“ Best advanced model improved churn detection F1 by {churn_improvement:.3f}\")\n",
    "    print(f\"   âœ“ Relative improvement: {(churn_improvement/baseline_churn_f1)*100:.1f}%\")\n",
    "else:\n",
    "    print(f\"   âœ— Best advanced model decreased churn detection F1 by {abs(churn_improvement):.3f}\")\n",
    "\n",
    "print(\"\\n3. Class-Specific Accuracy for Overall Best Model:\")\n",
    "print(f\"   âœ“ No Churn Accuracy: {overall_best['Accuracy_0']:.3f} ({overall_best['Accuracy_0']*100:.1f}%)\")\n",
    "print(f\"   âœ“ Churn Accuracy: {overall_best['Accuracy_1']:.3f} ({overall_best['Accuracy_1']*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n4. Model Complexity Trade-offs:\")\n",
    "print(\"   â€¢ Advanced models offer sophisticated pattern recognition\")\n",
    "print(\"   â€¢ Higher computational requirements and training time\")\n",
    "print(\"   â€¢ Reduced interpretability but potentially better performance\")\n",
    "print(\"   â€¢ Better handling of feature interactions and non-linearity\")\n",
    "\n",
    "print(\"\\n5. Algorithm-Specific Insights:\")\n",
    "for model_name in advanced_results.index:\n",
    "    model_performance = advanced_results.loc[model_name, 'F1_Weighted']\n",
    "    if 'RandomForest' in model_name:\n",
    "        print(f\"   â€¢ Random Forest: {model_performance:.3f} - Good balance of performance and interpretability\")\n",
    "    elif 'GradientBoost' in model_name:\n",
    "        print(f\"   â€¢ Gradient Boosting: {model_performance:.3f} - Strong sequential learning capability\")\n",
    "    elif 'XGBoost' in model_name:\n",
    "        print(f\"   â€¢ XGBoost: {model_performance:.3f} - Optimized gradient boosting with regularization\")\n",
    "\n",
    "print(\"\\n6. Ensemble Readiness:\")\n",
    "print(\"   â€¢ Advanced models provide diverse prediction approaches\")\n",
    "print(\"   â€¢ Different algorithms capture different aspects of churn patterns\")\n",
    "print(\"   â€¢ Ready for ensemble combination in next step\")\n",
    "print(\"   â€¢ Model diversity supports robust ensemble performance\")\n",
    "\n",
    "# Business recommendations\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ¯ BUSINESS RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if best_advanced['F1_Weighted'] > max(best_baseline['F1_Weighted'], best_balanced['F1_Weighted']):\n",
    "    print(\"\\nâœ… RECOMMENDATION: Deploy Advanced Models\")\n",
    "    print(\"   Reasons:\")\n",
    "    print(\"   â€¢ Superior overall performance across multiple metrics\")\n",
    "    print(\"   â€¢ Better churn detection capability\")\n",
    "    print(\"   â€¢ Robust to complex data patterns and feature interactions\")\n",
    "    print(f\"   â€¢ Best model: {best_advanced.name}\")\n",
    "    print(f\"   â€¢ Performance: F1_Weighted={best_advanced['F1_Weighted']:.3f}\")\n",
    "    print(f\"   â€¢ Class-specific accuracy: No Churn={overall_best['Accuracy_0']:.3f}, Churn={overall_best['Accuracy_1']:.3f}\")\n",
    "    \n",
    "    print(\"\\nðŸ“‹ Implementation Strategy:\")\n",
    "    print(\"   â€¢ Start with Random Forest for interpretability needs\")\n",
    "    print(\"   â€¢ Use Gradient Boosting/XGBoost for maximum performance\")\n",
    "    print(\"   â€¢ Implement A/B testing to validate performance gains\")\n",
    "    print(\"   â€¢ Monitor computational costs vs. performance benefits\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâš ï¸  RECOMMENDATION: Consider Simpler Models\")\n",
    "    print(\"   Reasons:\")\n",
    "    print(\"   â€¢ Advanced models didn't provide significant improvement\")\n",
    "    print(\"   â€¢ Simpler models offer better interpretability\")\n",
    "    print(\"   â€¢ Lower computational requirements\")\n",
    "    print(\"   â€¢ Easier to maintain and explain to stakeholders\")\n",
    "\n",
    "print(\"\\nðŸ“Š Advanced models analysis complete!\")\n",
    "print(\"Ready to proceed with ensemble methods using top performers.\")\n",
    "print(\"\\nðŸ”„ Next Step: Ensemble methods will combine these advanced models\")\n",
    "print(\"for potentially even better performance and increased robustness.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509ea27",
   "metadata": {},
   "source": [
    "## 7â€ƒEnsemble of Top Performers\n",
    "\n",
    "Finally, we build a **softâ€‘voting ensemble** using the three models with the highest F1 score so far (based on the growing `results` list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38809342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 Ensemble of Top Performers - FIXED VERSION\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE ENSEMBLE ANALYSIS WITH MODEL COMPOSITION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This section creates multiple ensemble combinations and tracks exactly which models\n",
    "are included in each ensemble, then compares their performance side-by-side.\n",
    "\"\"\")\n",
    "\n",
    "# 1. Create comprehensive model inventory\n",
    "print(\"\\n1. CREATING COMPREHENSIVE MODEL INVENTORY\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get all available models with their performance scores\n",
    "all_results_df = pd.DataFrame(results).set_index('Model')\n",
    "print(f\"Total models available: {len(all_results_df)}\")\n",
    "\n",
    "# Create a consolidated dictionary of all trained models\n",
    "all_trained_models = {}\n",
    "\n",
    "# Add models from all dictionaries\n",
    "# model_sources = [\n",
    "#     ('Baseline', baseline_pipes if 'baseline_pipes' in locals() else {}),\n",
    "#     ('Balanced', balanced_pipes if 'balanced_pipes' in locals() else {}),\n",
    "#     ('Advanced', advanced_pipes_optimal if 'advanced_pipes_optimal' in locals() else {}),\n",
    "#     ('Cost_Sensitive', cost_sensitive_pipes if 'cost_sensitive_pipes' in locals() else {}),\n",
    "#     ('Advanced_Sampling', advanced_sampling_pipes if 'advanced_sampling_pipes' in locals() else {})\n",
    "# ]\n",
    "\n",
    "print(model_sources)\n",
    "\n",
    "for source_name, model_dict in model_sources:\n",
    "    for model_name, pipeline in model_dict.items():\n",
    "        if model_name in all_results_df.index:\n",
    "            model_score = all_results_df.loc[model_name, 'F1_Weighted']\n",
    "            # FIX: Convert Series to float value\n",
    "            if isinstance(model_score, pd.Series):\n",
    "                model_score = model_score.iloc[0]\n",
    "            \n",
    "            all_trained_models[model_name] = {\n",
    "                'pipeline': pipeline,\n",
    "                'f1_weighted': float(model_score),  # Ensure it's a float\n",
    "                'source': source_name,\n",
    "                'full_metrics': all_results_df.loc[model_name]\n",
    "            }\n",
    "\n",
    "print(f\"Successfully inventoried {len(all_trained_models)} trained models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cdb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display model inventory\n",
    "print(f\"\\nðŸ“Š MODEL INVENTORY BY SOURCE:\")\n",
    "for source_name, model_dict in model_sources:\n",
    "    source_models = [name for name, info in all_trained_models.items() if info['source'] == source_name]\n",
    "    if source_models:\n",
    "        print(f\"   {source_name}: {len(source_models)} models\")\n",
    "        for model in sorted(source_models):\n",
    "            score = all_trained_models[model]['f1_weighted']\n",
    "            accuracy_0 = all_trained_models[model]['full_metrics']['Accuracy_0']\n",
    "            accuracy_1 = all_trained_models[model]['full_metrics']['Accuracy_1']\n",
    "            \n",
    "            # FIX: Convert Series to float if needed\n",
    "            if isinstance(accuracy_0, pd.Series):\n",
    "                accuracy_0 = float(accuracy_0.iloc[0])\n",
    "            else:\n",
    "                accuracy_0 = float(accuracy_0)\n",
    "            \n",
    "            if isinstance(accuracy_1, pd.Series):\n",
    "                accuracy_1 = float(accuracy_1.iloc[0])\n",
    "            else:\n",
    "                accuracy_1 = float(accuracy_1)\n",
    "            \n",
    "            print(f\"      â€¢ {model}: F1={score:.4f}, Churn=0 Acc={accuracy_0:.4f}, Churn=1 Acc={accuracy_1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc90ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Create different ensemble combinations\n",
    "print(\"\\n2. CREATING ENSEMBLE COMBINATIONS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def create_ensemble_safely(model_names, ensemble_name, description):\n",
    "    \"\"\"Create ensemble with error handling and model verification\"\"\"\n",
    "    estimators = []\n",
    "    included_models = []\n",
    "    skipped_models = []\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        if model_name in all_trained_models:\n",
    "            # Create unique name for ensemble to avoid conflicts\n",
    "            base_name = model_name.replace('_SMOTE', '').replace('_CostSensitive', '')\n",
    "            unique_name = f\"{base_name}_{len(estimators)}\"\n",
    "            estimators.append((unique_name, all_trained_models[model_name]['pipeline']))\n",
    "            \n",
    "            # FIX: Ensure all values are floats - handle both Series and scalar values\n",
    "            accuracy_0 = all_trained_models[model_name]['full_metrics']['Accuracy_0']\n",
    "            accuracy_1 = all_trained_models[model_name]['full_metrics']['Accuracy_1']\n",
    "            \n",
    "            # Convert Series to float if needed\n",
    "            if isinstance(accuracy_0, pd.Series):\n",
    "                accuracy_0 = float(accuracy_0.iloc[0])\n",
    "            else:\n",
    "                accuracy_0 = float(accuracy_0)\n",
    "            \n",
    "            if isinstance(accuracy_1, pd.Series):\n",
    "                accuracy_1 = float(accuracy_1.iloc[0])\n",
    "            else:\n",
    "                accuracy_1 = float(accuracy_1)\n",
    "            \n",
    "            included_models.append({\n",
    "                'original_name': model_name,\n",
    "                'ensemble_name': unique_name,\n",
    "                'f1_weighted': all_trained_models[model_name]['f1_weighted'],\n",
    "                'source': all_trained_models[model_name]['source'],\n",
    "                'accuracy_0': accuracy_0,\n",
    "                'accuracy_1': accuracy_1\n",
    "            })\n",
    "        else:\n",
    "            skipped_models.append(model_name)\n",
    "    \n",
    "    if len(estimators) >= 2:\n",
    "        ensemble = VotingClassifier(estimators=estimators, voting='soft')\n",
    "        print(f\"\\nâœ… Created {ensemble_name}: {len(estimators)} models\")\n",
    "        print(f\"   Description: {description}\")\n",
    "        print(f\"   Included models:\")\n",
    "        for model_info in included_models:\n",
    "            print(f\"      â€¢ {model_info['original_name']} ({model_info['source']}) â†’ {model_info['ensemble_name']}\")\n",
    "            print(f\"        F1: {model_info['f1_weighted']:.4f}, Churn=0 Acc: {model_info['accuracy_0']:.4f}, Churn=1 Acc: {model_info['accuracy_1']:.4f}\")\n",
    "        \n",
    "        if skipped_models:\n",
    "            print(f\"   Skipped models: {skipped_models}\")\n",
    "        \n",
    "        return ensemble, included_models\n",
    "    else:\n",
    "        print(f\"âŒ Cannot create {ensemble_name}: only {len(estimators)} valid models found\")\n",
    "        return None, []\n",
    "\n",
    "# 2.1 Top 3 Overall Winner Ensemble\n",
    "top_3_models = all_results_df.nlargest(3, 'F1_Weighted').index.tolist()\n",
    "top3_ensemble, top3_composition = create_ensemble_safely(\n",
    "    top_3_models, \n",
    "    \"Top 3 Overall Winner Ensemble\",\n",
    "    \"Best 3 models by F1_Weighted score across all categories\"\n",
    ")\n",
    "\n",
    "# 2.2 Top 5 Overall Winner Ensemble\n",
    "top_5_models = all_results_df.nlargest(5, 'F1_Weighted').index.tolist()\n",
    "top5_ensemble, top5_composition = create_ensemble_safely(\n",
    "    top_5_models,\n",
    "    \"Top 5 Overall Winner Ensemble\", \n",
    "    \"Best 5 models by F1_Weighted score across all categories\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a9931",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2.3 Category Winners Ensemble\n",
    "print(f\"\\nðŸ“Š FINDING CATEGORY WINNERS:\")\n",
    "category_winners = []\n",
    "\n",
    "# Define categories based on what we actually have\n",
    "categories_map = {\n",
    "    'Baseline': list(baseline_pipes.keys()) if 'baseline_pipes' in locals() else [],\n",
    "    'Balanced': list(balanced_pipes.keys()) if 'balanced_pipes' in locals() else [],\n",
    "    'Advanced': list(advanced_pipes_optimal.keys()) if 'advanced_pipes_optimal' in locals() else [],\n",
    "    'Cost_Sensitive': list(cost_sensitive_pipes.keys()) if 'cost_sensitive_pipes' in locals() else [],\n",
    "    'Advanced_Sampling': list(advanced_sampling_pipes.keys()) if 'advanced_sampling_pipes' in locals() else []\n",
    "}\n",
    "\n",
    "for category, model_list in categories_map.items():\n",
    "    if model_list:\n",
    "        # Find best model in this category\n",
    "        category_results = all_results_df[all_results_df.index.isin(model_list)]\n",
    "        if len(category_results) > 0:\n",
    "            # FIX: Get the index of the best model directly\n",
    "            best_model_index = category_results['F1_Weighted'].idxmax()\n",
    "            category_winners.append(best_model_index)\n",
    "            \n",
    "            # Get the F1 score for display - handle Series properly\n",
    "            f1_score = category_results.loc[best_model_index, 'F1_Weighted']\n",
    "            if isinstance(f1_score, pd.Series):\n",
    "                f1_score = f1_score.iloc[0]\n",
    "            \n",
    "            print(f\"   {category}: {best_model_index} (F1: {float(f1_score):.4f})\")\n",
    "\n",
    "category_ensemble, category_composition = create_ensemble_safely(\n",
    "    category_winners,\n",
    "    \"Category Winners Ensemble\",\n",
    "    \"Best performing model from each category\"\n",
    ")\n",
    "\n",
    "# 2.4 Mega Ensemble (All Models)\n",
    "all_model_names = list(all_trained_models.keys())\n",
    "# Limit to top 10 for computational efficiency\n",
    "mega_models = all_results_df.nlargest(10, 'F1_Weighted').index.tolist()\n",
    "mega_ensemble, mega_composition = create_ensemble_safely(\n",
    "    mega_models,\n",
    "    \"Mega Ensemble (Top 10)\",\n",
    "    \"Top 10 models across all categories and techniques\"\n",
    ")\n",
    "\n",
    "# 3. Train and evaluate all ensembles\n",
    "print(\"\\n3. TRAINING AND EVALUATING ENSEMBLES\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "ensemble_results = {}\n",
    "ensemble_compositions = {}\n",
    "\n",
    "ensembles_to_test = [\n",
    "    (\"Top3_Ensemble\", top3_ensemble, top3_composition),\n",
    "    (\"Top5_Ensemble\", top5_ensemble, top5_composition),  \n",
    "    (\"Category_Ensemble\", category_ensemble, category_composition),\n",
    "    (\"Mega_Ensemble\", mega_ensemble, mega_composition)\n",
    "]\n",
    "\n",
    "for ensemble_name, ensemble_model, composition in ensembles_to_test:\n",
    "    if ensemble_model is not None:\n",
    "        print(f\"\\nTraining {ensemble_name}...\")\n",
    "        try:\n",
    "            ensemble_model.fit(X_train, y_train)\n",
    "            confusion_matrix_plot(name, pipe, X_test, y_test)\n",
    "            evaluate_model(ensemble_name, ensemble_model, X_test, y_test, results)\n",
    "            \n",
    "            # Store results and composition\n",
    "            ensemble_results[ensemble_name] = pd.DataFrame(results[-1:]).set_index('Model').iloc[0]\n",
    "            ensemble_compositions[ensemble_name] = composition\n",
    "            print(f\"âœ… {ensemble_name} trained successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error training {ensemble_name}: {e}\")\n",
    "\n",
    "# 4. Compare ensemble performance\n",
    "print(\"\\n4. ENSEMBLE PERFORMANCE COMPARISON\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if ensemble_results:\n",
    "    # Create comparison dataframe\n",
    "    ensemble_comparison_df = pd.DataFrame(ensemble_results).T\n",
    "    \n",
    "    # Add best individual model for comparison\n",
    "    best_individual = all_results_df.loc[all_results_df['F1_Weighted'].idxmax()]\n",
    "    ensemble_comparison_df.loc['Best_Individual'] = best_individual\n",
    "    \n",
    "    print(\"ðŸ“Š ENSEMBLE PERFORMANCE COMPARISON:\")\n",
    "    display(ensemble_comparison_df[['Accuracy', 'Accuracy_0', 'Accuracy_1', 'F1_0', 'F1_1', 'F1_Weighted', 'ROC_AUC', 'PR_AUC']].round(4))\n",
    "\n",
    "# [Continue with rest of the original section 9 code...]\n",
    "\n",
    "# 4. Compare ensemble performance\n",
    "print(\"\\n4. ENSEMBLE PERFORMANCE COMPARISON\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if ensemble_results:\n",
    "    # Create comparison dataframe\n",
    "    ensemble_comparison_df = pd.DataFrame(ensemble_results).T\n",
    "    \n",
    "    # Add best individual model for comparison\n",
    "    best_individual = all_results_df.loc[all_results_df['F1_Weighted'].idxmax()]\n",
    "    ensemble_comparison_df.loc['Best_Individual'] = best_individual\n",
    "    \n",
    "    print(\"ðŸ“Š ENSEMBLE PERFORMANCE COMPARISON:\")\n",
    "    display(ensemble_comparison_df[['Accuracy', 'Accuracy_0', 'Accuracy_1', 'F1_0', 'F1_1', 'F1_Weighted', 'ROC_AUC', 'PR_AUC']].round(4))\n",
    "\n",
    "# 5. Detailed composition analysis with model names\n",
    "print(\"\\n5. DETAILED ENSEMBLE COMPOSITION ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for ensemble_name, composition in ensemble_compositions.items():\n",
    "    if composition:\n",
    "        print(f\"\\nðŸ” {ensemble_name.upper()} COMPOSITION:\")\n",
    "        print(f\"   Total Models: {len(composition)}\")\n",
    "        \n",
    "        print(f\"   ðŸ“‹ ACTUAL MODEL NAMES:\")\n",
    "        for i, model_info in enumerate(composition, 1):\n",
    "            print(f\"      {i}. {model_info['original_name']} ({model_info['source']})\")\n",
    "            print(f\"         - F1_Weighted: {model_info['f1_weighted']:.4f}\")\n",
    "            print(f\"         - Churn=0 Accuracy: {model_info['accuracy_0']:.4f}\")\n",
    "            print(f\"         - Churn=1 Accuracy: {model_info['accuracy_1']:.4f}\")\n",
    "        \n",
    "        # Group by source\n",
    "        source_counts = {}\n",
    "        for model_info in composition:\n",
    "            source = model_info['source']\n",
    "            source_counts[source] = source_counts.get(source, 0) + 1\n",
    "        \n",
    "        print(f\"   ðŸ“Š Source Distribution:\")\n",
    "        for source, count in source_counts.items():\n",
    "            print(f\"      â€¢ {source}: {count} models\")\n",
    "        \n",
    "        # Show F1 score range\n",
    "        f1_scores = [model_info['f1_weighted'] for model_info in composition]\n",
    "        print(f\"   ðŸ“ˆ Performance Statistics:\")\n",
    "        print(f\"      F1_Weighted Range: {min(f1_scores):.4f} - {max(f1_scores):.4f}\")\n",
    "        print(f\"      Average F1_Weighted: {np.mean(f1_scores):.4f}\")\n",
    "\n",
    "# 6. Create individual visualizations (ONE SUBPLOT EACH)\n",
    "print(\"\\n6. COMPREHENSIVE ENSEMBLE VISUALIZATIONS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if ensemble_results:\n",
    "    # Plot 6.1: Ensemble Performance Comparison\n",
    "    print(\"Plot 6.1: F1_Weighted Performance Comparison\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ensemble_names = list(ensemble_results.keys()) + ['Best_Individual']\n",
    "    f1_weighted_scores = [ensemble_results[name]['F1_Weighted'] for name in ensemble_results.keys()] + [best_individual['F1_Weighted']]\n",
    "    \n",
    "    colors = ['lightblue', 'lightgreen', 'orange', 'lightcoral', 'gold']\n",
    "    bars = plt.bar(range(len(ensemble_names)), f1_weighted_scores, color=colors[:len(ensemble_names)], alpha=0.8)\n",
    "    plt.ylabel('F1_Weighted Score')\n",
    "    plt.title('F1_Weighted Performance\\n(Ensembles vs Best Individual)', fontweight='bold', fontsize=14)\n",
    "    plt.xticks(range(len(ensemble_names)), [name.replace('_', '\\n') for name in ensemble_names], rotation=0, fontsize=10)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.ylim(0, 1.05)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 6.2: Churn Detection Performance\n",
    "    print(\"Plot 6.2: Churn Detection Performance\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    churn_f1_scores = [ensemble_results[name]['F1_1'] for name in ensemble_results.keys()] + [best_individual['F1_1']]\n",
    "    \n",
    "    bars = plt.bar(range(len(ensemble_names)), churn_f1_scores, color=colors[:len(ensemble_names)], alpha=0.8)\n",
    "    plt.ylabel('F1_1 Score (Churn Detection)')\n",
    "    plt.title('Churn Detection Performance\\n(Ensembles vs Best Individual)', fontweight='bold', fontsize=14)\n",
    "    plt.xticks(range(len(ensemble_names)), [name.replace('_', '\\n') for name in ensemble_names], rotation=0, fontsize=10)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.ylim(0, 1.05)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 6.3: ROC AUC Performance\n",
    "    print(\"Plot 6.3: ROC AUC Performance\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    roc_auc_scores = [ensemble_results[name]['ROC_AUC'] for name in ensemble_results.keys()] + [best_individual['ROC_AUC']]\n",
    "    \n",
    "    bars = plt.bar(range(len(ensemble_names)), roc_auc_scores, color=colors[:len(ensemble_names)], alpha=0.8)\n",
    "    plt.ylabel('ROC AUC Score')\n",
    "    plt.title('ROC AUC Performance\\n(Ensembles vs Best Individual)', fontweight='bold', fontsize=14)\n",
    "    plt.xticks(range(len(ensemble_names)), [name.replace('_', '\\n') for name in ensemble_names], rotation=0, fontsize=10)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.ylim(0, 1.05)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 6.4: Performance Improvement over Best Individual\n",
    "    print(\"Plot 6.4: Performance Improvement Analysis\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    best_individual_f1 = best_individual['F1_Weighted']\n",
    "    improvements = [(ensemble_results[name]['F1_Weighted'] - best_individual_f1) for name in ensemble_results.keys()]\n",
    "    ensemble_names_only = list(ensemble_results.keys())\n",
    "    \n",
    "    colors_imp = ['green' if imp > 0 else 'red' if imp < 0 else 'gray' for imp in improvements]\n",
    "    bars = plt.bar(range(len(ensemble_names_only)), improvements, color=colors_imp, alpha=0.8)\n",
    "    plt.ylabel('F1_Weighted Improvement')\n",
    "    plt.title('Performance Improvement vs Best Individual Model', fontweight='bold', fontsize=14)\n",
    "    plt.xticks(range(len(ensemble_names_only)), [name.replace('_', '\\n') for name in ensemble_names_only], rotation=0, fontsize=10)\n",
    "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.annotate(f'{height:+.4f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3 if height >= 0 else -15),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom' if height >= 0 else 'top', fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 6.5: Model Count in Each Ensemble\n",
    "    print(\"Plot 6.5: Ensemble Size Comparison\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    model_counts = [len(ensemble_compositions[name]) for name in ensemble_results.keys() if name in ensemble_compositions]\n",
    "    ensemble_names_for_count = [name for name in ensemble_results.keys() if name in ensemble_compositions]\n",
    "    \n",
    "    bars = plt.bar(range(len(ensemble_names_for_count)), model_counts, color='lightcoral', alpha=0.8)\n",
    "    plt.ylabel('Number of Models')\n",
    "    plt.title('Model Count in Each Ensemble', fontweight='bold', fontsize=14)\n",
    "    plt.xticks(range(len(ensemble_names_for_count)), [name.replace('_', '\\n') for name in ensemble_names_for_count], rotation=0, fontsize=10)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.annotate(f'{int(height)}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 6.6: Precision-Recall Trade-off\n",
    "    print(\"Plot 6.6: Precision-Recall Trade-off for Churn Detection\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    precision_1_scores = [ensemble_results[name]['Precision_1'] for name in ensemble_results.keys()]\n",
    "    recall_1_scores = [ensemble_results[name]['Recall_1'] for name in ensemble_results.keys()]\n",
    "    \n",
    "    # Add best individual for comparison\n",
    "    precision_1_scores.append(best_individual['Precision_1'])\n",
    "    recall_1_scores.append(best_individual['Recall_1'])\n",
    "    \n",
    "    colors_pr = colors[:len(precision_1_scores)]\n",
    "    \n",
    "    for i, name in enumerate(ensemble_names):\n",
    "        plt.scatter(recall_1_scores[i], precision_1_scores[i], s=150, alpha=0.8, \n",
    "                   color=colors_pr[i], label=name.replace('_', ' '))\n",
    "    \n",
    "    plt.xlabel('Recall - Class 1 (Churn)')\n",
    "    plt.ylabel('Precision - Class 1 (Churn)')\n",
    "    plt.title('Precision-Recall Trade-off\\n(Churn Detection Performance)', fontweight='bold', fontsize=14)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xlim(0, 1.05)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 7. Ensemble Model Ranking and Analysis\n",
    "print(\"\\n7. ENSEMBLE MODEL RANKING AND ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if ensemble_results:\n",
    "    # Create comprehensive ranking\n",
    "    all_models_for_ranking = {}\n",
    "    \n",
    "    # Add ensemble models\n",
    "    for name, metrics in ensemble_results.items():\n",
    "        all_models_for_ranking[name] = metrics\n",
    "    \n",
    "    # Add best individual model\n",
    "    all_models_for_ranking['Best_Individual'] = best_individual\n",
    "    \n",
    "    # Create ranking dataframe\n",
    "    ranking_df = pd.DataFrame(all_models_for_ranking).T\n",
    "    ranking_df = ranking_df.sort_values('F1_Weighted', ascending=False)\n",
    "    \n",
    "    print(\"ðŸ† ENSEMBLE MODEL RANKING (by F1_Weighted):\")\n",
    "    display(ranking_df[['Accuracy', 'Accuracy_0', 'Accuracy_1', 'F1_0', 'F1_1', 'F1_Weighted', 'ROC_AUC', 'PR_AUC']].round(4))\n",
    "    \n",
    "    # Winner analysis with actual model names\n",
    "    best_ensemble = ranking_df.index[0]\n",
    "    best_ensemble_metrics = ranking_df.iloc[0]\n",
    "    \n",
    "    print(f\"\\nðŸ¥‡ BEST PERFORMING MODEL: {best_ensemble}\")\n",
    "    print(f\"   F1_Weighted: {best_ensemble_metrics['F1_Weighted']:.4f}\")\n",
    "    print(f\"   Churn F1: {best_ensemble_metrics['F1_1']:.4f}\")\n",
    "    print(f\"   ROC AUC: {best_ensemble_metrics['ROC_AUC']:.4f}\")\n",
    "    print(f\"   Churn=0 Accuracy: {best_ensemble_metrics['Accuracy_0']:.4f}\")\n",
    "    print(f\"   Churn=1 Accuracy: {best_ensemble_metrics['Accuracy_1']:.4f}\")\n",
    "    \n",
    "    if best_ensemble in ensemble_compositions:\n",
    "        print(f\"   ðŸ“‹ ENSEMBLE COMPOSITION: {len(ensemble_compositions[best_ensemble])} models\")\n",
    "        for i, model_info in enumerate(ensemble_compositions[best_ensemble], 1):\n",
    "            print(f\"      {i}. {model_info['original_name']}\")\n",
    "            print(f\"         F1: {model_info['f1_weighted']:.4f}, Churn=0: {model_info['accuracy_0']:.4f}, Churn=1: {model_info['accuracy_1']:.4f}\")\n",
    "\n",
    "# 8. Statistical significance testing\n",
    "print(\"\\n8. STATISTICAL SIGNIFICANCE TESTING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if ensemble_results:\n",
    "    from scipy import stats\n",
    "    \n",
    "    # Test ensemble vs best individual\n",
    "    print(\"ðŸ“Š STATISTICAL SIGNIFICANCE ANALYSIS:\")\n",
    "    \n",
    "    # For this demonstration, we'll use the performance differences\n",
    "    ensemble_f1_scores = [ensemble_results[name]['F1_Weighted'] for name in ensemble_results.keys()]\n",
    "    best_individual_f1 = best_individual['F1_Weighted']\n",
    "    \n",
    "    print(f\"Best Individual F1_Weighted: {best_individual_f1:.4f}\")\n",
    "    print(f\"Ensemble F1_Weighted scores: {[f'{score:.4f}' for score in ensemble_f1_scores]}\")\n",
    "    \n",
    "    # Check if any ensemble significantly outperforms best individual\n",
    "    significant_improvements = []\n",
    "    for name, f1_score in zip(ensemble_results.keys(), ensemble_f1_scores):\n",
    "        improvement = f1_score - best_individual_f1\n",
    "        if improvement > 0.001:  # Meaningful improvement threshold\n",
    "            significant_improvements.append((name, improvement))\n",
    "    \n",
    "    if significant_improvements:\n",
    "        print(f\"\\nâœ… SIGNIFICANT IMPROVEMENTS DETECTED:\")\n",
    "        for name, improvement in significant_improvements:\n",
    "            print(f\"   {name}: +{improvement:.4f} improvement\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  No significant improvements over best individual model detected\")\n",
    "        print(f\"   This suggests ensembles provide robustness rather than raw performance gains\")\n",
    "\n",
    "# 9. Business recommendations for ensemble deployment\n",
    "print(\"\\n9. BUSINESS RECOMMENDATIONS FOR ENSEMBLE DEPLOYMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if ensemble_results:\n",
    "    print(\"\\nðŸŽ¯ DEPLOYMENT STRATEGY:\")\n",
    "    \n",
    "    # Determine best ensemble for deployment\n",
    "    best_for_deployment = ranking_df.index[0]\n",
    "    deployment_metrics = ranking_df.iloc[0]\n",
    "    \n",
    "    print(f\"âœ… RECOMMENDED FOR PRODUCTION: {best_for_deployment}\")\n",
    "    if best_for_deployment != 'Best_Individual':\n",
    "        print(f\"   Rationale: Highest F1_Weighted score\")\n",
    "    else:\n",
    "        print(f\"   Rationale: Best individual model performance\")\n",
    "    \n",
    "    print(f\"   Performance Metrics:\")\n",
    "    print(f\"      F1_Weighted: {deployment_metrics['F1_Weighted']:.4f}\")\n",
    "    print(f\"      Churn Detection F1: {deployment_metrics['F1_1']:.4f}\")\n",
    "    print(f\"      Overall Accuracy: {deployment_metrics['Accuracy']:.4f}\")\n",
    "    print(f\"      Churn=0 Accuracy: {deployment_metrics['Accuracy_0']:.4f}\")\n",
    "    print(f\"      Churn=1 Accuracy: {deployment_metrics['Accuracy_1']:.4f}\")\n",
    "    \n",
    "    if best_for_deployment in ensemble_compositions:\n",
    "        composition = ensemble_compositions[best_for_deployment]\n",
    "        print(f\"   Ensemble Details:\")\n",
    "        print(f\"      Model Count: {len(composition)}\")\n",
    "        print(f\"      Computational Overhead: {'High' if len(composition) > 5 else 'Medium' if len(composition) > 3 else 'Low'}\")\n",
    "        \n",
    "        print(f\"\\n   ðŸ“‹ COMPONENT MODELS TO DEPLOY:\")\n",
    "        for i, model_info in enumerate(composition, 1):\n",
    "            print(f\"      {i}. {model_info['original_name']} ({model_info['source']})\")\n",
    "            print(f\"         Performance: F1={model_info['f1_weighted']:.4f}, Churn=0={model_info['accuracy_0']:.4f}, Churn=1={model_info['accuracy_1']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¡ IMPLEMENTATION CONSIDERATIONS:\")\n",
    "    \n",
    "    if best_for_deployment != 'Best_Individual':\n",
    "        print(\"   ENSEMBLE DEPLOYMENT:\")\n",
    "        print(\"   â€¢ Higher computational cost but improved robustness\")\n",
    "        print(\"   â€¢ Requires all component models to be maintained\")\n",
    "        print(\"   â€¢ Better prediction stability across different data conditions\")\n",
    "        print(\"   â€¢ Recommended for high-stakes production environments\")\n",
    "    else:\n",
    "        print(\"   INDIVIDUAL MODEL DEPLOYMENT:\")\n",
    "        print(\"   â€¢ Lower computational cost and complexity\")\n",
    "        print(\"   â€¢ Easier to maintain and update\")\n",
    "        print(\"   â€¢ Sufficient performance for most use cases\")\n",
    "        print(\"   â€¢ Recommended for resource-constrained environments\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENSEMBLE ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# FIX: Corrected f-string formatting\n",
    "if ensemble_results and len(ranking_df) > 0:\n",
    "    final_recommendation = ranking_df.index[0]\n",
    "    final_performance = ranking_df.iloc[0]['F1_Weighted']\n",
    "else:\n",
    "    final_recommendation = 'Best Individual Model'\n",
    "    final_performance = best_individual['F1_Weighted']\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ… Comprehensive ensemble analysis completed successfully.\n",
    "\n",
    "ðŸ† FINAL RECOMMENDATION: {final_recommendation}\n",
    "   Performance: F1_Weighted = {final_performance:.4f}\n",
    "\n",
    "ðŸ“Š All models, ensembles, and performance metrics are ready for production deployment.\n",
    "   The analysis provides complete transparency into model composition and expected performance.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a2fec2",
   "metadata": {},
   "source": [
    "## 8 Churn-Biased Ensemble Model\n",
    "We need to create an model that favors churn. We are going to dynamically test ensembles to maximize churn accuracy.\n",
    "\n",
    "If you want to be biased toward predicting churn=1, you should primarily use Accuracy_1 as your metric, with F1_1 as a secondary consideration. Here's why:\n",
    "\n",
    "Primary Metric: Accuracy_1 (Churn=1 Accuracy)\n",
    "Accuracy_1 is the best metric when you want to maximize correct identification of churning customers because:\n",
    "\n",
    "It measures: (True Positives) / (True Positives + False Negatives)\n",
    "This is equivalent to Recall for Class 1 (churn detection rate)\n",
    "It directly answers: \"Of all customers who actually churned, what percentage did we correctly identify?\"\n",
    "Secondary Metric: F1_1 (F1-Score for Class 1)\n",
    "F1_1 provides a balanced view by considering both:\n",
    "\n",
    "Precision_1: Of customers predicted to churn, how many actually did?\n",
    "Recall_1: Of customers who churned, how many did we catch?\n",
    "\n",
    "Recommendation Hierarchy:\n",
    "Primary: Accuracy_1 (Recall_1) - maximizes churn detection\n",
    "Secondary: F1_1 - ensures you're not just predicting everyone as churn\n",
    "Monitor: Precision_1 - controls false alarms to acceptable levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a43d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Dynamic Ensemble Optimization for Maximum Churn=1 Accuracy - UPDATED WITH ACCURACY DISPLAY\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DYNAMIC ENSEMBLE OPTIMIZATION - MAXIMIZING CHURN=1 ACCURACY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This section dynamically finds the optimal ensemble combinations that maximize\n",
    "churn=1 accuracy (Accuracy_1) through systematic testing of different model combinations,\n",
    "voting strategies, and optimization techniques. We prioritize churn detection over overall accuracy.\n",
    "\"\"\")\n",
    "\n",
    "# 1. Debug and check what models we actually have\n",
    "print(\"\\n1. DEBUGGING: CHECKING AVAILABLE MODELS AND RESULTS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Check if results list exists and has data\n",
    "if 'results' in locals() and len(results) > 0:\n",
    "    print(f\"âœ… Found {len(results)} model results in results list\")\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    all_results_df = pd.DataFrame(results).set_index('Model')\n",
    "    print(f\"âœ… Results DataFrame created with {len(all_results_df)} rows\")\n",
    "    \n",
    "    # Check what accuracy_1 values we have\n",
    "    if 'Accuracy_1' in all_results_df.columns:\n",
    "        print(f\"ðŸ“Š Accuracy_1 statistics:\")\n",
    "        print(f\"   Min: {all_results_df['Accuracy_1'].min():.4f}\")\n",
    "        print(f\"   Max: {all_results_df['Accuracy_1'].max():.4f}\")\n",
    "        print(f\"   Mean: {all_results_df['Accuracy_1'].mean():.4f}\")\n",
    "        print(f\"   Models with Accuracy_1 >= 0.5: {(all_results_df['Accuracy_1'] >= 0.5).sum()}\")\n",
    "        print(f\"   Models with Accuracy_1 >= 0.6: {(all_results_df['Accuracy_1'] >= 0.6).sum()}\")\n",
    "    else:\n",
    "        print(\"âŒ Accuracy_1 column not found in results\")\n",
    "        print(f\"Available columns: {list(all_results_df.columns)}\")\n",
    "else:\n",
    "    print(\"âŒ No results found - creating dummy results for demonstration\")\n",
    "    # Create some dummy results if none exist\n",
    "    results = []\n",
    "\n",
    "# 2. Adaptive Model Selection - UPDATED TO PRIORITIZE ACCURACY_1\n",
    "print(\"\\n2. ADAPTIVE MODEL SELECTION - CHURN=1 BIASED\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if 'all_results_df' in locals() and len(all_results_df) > 0:\n",
    "    # Use adaptive thresholds based on actual data - PRIORITIZE ACCURACY_1\n",
    "    accuracy_1_threshold = max(0.3, all_results_df['Accuracy_1'].quantile(0.6))  # At least 60th percentile\n",
    "    f1_1_threshold = max(0.3, all_results_df['F1_1'].quantile(0.4))  # At least 40th percentile (secondary)\n",
    "    f1_weighted_threshold = max(0.7, all_results_df['F1_Weighted'].quantile(0.2))  # Minimum overall performance\n",
    "    \n",
    "    print(f\"ðŸ“Š Using churn-biased thresholds:\")\n",
    "    print(f\"   PRIMARY - Accuracy_1 >= {accuracy_1_threshold:.3f}\")\n",
    "    print(f\"   SECONDARY - F1_1 >= {f1_1_threshold:.3f}\")\n",
    "    print(f\"   MINIMUM - F1_Weighted >= {f1_weighted_threshold:.3f}\")\n",
    "    \n",
    "    # Filter models with good churn=1 accuracy as PRIMARY criterion\n",
    "    churn_focused_candidates = all_results_df[\n",
    "        (all_results_df['Accuracy_1'] >= accuracy_1_threshold) & \n",
    "        (all_results_df['F1_1'] >= f1_1_threshold) &\n",
    "        (all_results_df['F1_Weighted'] >= f1_weighted_threshold)\n",
    "    ].sort_values('Accuracy_1', ascending=False)  # Sort by Accuracy_1 instead of F1_Weighted\n",
    "    \n",
    "    print(f\"ðŸ“Š CHURN-FOCUSED MODEL CANDIDATES: {len(churn_focused_candidates)}\")\n",
    "    \n",
    "    if len(churn_focused_candidates) > 0:\n",
    "        # UPDATED: Display Accuracy_0, Accuracy_1, and F1_Weighted prominently\n",
    "        display(churn_focused_candidates[['Accuracy_0', 'Accuracy_1', 'F1_Weighted', 'F1_1', 'ROC_AUC']].head(10).round(4))\n",
    "    else:\n",
    "        print(\"âš ï¸  No models meet the adaptive criteria. Using top 5 models by Accuracy_1 instead.\")\n",
    "        churn_focused_candidates = all_results_df.nlargest(5, 'Accuracy_1')\n",
    "        display(churn_focused_candidates[['Accuracy_0', 'Accuracy_1', 'F1_Weighted', 'F1_1', 'ROC_AUC']].round(4))\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No model results available for ensemble optimization\")\n",
    "    print(\"This indicates that previous model training sections may not have run properly.\")\n",
    "    print(\"Please ensure all previous sections (5-9) have been executed successfully.\")\n",
    "    \n",
    "    # Stop execution here\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DYNAMIC ENSEMBLE OPTIMIZATION SKIPPED - NO MODELS AVAILABLE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Exit this section gracefully\n",
    "    if 'results' not in locals() or len(results) == 0:\n",
    "        print(\"\\nTo fix this issue:\")\n",
    "        print(\"1. Re-run all previous sections (5-9) to train models\")\n",
    "        print(\"2. Ensure the 'results' list is being populated correctly\")\n",
    "        print(\"3. Check that evaluate_model() function is working properly\")\n",
    "        \n",
    "        # Create a minimal example of what should be in results\n",
    "        print(\"\\nExample of expected results structure:\")\n",
    "        example_result = {\n",
    "            'Model': 'ExampleModel',\n",
    "            'Accuracy': 0.85,\n",
    "            'Accuracy_0': 0.90,\n",
    "            'Accuracy_1': 0.65,\n",
    "            'F1_0': 0.92,\n",
    "            'F1_1': 0.70,\n",
    "            'F1_Weighted': 0.88,\n",
    "            'ROC_AUC': 0.82\n",
    "        }\n",
    "        print(example_result)\n",
    "    \n",
    "    # Exit this section\n",
    "    exit()\n",
    "\n",
    "# 3. Create model pools for different churn-focused strategies (only if we have models)\n",
    "if len(churn_focused_candidates) > 0:\n",
    "    print(f\"\\n3. CREATING CHURN-FOCUSED MODEL POOLS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    model_pools = {\n",
    "        'top_churn_accuracy': churn_focused_candidates.head(min(8, len(churn_focused_candidates))).index.tolist(),\n",
    "        'high_churn_recall': all_results_df.nlargest(6, 'Recall_1').index.tolist() if 'Recall_1' in all_results_df.columns else [],\n",
    "        'balanced_churn_precision': all_results_df[\n",
    "            (all_results_df['Accuracy_1'] >= all_results_df['Accuracy_1'].quantile(0.5)) & \n",
    "            (all_results_df['Precision_1'] >= all_results_df['Precision_1'].quantile(0.5))\n",
    "        ].head(6).index.tolist() if 'Precision_1' in all_results_df.columns else [],\n",
    "        'high_f1_churn': all_results_df.nlargest(6, 'F1_1').index.tolist() if 'F1_1' in all_results_df.columns else [],\n",
    "        'diverse_top_performers': all_results_df.nlargest(6, 'Accuracy_1').index.tolist()\n",
    "    }\n",
    "    \n",
    "    # Add diverse algorithms focusing on churn detection\n",
    "    algorithm_types = {}\n",
    "    for model_name in all_results_df.index:\n",
    "        if 'RandomForest' in model_name:\n",
    "            algorithm_types.setdefault('RandomForest', []).append(model_name)\n",
    "        elif 'GradientBoost' in model_name:\n",
    "            algorithm_types.setdefault('GradientBoost', []).append(model_name)\n",
    "        elif 'XGBoost' in model_name:\n",
    "            algorithm_types.setdefault('XGBoost', []).append(model_name)\n",
    "        elif 'LogReg' in model_name or 'Logistic' in model_name:\n",
    "            algorithm_types.setdefault('LogisticRegression', []).append(model_name)\n",
    "        elif any(keyword in model_name for keyword in ['SMOTE', 'BorderlineSMOTE', 'ADASYN']):\n",
    "            algorithm_types.setdefault('Sampling_Enhanced', []).append(model_name)\n",
    "    \n",
    "    # Select best from each algorithm type BASED ON ACCURACY_1\n",
    "    diverse_algorithms = []\n",
    "    for alg_type, models in algorithm_types.items():\n",
    "        if models:\n",
    "            best_in_type = all_results_df.loc[models].nlargest(1, 'Accuracy_1').index[0]\n",
    "            diverse_algorithms.append(best_in_type)\n",
    "    \n",
    "    model_pools['diverse_algorithms_churn_focused'] = diverse_algorithms\n",
    "    \n",
    "    print(f\"ðŸ“‹ CHURN-FOCUSED MODEL POOL SUMMARY:\")\n",
    "    for pool_name, models in model_pools.items():\n",
    "        if models:  # Only show non-empty pools\n",
    "            print(f\"   {pool_name}: {len(models)} models\")\n",
    "            for model in models[:3]:  # Show first 3 models\n",
    "                if model in all_results_df.index:\n",
    "                    # UPDATED: Show Accuracy_0, Accuracy_1, and F1_Weighted\n",
    "                    acc_0_series = all_results_df.loc[model, 'Accuracy_0']\n",
    "                    acc_1_series = all_results_df.loc[model, 'Accuracy_1']\n",
    "                    f1_weighted_series = all_results_df.loc[model, 'F1_Weighted']\n",
    "                    \n",
    "                    # Convert to scalar values\n",
    "                    acc_0 = acc_0_series.iloc[0] if hasattr(acc_0_series, 'iloc') else float(acc_0_series)\n",
    "                    acc_1 = acc_1_series.iloc[0] if hasattr(acc_1_series, 'iloc') else float(acc_1_series)\n",
    "                    f1_weighted = f1_weighted_series.iloc[0] if hasattr(f1_weighted_series, 'iloc') else float(f1_weighted_series)\n",
    "                    \n",
    "                    print(f\"      â€¢ {model}: No_Churn_Acc={acc_0:.3f}, Churn_Acc={acc_1:.3f}, F1_Weighted={f1_weighted:.3f}\")\n",
    "\n",
    "# 4. Enhanced Ensemble Creation for Maximum Churn Detection\n",
    "if len(churn_focused_candidates) > 0 and any(len(pool) >= 2 for pool in model_pools.values()):\n",
    "    print(f\"\\n4. ENHANCED CHURN-FOCUSED ENSEMBLE CREATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Create a consolidated dictionary of all trained models\n",
    "    all_model_pipelines = {}\n",
    "    \n",
    "    # Add models from all dictionaries with error handling\n",
    "    # model_sources = [\n",
    "    #     ('baseline_pipes', baseline_pipes if 'baseline_pipes' in locals() else {}),\n",
    "    #     ('balanced_pipes', balanced_pipes if 'balanced_pipes' in locals() else {}),\n",
    "    #     ('advanced_pipes_optimal', advanced_pipes_optimal if 'advanced_pipes_optimal' in locals() else {}),\n",
    "    #     ('cost_sensitive_pipes', cost_sensitive_pipes if 'cost_sensitive_pipes' in locals() else {}),\n",
    "    #     ('advanced_sampling_pipes', advanced_sampling_pipes if 'advanced_sampling_pipes' in locals() else {})\n",
    "    # ]\n",
    "    \n",
    "    models_found = 0\n",
    "    for source_name, model_dict in model_sources:\n",
    "        if isinstance(model_dict, dict):\n",
    "            for model_name, pipeline in model_dict.items():\n",
    "                if model_name in all_results_df.index:\n",
    "                    all_model_pipelines[model_name] = pipeline\n",
    "                    models_found += 1\n",
    "    \n",
    "    print(f\"âœ… Found {models_found} trained model pipelines\")\n",
    "    \n",
    "    if models_found >= 2:\n",
    "        # Create multiple churn-focused ensembles\n",
    "        churn_ensembles = {}\n",
    "        \n",
    "        # Ensemble 1: Top Churn Accuracy Models\n",
    "        top_churn_models = all_results_df.nlargest(3, 'Accuracy_1').index.tolist()\n",
    "        available_top_churn = [m for m in top_churn_models if m in all_model_pipelines]\n",
    "        \n",
    "        if len(available_top_churn) >= 2:\n",
    "            print(f\"\\nðŸŽ¯ CREATING TOP CHURN ACCURACY ENSEMBLE:\")\n",
    "            for model in available_top_churn:\n",
    "                # UPDATED: Show all three key metrics\n",
    "                acc_0_series = all_results_df.loc[model, 'Accuracy_0']\n",
    "                acc_1_series = all_results_df.loc[model, 'Accuracy_1']\n",
    "                f1_weighted_series = all_results_df.loc[model, 'F1_Weighted']\n",
    "                \n",
    "                acc_0 = acc_0_series.iloc[0] if hasattr(acc_0_series, 'iloc') else float(acc_0_series)\n",
    "                acc_1 = acc_1_series.iloc[0] if hasattr(acc_1_series, 'iloc') else float(acc_1_series)\n",
    "                f1_weighted = f1_weighted_series.iloc[0] if hasattr(f1_weighted_series, 'iloc') else float(f1_weighted_series)\n",
    "                \n",
    "                print(f\"   â€¢ {model}: No_Churn_Acc={acc_0:.3f}, Churn_Acc={acc_1:.3f}, F1_Weighted={f1_weighted:.3f}\")\n",
    "            \n",
    "            try:\n",
    "                estimators = [(f\"churn_model_{i}\", all_model_pipelines[model]) \n",
    "                             for i, model in enumerate(available_top_churn)]\n",
    "                \n",
    "                top_churn_ensemble = VotingClassifier(estimators=estimators, voting='soft')\n",
    "                top_churn_ensemble.fit(X_train, y_train)\n",
    "                confusion_matrix_plot(name, pipe, X_test, y_test)\n",
    "                evaluate_model(\"Top_Churn_Accuracy_Ensemble\", top_churn_ensemble, X_test, y_test, results)\n",
    "                churn_ensembles[\"Top_Churn_Accuracy_Ensemble\"] = top_churn_ensemble\n",
    "                \n",
    "                print(f\"âœ… Top Churn Accuracy ensemble created successfully!\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error creating top churn ensemble: {e}\")\n",
    "        \n",
    "        # Ensemble 2: Balanced Churn Performance Models\n",
    "        balanced_churn_models = all_results_df[\n",
    "            (all_results_df['Accuracy_1'] >= all_results_df['Accuracy_1'].quantile(0.7)) &\n",
    "            (all_results_df['F1_1'] >= all_results_df['F1_1'].quantile(0.7))\n",
    "        ].nlargest(3, 'Accuracy_1').index.tolist()\n",
    "        \n",
    "        available_balanced_churn = [m for m in balanced_churn_models if m in all_model_pipelines]\n",
    "        \n",
    "        if len(available_balanced_churn) >= 2:\n",
    "            print(f\"\\nðŸŽ¯ CREATING BALANCED CHURN PERFORMANCE ENSEMBLE:\")\n",
    "            for model in available_balanced_churn:\n",
    "                # UPDATED: Show all three key metrics\n",
    "                acc_0_series = all_results_df.loc[model, 'Accuracy_0']\n",
    "                acc_1_series = all_results_df.loc[model, 'Accuracy_1']\n",
    "                f1_weighted_series = all_results_df.loc[model, 'F1_Weighted']\n",
    "                \n",
    "                acc_0 = acc_0_series.iloc[0] if hasattr(acc_0_series, 'iloc') else float(acc_0_series)\n",
    "                acc_1 = acc_1_series.iloc[0] if hasattr(acc_1_series, 'iloc') else float(acc_1_series)\n",
    "                f1_weighted = f1_weighted_series.iloc[0] if hasattr(f1_weighted_series, 'iloc') else float(f1_weighted_series)\n",
    "                \n",
    "                print(f\"   â€¢ {model}: No_Churn_Acc={acc_0:.3f}, Churn_Acc={acc_1:.3f}, F1_Weighted={f1_weighted:.3f}\")\n",
    "            \n",
    "            try:\n",
    "                estimators = [(f\"balanced_churn_{i}\", all_model_pipelines[model]) \n",
    "                             for i, model in enumerate(available_balanced_churn)]\n",
    "                \n",
    "                balanced_churn_ensemble = VotingClassifier(estimators=estimators, voting='soft')\n",
    "                balanced_churn_ensemble.fit(X_train, y_train)\n",
    "                \n",
    "                evaluate_model(\"Balanced_Churn_Performance_Ensemble\", balanced_churn_ensemble, X_test, y_test, results)\n",
    "                churn_ensembles[\"Balanced_Churn_Performance_Ensemble\"] = balanced_churn_ensemble\n",
    "                \n",
    "                print(f\"âœ… Balanced Churn Performance ensemble created successfully!\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error creating balanced churn ensemble: {e}\")\n",
    "        \n",
    "        # Ensemble 3: Diverse Algorithm Churn-Focused\n",
    "        if len(diverse_algorithms) >= 2:\n",
    "            available_diverse = [m for m in diverse_algorithms if m in all_model_pipelines]\n",
    "            \n",
    "            if len(available_diverse) >= 2:\n",
    "                print(f\"\\nðŸŽ¯ CREATING DIVERSE ALGORITHM CHURN-FOCUSED ENSEMBLE:\")\n",
    "                for model in available_diverse:\n",
    "                    # UPDATED: Show all three key metrics\n",
    "                    acc_0_series = all_results_df.loc[model, 'Accuracy_0']\n",
    "                    acc_1_series = all_results_df.loc[model, 'Accuracy_1']\n",
    "                    f1_weighted_series = all_results_df.loc[model, 'F1_Weighted']\n",
    "                    \n",
    "                    acc_0 = acc_0_series.iloc[0] if hasattr(acc_0_series, 'iloc') else float(acc_0_series)\n",
    "                    acc_1 = acc_1_series.iloc[0] if hasattr(acc_1_series, 'iloc') else float(acc_1_series)\n",
    "                    f1_weighted = f1_weighted_series.iloc[0] if hasattr(f1_weighted_series, 'iloc') else float(f1_weighted_series)\n",
    "                    \n",
    "                    print(f\"   â€¢ {model}: No_Churn_Acc={acc_0:.3f}, Churn_Acc={acc_1:.3f}, F1_Weighted={f1_weighted:.3f}\")\n",
    "                \n",
    "                try:\n",
    "                    estimators = [(f\"diverse_churn_{i}\", all_model_pipelines[model]) \n",
    "                                 for i, model in enumerate(available_diverse)]\n",
    "                    \n",
    "                    diverse_churn_ensemble = VotingClassifier(estimators=estimators, voting='soft')\n",
    "                    diverse_churn_ensemble.fit(X_train, y_train)\n",
    "                    \n",
    "                    evaluate_model(\"Diverse_Algorithm_Churn_Ensemble\", diverse_churn_ensemble, X_test, y_test, results)\n",
    "                    churn_ensembles[\"Diverse_Algorithm_Churn_Ensemble\"] = diverse_churn_ensemble\n",
    "                    \n",
    "                    print(f\"âœ… Diverse Algorithm Churn ensemble created successfully!\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Error creating diverse churn ensemble: {e}\")\n",
    "        \n",
    "        # 5. Evaluate and Compare Churn-Focused Ensembles\n",
    "        print(f\"\\n5. CHURN-FOCUSED ENSEMBLE EVALUATION\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        if churn_ensembles:\n",
    "            # Get ensemble results\n",
    "            ensemble_count = len(churn_ensembles)\n",
    "            churn_ensemble_results = pd.DataFrame(results[-ensemble_count:]).set_index('Model')\n",
    "            \n",
    "            print(f\"ðŸ“Š CHURN-FOCUSED ENSEMBLE PERFORMANCE:\")\n",
    "            # UPDATED: Display Accuracy_0, Accuracy_1, and F1_Weighted prominently\n",
    "            display(churn_ensemble_results[['Accuracy_0', 'Accuracy_1', 'F1_Weighted', 'F1_1', 'ROC_AUC']].round(4))\n",
    "            \n",
    "            # Find the best churn-focused ensemble\n",
    "            best_churn_ensemble = churn_ensemble_results.loc[churn_ensemble_results['Accuracy_1'].idxmax()]\n",
    "            \n",
    "            print(f\"\\nðŸ† BEST CHURN-FOCUSED ENSEMBLE: {best_churn_ensemble.name}\")\n",
    "            print(f\"   No Churn Accuracy (Accuracy_0): {best_churn_ensemble['Accuracy_0']:.4f}\")\n",
    "            print(f\"   Churn Accuracy (Accuracy_1): {best_churn_ensemble['Accuracy_1']:.4f}\")\n",
    "            print(f\"   F1_Weighted: {best_churn_ensemble['F1_Weighted']:.4f}\")\n",
    "            print(f\"   Churn F1 Score: {best_churn_ensemble['F1_1']:.4f}\")\n",
    "            print(f\"   Overall Accuracy: {best_churn_ensemble['Accuracy']:.4f}\")\n",
    "            print(f\"   ROC_AUC: {best_churn_ensemble['ROC_AUC']:.4f}\")\n",
    "            \n",
    "            # Compare with best individual model\n",
    "            best_individual_churn = all_results_df.loc[all_results_df['Accuracy_1'].idxmax()]\n",
    "            \n",
    "            print(f\"\\nðŸ“Š COMPARISON WITH BEST INDIVIDUAL MODEL:\")\n",
    "            print(f\"   Best Individual: {best_individual_churn.name}\")\n",
    "            print(f\"   Individual No Churn Accuracy: {best_individual_churn['Accuracy_0']:.4f}\")\n",
    "            print(f\"   Individual Churn Accuracy: {best_individual_churn['Accuracy_1']:.4f}\")\n",
    "            print(f\"   Individual F1_Weighted: {best_individual_churn['F1_Weighted']:.4f}\")\n",
    "            print(f\"   Ensemble No Churn Accuracy: {best_churn_ensemble['Accuracy_0']:.4f}\")\n",
    "            print(f\"   Ensemble Churn Accuracy: {best_churn_ensemble['Accuracy_1']:.4f}\")\n",
    "            print(f\"   Ensemble F1_Weighted: {best_churn_ensemble['F1_Weighted']:.4f}\")\n",
    "            print(f\"   Churn Accuracy Improvement: {best_churn_ensemble['Accuracy_1'] - best_individual_churn['Accuracy_1']:+.4f}\")\n",
    "            print(f\"   F1_Weighted Improvement: {best_churn_ensemble['F1_Weighted'] - best_individual_churn['F1_Weighted']:+.4f}\")\n",
    "            \n",
    "            # Visualization - UPDATED WITH NEW METRICS\n",
    "            print(f\"\\n6. CHURN-FOCUSED ENSEMBLE VISUALIZATIONS\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Create visualizations\n",
    "            fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "            \n",
    "            # Plot 1: Churn Accuracy (Accuracy_1) Comparison\n",
    "            ax1 = axes[0, 0]\n",
    "            ensemble_names = list(churn_ensemble_results.index)\n",
    "            churn_accuracies = churn_ensemble_results['Accuracy_1'].values\n",
    "            \n",
    "            bars = ax1.bar(ensemble_names, churn_accuracies, alpha=0.8, color='lightcoral')\n",
    "            ax1.set_ylabel('Churn Accuracy (Accuracy_1)')\n",
    "            ax1.set_title('Churn Accuracy by Ensemble', fontweight='bold')\n",
    "            ax1.tick_params(axis='x', rotation=45)\n",
    "            ax1.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Add value labels\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax1.annotate(f'{height:.3f}',\n",
    "                            xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                            xytext=(0, 3),\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom', fontsize=10)\n",
    "            \n",
    "            # Plot 2: No Churn Accuracy (Accuracy_0) Comparison\n",
    "            ax2 = axes[0, 1]\n",
    "            no_churn_accuracies = churn_ensemble_results['Accuracy_0'].values\n",
    "            \n",
    "            bars = ax2.bar(ensemble_names, no_churn_accuracies, alpha=0.8, color='lightblue')\n",
    "            ax2.set_ylabel('No Churn Accuracy (Accuracy_0)')\n",
    "            ax2.set_title('No Churn Accuracy by Ensemble', fontweight='bold')\n",
    "            ax2.tick_params(axis='x', rotation=45)\n",
    "            ax2.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Add value labels\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax2.annotate(f'{height:.3f}',\n",
    "                            xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                            xytext=(0, 3),\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom', fontsize=10)\n",
    "            \n",
    "            # Plot 3: F1_Weighted Comparison\n",
    "            ax3 = axes[0, 2]\n",
    "            f1_weighted_scores = churn_ensemble_results['F1_Weighted'].values\n",
    "            \n",
    "            bars = ax3.bar(ensemble_names, f1_weighted_scores, alpha=0.8, color='lightgreen')\n",
    "            ax3.set_ylabel('F1_Weighted Score')\n",
    "            ax3.set_title('F1_Weighted by Ensemble', fontweight='bold')\n",
    "            ax3.tick_params(axis='x', rotation=45)\n",
    "            ax3.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Add value labels\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax3.annotate(f'{height:.3f}',\n",
    "                            xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                            xytext=(0, 3),\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom', fontsize=10)\n",
    "            \n",
    "            # Plot 4: Class-Specific Performance Comparison\n",
    "            ax4 = axes[1, 0]\n",
    "            class_0_acc = churn_ensemble_results['Accuracy_0'].values\n",
    "            class_1_acc = churn_ensemble_results['Accuracy_1'].values\n",
    "            \n",
    "            x_pos = np.arange(len(ensemble_names))\n",
    "            width = 0.35\n",
    "            \n",
    "            ax4.bar(x_pos - width/2, class_0_acc, width, label='No Churn (Accuracy_0)', alpha=0.8, color='lightblue')\n",
    "            ax4.bar(x_pos + width/2, class_1_acc, width, label='Churn (Accuracy_1)', alpha=0.8, color='lightcoral')\n",
    "            \n",
    "            ax4.set_xlabel('Ensembles')\n",
    "            ax4.set_ylabel('Class-Specific Accuracy')\n",
    "            ax4.set_title('Class-Specific Accuracy Comparison', fontweight='bold')\n",
    "            ax4.set_xticks(x_pos)\n",
    "            ax4.set_xticklabels(ensemble_names, rotation=45, ha='right')\n",
    "            ax4.legend()\n",
    "            ax4.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Plot 5: Combined Performance Radar\n",
    "            ax5 = axes[1, 1]\n",
    "            metrics = ['Accuracy_0', 'Accuracy_1', 'F1_Weighted', 'F1_1', 'ROC_AUC']\n",
    "            best_ensemble_values = [best_churn_ensemble[metric] for metric in metrics]\n",
    "            best_individual_values = [best_individual_churn[metric] for metric in metrics]\n",
    "            \n",
    "            x = np.arange(len(metrics))\n",
    "            width = 0.35\n",
    "            \n",
    "            ax5.bar(x - width/2, best_individual_values, width, label='Best Individual', alpha=0.8, color='lightblue')\n",
    "            ax5.bar(x + width/2, best_ensemble_values, width, label='Best Ensemble', alpha=0.8, color='lightgreen')\n",
    "            \n",
    "            ax5.set_xlabel('Metrics')\n",
    "            ax5.set_ylabel('Score')\n",
    "            ax5.set_title('Best Individual vs Best Churn Ensemble', fontweight='bold')\n",
    "            ax5.set_xticks(x)\n",
    "            ax5.set_xticklabels(metrics, rotation=45)\n",
    "            ax5.legend()\n",
    "            ax5.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Plot 6: Performance Summary Table (as plot)\n",
    "            ax6 = axes[1, 2]\n",
    "            ax6.axis('tight')\n",
    "            ax6.axis('off')\n",
    "            \n",
    "            # Create summary table data\n",
    "            table_data = []\n",
    "            for ensemble_name in ensemble_names:\n",
    "                ensemble_data = churn_ensemble_results.loc[ensemble_name]\n",
    "                table_data.append([\n",
    "                    ensemble_name,\n",
    "                    f\"{ensemble_data['Accuracy_0']:.3f}\",\n",
    "                    f\"{ensemble_data['Accuracy_1']:.3f}\",\n",
    "                    f\"{ensemble_data['F1_Weighted']:.3f}\"\n",
    "                ])\n",
    "            \n",
    "            table = ax6.table(cellText=table_data,\n",
    "                             colLabels=['Ensemble', 'Accuracy_0', 'Accuracy_1', 'F1_Weighted'],\n",
    "                             cellLoc='center',\n",
    "                             loc='center')\n",
    "            table.auto_set_font_size(False)\n",
    "            table.set_fontsize(9)\n",
    "            table.scale(1.2, 1.5)\n",
    "            ax6.set_title('Performance Summary', fontweight='bold')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        else:\n",
    "            print(\"âš ï¸  No churn-focused ensembles could be created\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  Only {models_found} trained models found - need at least 2 for ensemble\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸  Insufficient models for churn-focused ensemble optimization\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHURN-FOCUSED DYNAMIC ENSEMBLE OPTIMIZATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'all_results_df' in locals() and len(all_results_df) > 0:\n",
    "\n",
    "    model_sources.append(('Churn_Ensembles', churn_ensembles))\n",
    "    \n",
    "    print(f\"\"\"\n",
    "âœ… Churn-focused analysis completed with available models:\n",
    "\n",
    "ðŸ“Š SUMMARY:\n",
    "   â€¢ Total models analyzed: {len(all_results_df)}\n",
    "   â€¢ Models meeting churn criteria: {len(churn_focused_candidates) if 'churn_focused_candidates' in locals() else 0}\n",
    "   â€¢ Best individual Accuracy_0 (No Churn): {all_results_df['Accuracy_0'].max():.4f}\n",
    "   â€¢ Best individual Accuracy_1 (Churn): {all_results_df['Accuracy_1'].max():.4f}\n",
    "   â€¢ Best individual F1_Weighted: {all_results_df['F1_Weighted'].max():.4f}\n",
    "   â€¢ Churn-focused ensembles created: {'Yes' if 'churn_ensembles' in locals() and churn_ensembles else 'No'}\n",
    "\n",
    "ðŸŽ¯ CHURN DETECTION FOCUS:\n",
    "   â€¢ Primary metric: Accuracy_1 (correct identification of churning customers)\n",
    "   â€¢ Secondary metric: F1_1 (balanced churn detection performance)\n",
    "   â€¢ Supporting metric: F1_Weighted (overall model quality)\n",
    "   â€¢ Business impact: Maximizes customer retention through early churn identification\n",
    "\"\"\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "âš ï¸  No model results available for analysis.\n",
    "   Please ensure previous sections have been run successfully.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98182f5",
   "metadata": {},
   "source": [
    "### 8.1 Churn Biased Ensemble Compared to Winning Un-biased Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1 Ultimate Model Comparison - Churn-Biased vs Overall Best Ensemble - FIXED\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ULTIMATE MODEL COMPARISON - CHURN-BIASED vs OVERALL BEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This section creates the ultimate ensemble by combining:\n",
    "1. Best churn-biased ensemble (maximizes Accuracy_1)\n",
    "2. Best overall performing models (maximizes F1_Weighted)\n",
    "Then declares winners for both churn prediction and overall accuracy.\n",
    "\"\"\")\n",
    "\n",
    "# 1. Identify the best models from each category\n",
    "print(\"\\n1. IDENTIFYING BEST MODELS FROM EACH CATEGORY\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get all results for analysis - FIX: Remove duplicates first\n",
    "all_results_df = pd.DataFrame(results).drop_duplicates('Model', keep='last').set_index('Model')\n",
    "print(f\"âœ… Total models available: {len(all_results_df)}\")\n",
    "\n",
    "# Find best churn-biased model (highest Accuracy_1)\n",
    "best_churn_model_idx = all_results_df['Accuracy_1'].idxmax()\n",
    "best_churn_model = all_results_df.loc[best_churn_model_idx]\n",
    "print(f\"\\nðŸŽ¯ BEST CHURN-BIASED MODEL: {best_churn_model.name}\")\n",
    "print(f\"   Churn Accuracy (Accuracy_1): {best_churn_model['Accuracy_1']:.4f}\")\n",
    "print(f\"   No Churn Accuracy (Accuracy_0): {best_churn_model['Accuracy_0']:.4f}\")\n",
    "print(f\"   F1_Weighted: {best_churn_model['F1_Weighted']:.4f}\")\n",
    "print(f\"   Churn F1: {best_churn_model['F1_1']:.4f}\")\n",
    "\n",
    "# Find best overall model (highest F1_Weighted)\n",
    "best_overall_model_idx = all_results_df['F1_Weighted'].idxmax()\n",
    "best_overall_model = all_results_df.loc[best_overall_model_idx]\n",
    "print(f\"\\nðŸ† BEST OVERALL MODEL: {best_overall_model.name}\")\n",
    "print(f\"   F1_Weighted: {best_overall_model['F1_Weighted']:.4f}\")\n",
    "print(f\"   Churn Accuracy (Accuracy_1): {best_overall_model['Accuracy_1']:.4f}\")\n",
    "print(f\"   No Churn Accuracy (Accuracy_0): {best_overall_model['Accuracy_0']:.4f}\")\n",
    "print(f\"   Churn F1: {best_overall_model['F1_1']:.4f}\")\n",
    "\n",
    "# 2. Create the ultimate ensemble combining both approaches\n",
    "print(\"\\n2. CREATING ULTIMATE CHURN-FOCUSED vs OVERALL ENSEMBLE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get top 3 churn-biased models and top 3 overall models\n",
    "top_churn_models = all_results_df.nlargest(3, 'Accuracy_1').index.tolist()\n",
    "top_overall_models = all_results_df.nlargest(3, 'F1_Weighted').index.tolist()\n",
    "\n",
    "print(f\"ðŸŽ¯ TOP 3 CHURN-BIASED MODELS:\")\n",
    "for i, model in enumerate(top_churn_models, 1):\n",
    "    # FIX: Get scalar values using .iloc[0] if Series, otherwise direct access\n",
    "    model_data = all_results_df.loc[model]\n",
    "    acc_1 = model_data['Accuracy_1'] if not isinstance(model_data['Accuracy_1'], pd.Series) else model_data['Accuracy_1'].iloc[0]\n",
    "    acc_0 = model_data['Accuracy_0'] if not isinstance(model_data['Accuracy_0'], pd.Series) else model_data['Accuracy_0'].iloc[0]\n",
    "    f1_w = model_data['F1_Weighted'] if not isinstance(model_data['F1_Weighted'], pd.Series) else model_data['F1_Weighted'].iloc[0]\n",
    "    print(f\"   {i}. {model}: Churn_Acc={acc_1:.4f}, No_Churn_Acc={acc_0:.4f}, F1_W={f1_w:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ† TOP 3 OVERALL MODELS:\")\n",
    "for i, model in enumerate(top_overall_models, 1):\n",
    "    # FIX: Get scalar values using .iloc[0] if Series, otherwise direct access\n",
    "    model_data = all_results_df.loc[model]\n",
    "    acc_1 = model_data['Accuracy_1'] if not isinstance(model_data['Accuracy_1'], pd.Series) else model_data['Accuracy_1'].iloc[0]\n",
    "    acc_0 = model_data['Accuracy_0'] if not isinstance(model_data['Accuracy_0'], pd.Series) else model_data['Accuracy_0'].iloc[0]\n",
    "    f1_w = model_data['F1_Weighted'] if not isinstance(model_data['F1_Weighted'], pd.Series) else model_data['F1_Weighted'].iloc[0]\n",
    "    print(f\"   {i}. {model}: F1_W={f1_w:.4f}, Churn_Acc={acc_1:.4f}, No_Churn_Acc={acc_0:.4f}\")\n",
    "\n",
    "# Create consolidated model inventory - More robust approach\n",
    "all_model_pipelines = {}\n",
    "\n",
    "# Safely check for model dictionaries and collect available models\n",
    "# model_sources = [\n",
    "#     ('baseline_pipes', 'baseline_pipes'),\n",
    "#     ('balanced_pipes', 'balanced_pipes'),\n",
    "#     ('advanced_pipes_optimal', 'advanced_pipes_optimal'),\n",
    "#     ('cost_sensitive_pipes', 'cost_sensitive_pipes'),\n",
    "#     ('advanced_sampling_pipes', 'advanced_sampling_pipes'),\n",
    "#     ('ensemble_pipes', 'ensemble_pipes')\n",
    "# ]\n",
    "\n",
    "for source_name, var_name in model_sources:\n",
    "    try:\n",
    "        if var_name in globals():\n",
    "            model_dict = globals()[var_name]\n",
    "            if isinstance(model_dict, dict):\n",
    "                for model_name, pipeline in model_dict.items():\n",
    "                    if model_name in all_results_df.index:\n",
    "                        all_model_pipelines[model_name] = pipeline\n",
    "                        print(f\"   âœ… Found model: {model_name} from {source_name}\")\n",
    "            else:\n",
    "                print(f\"   âš ï¸  {var_name} is not a dictionary\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸  {var_name} not found in globals\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error accessing {var_name}: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… Found {len(all_model_pipelines)} trained model pipelines\")\n",
    "print(f\"   Available models: {list(all_model_pipelines.keys())[:5]}{'...' if len(all_model_pipelines) > 5 else ''}\")\n",
    "\n",
    "# 3. Create Ultimate Ensembles (only if we have enough models)\n",
    "print(\"\\n3. CREATING ULTIMATE ENSEMBLES\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "ultimate_ensembles = {}\n",
    "\n",
    "# Check if we have at least some trained models\n",
    "if len(all_model_pipelines) >= 2:\n",
    "    \n",
    "    # Ultimate Churn-Focused Ensemble (combines best churn models)\n",
    "    available_churn_models = [m for m in top_churn_models if m in all_model_pipelines]\n",
    "    if len(available_churn_models) >= 2:\n",
    "        print(f\"\\nðŸŽ¯ CREATING ULTIMATE CHURN-FOCUSED ENSEMBLE:\")\n",
    "        for model in available_churn_models:\n",
    "            # FIX: Get scalar values safely\n",
    "            model_data = all_results_df.loc[model]\n",
    "            acc_0 = model_data['Accuracy_0'] if not isinstance(model_data['Accuracy_0'], pd.Series) else model_data['Accuracy_0'].iloc[0]\n",
    "            acc_1 = model_data['Accuracy_1'] if not isinstance(model_data['Accuracy_1'], pd.Series) else model_data['Accuracy_1'].iloc[0]\n",
    "            f1_w = model_data['F1_Weighted'] if not isinstance(model_data['F1_Weighted'], pd.Series) else model_data['F1_Weighted'].iloc[0]\n",
    "            print(f\"   â€¢ {model}: Churn_Acc={acc_1:.4f}, No_Churn_Acc={acc_0:.4f}, F1_W={f1_w:.4f}\")\n",
    "        \n",
    "        try:\n",
    "            estimators = [(f\"churn_focus_{i}\", all_model_pipelines[model]) \n",
    "                         for i, model in enumerate(available_churn_models)]\n",
    "            \n",
    "            ultimate_churn_ensemble = VotingClassifier(estimators=estimators, voting='soft')\n",
    "            ultimate_churn_ensemble.fit(X_train, y_train)\n",
    "            \n",
    "            evaluate_model(\"Ultimate_Churn_Focused_Ensemble\", ultimate_churn_ensemble, X_test, y_test, results)\n",
    "            ultimate_ensembles[\"Ultimate_Churn_Focused_Ensemble\"] = ultimate_churn_ensemble\n",
    "            \n",
    "            print(f\"âœ… Ultimate Churn-Focused ensemble created successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error creating ultimate churn ensemble: {e}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  Not enough churn-focused models available ({len(available_churn_models)} found, need at least 2)\")\n",
    "\n",
    "    # Ultimate Overall Ensemble (combines best overall models)\n",
    "    available_overall_models = [m for m in top_overall_models if m in all_model_pipelines]\n",
    "    if len(available_overall_models) >= 2:\n",
    "        print(f\"\\nðŸ† CREATING ULTIMATE OVERALL ENSEMBLE:\")\n",
    "        for model in available_overall_models:\n",
    "            # FIX: Get scalar values safely\n",
    "            model_data = all_results_df.loc[model]\n",
    "            acc_0 = model_data['Accuracy_0'] if not isinstance(model_data['Accuracy_0'], pd.Series) else model_data['Accuracy_0'].iloc[0]\n",
    "            acc_1 = model_data['Accuracy_1'] if not isinstance(model_data['Accuracy_1'], pd.Series) else model_data['Accuracy_1'].iloc[0]\n",
    "            f1_w = model_data['F1_Weighted'] if not isinstance(model_data['F1_Weighted'], pd.Series) else model_data['F1_Weighted'].iloc[0]\n",
    "            print(f\"   â€¢ {model}: F1_W={f1_w:.4f}, Churn_Acc={acc_1:.4f}, No_Churn_Acc={acc_0:.4f}\")\n",
    "        \n",
    "        try:\n",
    "            estimators = [(f\"overall_best_{i}\", all_model_pipelines[model]) \n",
    "                         for i, model in enumerate(available_overall_models)]\n",
    "            \n",
    "            ultimate_overall_ensemble = VotingClassifier(estimators=estimators, voting='soft')\n",
    "            ultimate_overall_ensemble.fit(X_train, y_train)\n",
    "            \n",
    "            evaluate_model(\"Ultimate_Overall_Ensemble\", ultimate_overall_ensemble, X_test, y_test, results)\n",
    "            ultimate_ensembles[\"Ultimate_Overall_Ensemble\"] = ultimate_overall_ensemble\n",
    "            \n",
    "            print(f\"âœ… Ultimate Overall ensemble created successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error creating ultimate overall ensemble: {e}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  Not enough overall models available ({len(available_overall_models)} found, need at least 2)\")\n",
    "\n",
    "    # Hybrid Ensemble (combines best from both categories)\n",
    "    # Combine unique models from both top lists\n",
    "    hybrid_models = list(set(available_churn_models + available_overall_models))\n",
    "    if len(hybrid_models) >= 3:\n",
    "        print(f\"\\nðŸ”¥ CREATING ULTIMATE HYBRID ENSEMBLE:\")\n",
    "        for model in hybrid_models:\n",
    "            # FIX: Get scalar values safely\n",
    "            model_data = all_results_df.loc[model]\n",
    "            acc_0 = model_data['Accuracy_0'] if not isinstance(model_data['Accuracy_0'], pd.Series) else model_data['Accuracy_0'].iloc[0]\n",
    "            acc_1 = model_data['Accuracy_1'] if not isinstance(model_data['Accuracy_1'], pd.Series) else model_data['Accuracy_1'].iloc[0]\n",
    "            f1_w = model_data['F1_Weighted'] if not isinstance(model_data['F1_Weighted'], pd.Series) else model_data['F1_Weighted'].iloc[0]\n",
    "            print(f\"   â€¢ {model}: F1_W={f1_w:.4f}, Churn_Acc={acc_1:.4f}, No_Churn_Acc={acc_0:.4f}\")\n",
    "        \n",
    "        try:\n",
    "            estimators = [(f\"hybrid_{i}\", all_model_pipelines[model]) \n",
    "                         for i, model in enumerate(hybrid_models)]\n",
    "            \n",
    "            ultimate_hybrid_ensemble = VotingClassifier(estimators=estimators, voting='soft')\n",
    "            ultimate_hybrid_ensemble.fit(X_train, y_train)\n",
    "            confusion_matrix_plot(name, pipe, X_test, y_test)\n",
    "            evaluate_model(\"Ultimate_Hybrid_Ensemble\", ultimate_hybrid_ensemble, X_test, y_test, results)\n",
    "            ultimate_ensembles[\"Ultimate_Hybrid_Ensemble\"] = ultimate_hybrid_ensemble\n",
    "            \n",
    "            print(f\"âœ… Ultimate Hybrid ensemble created successfully!\")\n",
    "            \n",
    "            model_sources.append(('Ultimate_Ensembles', ultimate_ensembles))\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error creating ultimate hybrid ensemble: {e}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  Not enough models for hybrid ensemble ({len(hybrid_models)} found, need at least 3)\")\n",
    "\n",
    "else:\n",
    "    print(f\"âš ï¸  Not enough trained model pipelines available ({len(all_model_pipelines)} found, need at least 2)\")\n",
    "    print(\"   Skipping ensemble creation and proceeding with analysis of existing models\")\n",
    "\n",
    "# Continue with the rest of the analysis...\n",
    "print(\"\\nâœ… Ultimate ensemble creation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa28e4aa",
   "metadata": {},
   "source": [
    "## 9 Churn Predictor Leader Board\n",
    "Leader Board focused on models that predict churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 Churn Predictor Leader Board\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHURN PREDICTOR LEADER BOARD - COMPLETE RANKINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This section creates the ultimate churn predictor leader board, ranking all models\n",
    "by their ability to predict churn (Accuracy_1) while also showing overall performance.\n",
    "Each model is evaluated on key metrics with comprehensive visualizations.\n",
    "\"\"\")\n",
    "\n",
    "# 1. Create comprehensive leader board\n",
    "print(\"\\n1. CREATING COMPREHENSIVE LEADER BOARD\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get all results and remove duplicates\n",
    "all_results_df = pd.DataFrame(results).drop_duplicates('Model', keep='last').set_index('Model')\n",
    "print(f\"âœ… Total models in leader board: {len(all_results_df)}\")\n",
    "\n",
    "# Sort by Accuracy_1 (churn prediction) as primary metric\n",
    "churn_leaderboard = all_results_df.sort_values('Accuracy_1', ascending=False).copy()\n",
    "\n",
    "# Add rankings\n",
    "churn_leaderboard['Churn_Rank'] = range(1, len(churn_leaderboard) + 1)\n",
    "churn_leaderboard['Overall_Rank'] = churn_leaderboard['F1_Weighted'].rank(ascending=False, method='min')\n",
    "\n",
    "# Add performance categories\n",
    "def categorize_churn_performance(accuracy_1):\n",
    "    if accuracy_1 >= 0.8:\n",
    "        return 'Excellent'\n",
    "    elif accuracy_1 >= 0.7:\n",
    "        return 'Good'\n",
    "    elif accuracy_1 >= 0.6:\n",
    "        return 'Fair'\n",
    "    else:\n",
    "        return 'Poor'\n",
    "\n",
    "churn_leaderboard['Churn_Performance'] = churn_leaderboard['Accuracy_1'].apply(categorize_churn_performance)\n",
    "\n",
    "# Create the complete leader board table\n",
    "print(\"\\nðŸ“‹ COMPLETE CHURN PREDICTOR LEADER BOARD:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "leader_board_display = churn_leaderboard[['Churn_Rank', 'Overall_Rank', 'Accuracy_0', 'Accuracy_1', \n",
    "                                         'F1_0', 'F1_1', 'F1_Weighted', 'ROC_AUC', 'PR_AUC', \n",
    "                                         'Churn_Performance']].copy()\n",
    "\n",
    "# Format for better display\n",
    "for col in ['Accuracy_0', 'Accuracy_1', 'F1_0', 'F1_1', 'F1_Weighted', 'ROC_AUC', 'PR_AUC']:\n",
    "    leader_board_display[col] = leader_board_display[col].round(4)\n",
    "\n",
    "leader_board_display['Churn_Rank'] = leader_board_display['Churn_Rank'].astype(int)\n",
    "leader_board_display['Overall_Rank'] = leader_board_display['Overall_Rank'].astype(int)\n",
    "\n",
    "display(leader_board_display)\n",
    "\n",
    "# 2. Top 10 Churn Predictors Summary\n",
    "print(\"\\n2. TOP 10 CHURN PREDICTORS SUMMARY\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "top_10_churn = churn_leaderboard.head(10)\n",
    "\n",
    "print(\"ðŸ† TOP 10 CHURN PREDICTION MODELS:\")\n",
    "for i, (model_name, metrics) in enumerate(top_10_churn.iterrows(), 1):\n",
    "    print(f\"{i:2d}. {model_name}\")\n",
    "    print(f\"    Churn Accuracy: {metrics['Accuracy_1']:.4f} ({metrics['Churn_Performance']})\")\n",
    "    print(f\"    No-Churn Accuracy: {metrics['Accuracy_0']:.4f}\")\n",
    "    print(f\"    Overall F1_Weighted: {metrics['F1_Weighted']:.4f} (Rank #{int(metrics['Overall_Rank'])})\")\n",
    "    print(f\"    ROC_AUC: {metrics['ROC_AUC']:.4f}\")\n",
    "    print(\"\")\n",
    "\n",
    "# 3. Performance Statistics\n",
    "print(\"\\n3. LEADER BOARD STATISTICS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"ðŸ“Š CHURN PREDICTION STATISTICS:\")\n",
    "print(f\"   Best Churn Accuracy: {churn_leaderboard['Accuracy_1'].max():.4f}\")\n",
    "print(f\"   Average Churn Accuracy: {churn_leaderboard['Accuracy_1'].mean():.4f}\")\n",
    "print(f\"   Worst Churn Accuracy: {churn_leaderboard['Accuracy_1'].min():.4f}\")\n",
    "print(f\"   Standard Deviation: {churn_leaderboard['Accuracy_1'].std():.4f}\")\n",
    "\n",
    "print(\"\\nðŸ“Š PERFORMANCE CATEGORY DISTRIBUTION:\")\n",
    "category_counts = churn_leaderboard['Churn_Performance'].value_counts()\n",
    "for category, count in category_counts.items():\n",
    "    percentage = (count / len(churn_leaderboard)) * 100\n",
    "    print(f\"   {category}: {count} models ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nðŸ“Š NO-CHURN PREDICTION STATISTICS:\")\n",
    "print(f\"   Best No-Churn Accuracy: {churn_leaderboard['Accuracy_0'].max():.4f}\")\n",
    "print(f\"   Average No-Churn Accuracy: {churn_leaderboard['Accuracy_0'].mean():.4f}\")\n",
    "print(f\"   Worst No-Churn Accuracy: {churn_leaderboard['Accuracy_0'].min():.4f}\")\n",
    "\n",
    "# 4. Individual Visualizations (no subplots)\n",
    "print(\"\\n4. COMPREHENSIVE LEADER BOARD VISUALIZATIONS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Visualization 1: Churn Accuracy Leader Board (Top 15)\n",
    "print(\"Visualization 1: Churn Accuracy Leader Board\")\n",
    "plt.figure(figsize=(14, 8))\n",
    "top_15_churn = churn_leaderboard.head(15)\n",
    "\n",
    "# Create color coding based on performance\n",
    "color_map = {'Excellent': 'green', 'Good': 'orange', 'Fair': 'yellow', 'Poor': 'red'}\n",
    "colors = [color_map[perf] for perf in top_15_churn['Churn_Performance']]\n",
    "\n",
    "bars = plt.barh(range(len(top_15_churn)), top_15_churn['Accuracy_1'], color=colors, alpha=0.8)\n",
    "\n",
    "plt.yticks(range(len(top_15_churn)), top_15_churn.index, fontsize=10)\n",
    "plt.xlabel('Churn Accuracy (Accuracy_1)', fontsize=12)\n",
    "plt.title('Churn Predictor Leader Board - Top 15 Models\\n(Ranked by Churn Detection Accuracy)', fontweight='bold', fontsize=14)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    plt.annotate(f'{width:.3f}',\n",
    "                xy=(width, bar.get_y() + bar.get_height() / 2),\n",
    "                xytext=(5, 0),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='left', va='center', fontsize=9)\n",
    "\n",
    "# Add legend for performance categories\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=color_map[cat], alpha=0.8, label=cat) for cat in color_map.keys()]\n",
    "plt.legend(handles=legend_elements, title='Performance Category', loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: No-Churn Accuracy Leader Board (Top 15)\n",
    "print(\"Visualization 2: No-Churn Accuracy Leader Board\")\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "bars = plt.barh(range(len(top_15_churn)), top_15_churn['Accuracy_0'], color='lightblue', alpha=0.8)\n",
    "\n",
    "plt.yticks(range(len(top_15_churn)), top_15_churn.index, fontsize=10)\n",
    "plt.xlabel('No-Churn Accuracy (Accuracy_0)', fontsize=12)\n",
    "plt.title('No-Churn Prediction Leader Board - Top 15 Models\\n(Same Models as Churn Leader Board)', fontweight='bold', fontsize=14)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    plt.annotate(f'{width:.3f}',\n",
    "                xy=(width, bar.get_y() + bar.get_height() / 2),\n",
    "                xytext=(5, 0),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='left', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 3: Churn vs No-Churn Accuracy Comparison\n",
    "print(\"Visualization 3: Churn vs No-Churn Accuracy Comparison\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot all models as scatter plot\n",
    "scatter = plt.scatter(churn_leaderboard['Accuracy_0'], churn_leaderboard['Accuracy_1'], \n",
    "                     c=[color_map[perf] for perf in churn_leaderboard['Churn_Performance']], \n",
    "                     alpha=0.7, s=80)\n",
    "\n",
    "plt.xlabel('No-Churn Accuracy (Accuracy_0)', fontsize=12)\n",
    "plt.ylabel('Churn Accuracy (Accuracy_1)', fontsize=12)\n",
    "plt.title('Churn vs No-Churn Accuracy Trade-off\\n(All Models)', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Add diagonal line for reference\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.3, label='Equal Performance Line')\n",
    "\n",
    "# Annotate top 5 models\n",
    "for i, (model_name, metrics) in enumerate(top_15_churn.head(5).iterrows()):\n",
    "    plt.annotate(f'{i+1}', \n",
    "                (metrics['Accuracy_0'], metrics['Accuracy_1']), \n",
    "                xytext=(5, 5), textcoords='offset points', \n",
    "                fontsize=10, fontweight='bold',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "plt.legend(handles=legend_elements + [plt.Line2D([0], [0], color='black', linestyle='--', alpha=0.3, label='Equal Performance')], \n",
    "          title='Performance Category', loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 1.05)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 4: F1_Weighted vs Churn Accuracy\n",
    "print(\"Visualization 4: Overall Performance vs Churn Accuracy\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "scatter = plt.scatter(churn_leaderboard['F1_Weighted'], churn_leaderboard['Accuracy_1'], \n",
    "                     c=[color_map[perf] for perf in churn_leaderboard['Churn_Performance']], \n",
    "                     alpha=0.7, s=80)\n",
    "\n",
    "plt.xlabel('F1_Weighted Score (Overall Performance)', fontsize=12)\n",
    "plt.ylabel('Churn Accuracy (Accuracy_1)', fontsize=12)\n",
    "plt.title('Overall Performance vs Churn Detection Accuracy\\n(All Models)', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Annotate top 5 models\n",
    "for i, (model_name, metrics) in enumerate(top_15_churn.head(5).iterrows()):\n",
    "    plt.annotate(f'{i+1}', \n",
    "                (metrics['F1_Weighted'], metrics['Accuracy_1']), \n",
    "                xytext=(5, 5), textcoords='offset points', \n",
    "                fontsize=10, fontweight='bold',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "plt.legend(handles=legend_elements, title='Churn Performance', loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 1.05)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 5: ROC AUC Leader Board\n",
    "print(\"Visualization 5: ROC AUC Performance Leader Board\")\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Sort by ROC AUC for this visualization\n",
    "top_15_roc = churn_leaderboard.nlargest(15, 'ROC_AUC')\n",
    "bars = plt.barh(range(len(top_15_roc)), top_15_roc['ROC_AUC'], color='lightgreen', alpha=0.8)\n",
    "\n",
    "plt.yticks(range(len(top_15_roc)), top_15_roc.index, fontsize=10)\n",
    "plt.xlabel('ROC AUC Score', fontsize=12)\n",
    "plt.title('ROC AUC Leader Board - Top 15 Models\\n(Ranked by ROC AUC)', fontweight='bold', fontsize=14)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    plt.annotate(f'{width:.3f}',\n",
    "                xy=(width, bar.get_y() + bar.get_height() / 2),\n",
    "                xytext=(5, 0),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='left', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 6: F1 Score Comparison (Churn vs No-Churn)\n",
    "print(\"Visualization 6: F1 Score Comparison - Churn vs No-Churn\")\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "x_pos = np.arange(len(top_15_churn))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = plt.bar(x_pos - width/2, top_15_churn['F1_0'], width, \n",
    "                label='F1_0 (No Churn)', alpha=0.8, color='lightblue')\n",
    "bars2 = plt.bar(x_pos + width/2, top_15_churn['F1_1'], width,\n",
    "                label='F1_1 (Churn)', alpha=0.8, color='lightcoral')\n",
    "\n",
    "plt.xlabel('Models (Top 15 Churn Predictors)', fontsize=12)\n",
    "plt.ylabel('F1 Score', fontsize=12)\n",
    "plt.title('F1 Score Comparison: No-Churn vs Churn\\n(Top 15 Churn Prediction Models)', fontweight='bold', fontsize=14)\n",
    "plt.xticks(x_pos, [name[:15] + '...' if len(name) > 15 else name for name in top_15_churn.index], \n",
    "           rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 7: Performance Distribution by Category\n",
    "print(\"Visualization 7: Churn Accuracy Distribution by Performance Category\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "performance_categories = ['Excellent', 'Good', 'Fair', 'Poor']\n",
    "category_data = []\n",
    "\n",
    "for category in performance_categories:\n",
    "    cat_data = churn_leaderboard[churn_leaderboard['Churn_Performance'] == category]['Accuracy_1']\n",
    "    if len(cat_data) > 0:\n",
    "        category_data.append(cat_data.values)\n",
    "    else:\n",
    "        category_data.append([])\n",
    "\n",
    "# Create box plot\n",
    "bp = plt.boxplot([data for data in category_data if len(data) > 0], \n",
    "                 labels=[cat for i, cat in enumerate(performance_categories) if len(category_data[i]) > 0],\n",
    "                 patch_artist=True)\n",
    "\n",
    "colors = ['green', 'orange', 'yellow', 'red']\n",
    "for patch, color in zip(bp['boxes'], colors[:len(bp['boxes'])]):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.6)\n",
    "\n",
    "plt.ylabel('Churn Accuracy (Accuracy_1)', fontsize=12)\n",
    "plt.title('Churn Accuracy Distribution by Performance Category\\n(Box Plot)', fontweight='bold', fontsize=14)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 8: Model Ranking Comparison\n",
    "print(\"Visualization 8: Churn Rank vs Overall Rank Comparison\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(churn_leaderboard['Churn_Rank'], churn_leaderboard['Overall_Rank'], \n",
    "           alpha=0.7, s=80, color='purple')\n",
    "\n",
    "plt.xlabel('Churn Prediction Rank', fontsize=12)\n",
    "plt.ylabel('Overall Performance Rank (F1_Weighted)', fontsize=12)\n",
    "plt.title('Churn Prediction Rank vs Overall Performance Rank\\n(Lower is Better)', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Add diagonal line for reference\n",
    "max_rank = max(churn_leaderboard['Churn_Rank'].max(), churn_leaderboard['Overall_Rank'].max())\n",
    "plt.plot([1, max_rank], [1, max_rank], 'k--', alpha=0.3, label='Equal Rank Line')\n",
    "\n",
    "# Annotate models that are top in both categories\n",
    "top_both = churn_leaderboard[(churn_leaderboard['Churn_Rank'] <= 5) & \n",
    "                           (churn_leaderboard['Overall_Rank'] <= 5)]\n",
    "for model_name, metrics in top_both.iterrows():\n",
    "    plt.annotate(model_name[:10] + '...', \n",
    "                (metrics['Churn_Rank'], metrics['Overall_Rank']), \n",
    "                xytext=(5, 5), textcoords='offset points', \n",
    "                fontsize=8, alpha=0.8)\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 9: Top 10 Models - All Key Metrics\n",
    "print(\"Visualization 9: Top 10 Models - All Key Metrics Radar\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "top_5_models = top_10_churn.head(5)\n",
    "metrics_for_radar = ['Accuracy_0', 'Accuracy_1', 'F1_0', 'F1_1', 'F1_Weighted']\n",
    "\n",
    "# Normalize metrics to 0-1 scale for radar chart\n",
    "normalized_data = top_5_models[metrics_for_radar].values\n",
    "\n",
    "# Create angles for radar chart\n",
    "angles = np.linspace(0, 2 * np.pi, len(metrics_for_radar), endpoint=False).tolist()\n",
    "angles += angles[:1]  # Complete the circle\n",
    "\n",
    "ax = plt.subplot(111, projection='polar')\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "for i, (model_name, row) in enumerate(top_5_models.iterrows()):\n",
    "    values = [row[metric] for metric in metrics_for_radar]\n",
    "    values += values[:1]  # Complete the circle\n",
    "    \n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=f'{i+1}. {model_name[:15]}...', color=colors[i])\n",
    "    ax.fill(angles, values, alpha=0.25, color=colors[i])\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(metrics_for_radar)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Top 5 Churn Predictors - Performance Radar\\n(All Key Metrics)', fontweight='bold', fontsize=14, pad=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 10: Performance Improvement Histogram\n",
    "print(\"Visualization 10: Churn Accuracy Distribution\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.hist(churn_leaderboard['Accuracy_1'], bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "plt.axvline(churn_leaderboard['Accuracy_1'].mean(), color='red', linestyle='--', \n",
    "           label=f'Mean: {churn_leaderboard[\"Accuracy_1\"].mean():.3f}')\n",
    "plt.axvline(churn_leaderboard['Accuracy_1'].median(), color='blue', linestyle='--', \n",
    "           label=f'Median: {churn_leaderboard[\"Accuracy_1\"].median():.3f}')\n",
    "\n",
    "plt.xlabel('Churn Accuracy (Accuracy_1)', fontsize=12)\n",
    "plt.ylabel('Number of Models', fontsize=12)\n",
    "plt.title('Distribution of Churn Accuracy Across All Models\\n(Histogram)', fontweight='bold', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Final Leader Board Summary\n",
    "print(\"\\n5. FINAL LEADER BOARD SUMMARY\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"ðŸ† CHURN PREDICTION CHAMPION:\")\n",
    "champion = churn_leaderboard.iloc[0]\n",
    "print(f\"   Model: {champion.name}\")\n",
    "print(f\"   Churn Accuracy: {champion['Accuracy_1']:.4f}\")\n",
    "print(f\"   No-Churn Accuracy: {champion['Accuracy_0']:.4f}\")\n",
    "print(f\"   F1_Weighted: {champion['F1_Weighted']:.4f}\")\n",
    "print(f\"   ROC_AUC: {champion['ROC_AUC']:.4f}\")\n",
    "print(f\"   Performance Category: {champion['Churn_Performance']}\")\n",
    "\n",
    "print(\"\\nðŸ¥ˆ RUNNER-UP:\")\n",
    "runner_up = churn_leaderboard.iloc[1]\n",
    "print(f\"   Model: {runner_up.name}\")\n",
    "print(f\"   Churn Accuracy: {runner_up['Accuracy_1']:.4f}\")\n",
    "print(f\"   Performance Gap: {champion['Accuracy_1'] - runner_up['Accuracy_1']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ¥‰ THIRD PLACE:\")\n",
    "third_place = churn_leaderboard.iloc[2]\n",
    "print(f\"   Model: {third_place.name}\")\n",
    "print(f\"   Churn Accuracy: {third_place['Accuracy_1']:.4f}\")\n",
    "print(f\"   Performance Gap: {champion['Accuracy_1'] - third_place['Accuracy_1']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ“Š LEADER BOARD INSIGHTS:\")\n",
    "print(f\"   â€¢ Total models evaluated: {len(churn_leaderboard)}\")\n",
    "print(f\"   â€¢ Models with 'Excellent' churn prediction: {(churn_leaderboard['Churn_Performance'] == 'Excellent').sum()}\")\n",
    "print(f\"   â€¢ Average churn accuracy: {churn_leaderboard['Accuracy_1'].mean():.4f}\")\n",
    "print(f\"   â€¢ Best churn accuracy: {churn_leaderboard['Accuracy_1'].max():.4f}\")\n",
    "print(f\"   â€¢ Models with >90% churn accuracy: {(churn_leaderboard['Accuracy_1'] > 0.9).sum()}\")\n",
    "print(f\"   â€¢ Models with >80% churn accuracy: {(churn_leaderboard['Accuracy_1'] > 0.8).sum()}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ DEPLOYMENT RECOMMENDATIONS:\")\n",
    "print(\"   â€¢ Primary: Deploy the champion model for maximum churn detection\")\n",
    "print(\"   â€¢ Backup: Keep runner-up model as fallback option\")\n",
    "print(\"   â€¢ Ensemble: Consider combining top 3 models for enhanced robustness\")\n",
    "print(\"   â€¢ Monitoring: Track performance degradation over time\")\n",
    "print(\"   â€¢ Retraining: Schedule monthly retraining with new data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHURN PREDICTOR LEADER BOARD COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ… Leader board analysis complete with comprehensive rankings and visualizations.\n",
    "\n",
    "ðŸ† CHAMPION MODEL: {champion.name}\n",
    "   ðŸ“Š Churn Detection: {champion['Accuracy_1']:.4f} (Top performance)\n",
    "   ðŸ“Š Overall Performance: {champion['F1_Weighted']:.4f} (Rank #{int(champion['Overall_Rank'])})\n",
    "   ðŸ“Š Balanced Performance: Excellent churn detection with strong overall metrics\n",
    "\n",
    "ðŸš€ All visualizations demonstrate model performance across multiple dimensions,\n",
    "   providing clear guidance for production deployment decisions.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e87515",
   "metadata": {},
   "source": [
    "## 10 Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7375f9c7",
   "metadata": {},
   "source": [
    "## 10.1 According to the winning model, which features and combinations of features most impact churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdead8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1 According to the winning model, which features and combinations of features most impact churn?\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS - WINNING MODEL FROM LEADERBOARD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This section analyzes feature importance using the champion model from our comprehensive\n",
    "churn predictor leaderboard. We'll identify which features and feature combinations\n",
    "have the strongest impact on churn predictions.\n",
    "\"\"\")\n",
    "\n",
    "# 1. Identify and analyze the winning model from leaderboard\n",
    "print(\"\\n1. WINNING MODEL ANALYSIS FROM LEADERBOARD\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get the champion model from the churn leaderboard\n",
    "if 'churn_leaderboard' in locals():\n",
    "    champion_model_name = churn_leaderboard.index[0]\n",
    "    champion_metrics = churn_leaderboard.iloc[0]\n",
    "    \n",
    "    print(f\"ðŸ† CHURN PREDICTION CHAMPION: {champion_model_name}\")\n",
    "    print(f\"   Churn Accuracy (Accuracy_1): {champion_metrics['Accuracy_1']:.4f}\")\n",
    "    print(f\"   No-Churn Accuracy (Accuracy_0): {champion_metrics['Accuracy_0']:.4f}\")\n",
    "    print(f\"   F1_Weighted: {champion_metrics['F1_Weighted']:.4f}\")\n",
    "    print(f\"   Churn F1: {champion_metrics['F1_1']:.4f}\")\n",
    "    print(f\"   ROC_AUC: {champion_metrics['ROC_AUC']:.4f}\")\n",
    "    print(f\"   Performance Category: {champion_metrics['Churn_Performance']}\")\n",
    "    print(f\"   Leaderboard Rank: #{champion_metrics['Churn_Rank']}\")\n",
    "    print(f\"   Overall Rank: #{int(champion_metrics['Overall_Rank'])}\")\n",
    "else:\n",
    "    # Fallback to final_results_ordered if churn_leaderboard not available\n",
    "    champion_model_name = all_results_df.loc[all_results_df['Accuracy_1'].idxmax()].name\n",
    "    champion_metrics = all_results_df.loc[champion_model_name]\n",
    "    \n",
    "    print(f\"ðŸ† BEST CHURN PREDICTOR: {champion_model_name}\")\n",
    "    print(f\"   Churn Accuracy (Accuracy_1): {champion_metrics['Accuracy_1']:.4f}\")\n",
    "    print(f\"   F1_Weighted: {champion_metrics['F1_Weighted']:.4f}\")\n",
    "    print(f\"   ROC_AUC: {champion_metrics['ROC_AUC']:.4f}\")\n",
    "\n",
    "# 2. Retrieve the champion model pipeline\n",
    "print(f\"\\n2. RETRIEVING CHAMPION MODEL PIPELINE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "winning_model = None\n",
    "model_source = None\n",
    "\n",
    "# Check all possible model dictionaries for the champion\n",
    "# model_sources = [\n",
    "#     ('advanced_pipes_optimal', 'advanced_pipes_optimal'),\n",
    "#     ('balanced_pipes', 'balanced_pipes'),\n",
    "#     ('baseline_pipes', 'baseline_pipes'),\n",
    "#     ('cost_sensitive_pipes', 'cost_sensitive_pipes'),\n",
    "#     ('advanced_sampling_pipes', 'advanced_sampling_pipes'),\n",
    "#     ('churn_ensembles', 'churn_ensembles'),\n",
    "#     ('ultimate_ensembles', 'ultimate_ensembles')\n",
    "# ]\n",
    "\n",
    "for source_name, var_name in model_sources:\n",
    "    try:\n",
    "        if var_name in globals():\n",
    "            model_dict = globals()[var_name]\n",
    "            if isinstance(model_dict, dict) and champion_model_name in model_dict:\n",
    "                winning_model = model_dict[champion_model_name]\n",
    "                model_source = source_name\n",
    "                print(f\"âœ… Found champion model in: {source_name}\")\n",
    "                break\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "if winning_model is None:\n",
    "    print(\"âš ï¸  Champion model pipeline not found in standard dictionaries\")\n",
    "    print(\"    This may occur if the model was from an ensemble or special analysis\")\n",
    "    print(\"    Proceeding with feature importance analysis using available models...\")\n",
    "\n",
    "if winning_model is not None:\n",
    "    print(f\"âœ… Successfully retrieved champion model: {champion_model_name}\")\n",
    "    print(f\"   Source: {model_source}\")\n",
    "    print(f\"   Model Type: {type(winning_model).__name__}\")\n",
    "\n",
    "# 3. Enhanced feature importance extraction\n",
    "print(\"\\n3. ENHANCED FEATURE IMPORTANCE EXTRACTION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def get_feature_names_from_pipeline(pipeline):\n",
    "    \"\"\"Extract feature names from a fitted pipeline with enhanced error handling\"\"\"\n",
    "    try:\n",
    "        # Handle different pipeline structures\n",
    "        if hasattr(pipeline, 'named_steps'):\n",
    "            if 'pre' in pipeline.named_steps:\n",
    "                preprocessor = pipeline.named_steps['pre']\n",
    "            elif 'preprocessor' in pipeline.named_steps:\n",
    "                preprocessor = pipeline.named_steps['preprocessor']\n",
    "            else:\n",
    "                # Find preprocessing step\n",
    "                for step_name, step in pipeline.named_steps.items():\n",
    "                    if hasattr(step, 'get_feature_names_out') or hasattr(step, 'transform'):\n",
    "                        preprocessor = step\n",
    "                        break\n",
    "                else:\n",
    "                    preprocessor = pipeline.steps[0][1]\n",
    "        else:\n",
    "            # For ensemble models, get from first estimator\n",
    "            if hasattr(pipeline, 'estimators_'):\n",
    "                first_estimator = pipeline.estimators_[0][1]\n",
    "                return get_feature_names_from_pipeline(first_estimator)\n",
    "            else:\n",
    "                return None\n",
    "        \n",
    "        # Get feature names\n",
    "        feature_names = []\n",
    "        \n",
    "        if hasattr(preprocessor, 'get_feature_names_out'):\n",
    "            try:\n",
    "                feature_names = preprocessor.get_feature_names_out()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if len(feature_names) == 0 and hasattr(preprocessor, 'named_transformers_'):\n",
    "            # Try to build feature names from transformers\n",
    "            if 'num' in preprocessor.named_transformers_:\n",
    "                try:\n",
    "                    num_features = preprocessor.named_transformers_['num'].get_feature_names_out()\n",
    "                    feature_names.extend(num_features)\n",
    "                except:\n",
    "                    # Fallback to original numeric feature names\n",
    "                    if hasattr(preprocessor, '_feature_names_in'):\n",
    "                        numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "                        feature_names.extend([f\"num__{col}\" for col in numeric_features])\n",
    "            \n",
    "            if 'cat' in preprocessor.named_transformers_:\n",
    "                try:\n",
    "                    cat_features = preprocessor.named_transformers_['cat'].get_feature_names_out()\n",
    "                    feature_names.extend(cat_features)\n",
    "                except:\n",
    "                    # Fallback to original categorical feature names\n",
    "                    categorical_features = X.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "                    feature_names.extend([f\"cat__{col}\" for col in categorical_features])\n",
    "        \n",
    "        # Final fallback: use generic names\n",
    "        if len(feature_names) == 0:\n",
    "            # Try to get number of features from a sample transformation\n",
    "            try:\n",
    "                sample = X.head(1)\n",
    "                transformed = preprocessor.transform(sample)\n",
    "                n_features = transformed.shape[1]\n",
    "                feature_names = [f\"feature_{i}\" for i in range(n_features)]\n",
    "            except:\n",
    "                # Use original column names as last resort\n",
    "                feature_names = X.columns.tolist()\n",
    "        \n",
    "        return feature_names\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting feature names: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_feature_importance_enhanced(model, model_name):\n",
    "    \"\"\"Enhanced feature importance extraction with multiple fallback methods\"\"\"\n",
    "    try:\n",
    "        # Handle ensemble models first\n",
    "        if 'ensemble' in model_name.lower() or 'voting' in model_name.lower():\n",
    "            return extract_ensemble_importance_enhanced(model, model_name)\n",
    "        \n",
    "        # Get the classifier from the pipeline\n",
    "        classifier = None\n",
    "        if hasattr(model, 'named_steps'):\n",
    "            # Look for common classifier step names\n",
    "            classifier_names = ['clf', 'classifier', 'estimator', 'model']\n",
    "            for name in classifier_names:\n",
    "                if name in model.named_steps:\n",
    "                    classifier = model.named_steps[name]\n",
    "                    break\n",
    "            \n",
    "            # If not found, look for any step with importance attributes\n",
    "            if classifier is None:\n",
    "                for step_name, step in model.named_steps.items():\n",
    "                    if hasattr(step, 'feature_importances_') or hasattr(step, 'coef_'):\n",
    "                        classifier = step\n",
    "                        break\n",
    "        else:\n",
    "            classifier = model\n",
    "        \n",
    "        if classifier is None:\n",
    "            print(f\"Could not find classifier in {model_name}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Extract importance based on classifier type\n",
    "        if hasattr(classifier, 'feature_importances_'):\n",
    "            # Tree-based models (Random Forest, XGBoost, etc.)\n",
    "            importances = classifier.feature_importances_\n",
    "            importance_type = f'Tree_Feature_Importance_{type(classifier).__name__}'\n",
    "        elif hasattr(classifier, 'coef_'):\n",
    "            # Linear models (Logistic Regression, etc.)\n",
    "            if len(classifier.coef_.shape) > 1:\n",
    "                importances = np.abs(classifier.coef_[0])  # Binary classification\n",
    "            else:\n",
    "                importances = np.abs(classifier.coef_)\n",
    "            importance_type = f'Linear_Coefficient_Magnitude_{type(classifier).__name__}'\n",
    "        else:\n",
    "            print(f\"âš ï¸  Classifier {type(classifier).__name__} doesn't have extractable feature importance\")\n",
    "            return None, None\n",
    "        \n",
    "        return importances, importance_type\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting importance from {model_name}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def extract_ensemble_importance_enhanced(ensemble_model, model_name):\n",
    "    \"\"\"Enhanced ensemble importance extraction\"\"\"\n",
    "    try:\n",
    "        if hasattr(ensemble_model, 'estimators_'):\n",
    "            # VotingClassifier or similar\n",
    "            all_importances = []\n",
    "            estimator_info = []\n",
    "            \n",
    "            for estimator_name, estimator in ensemble_model.estimators_:\n",
    "                imp, imp_type = extract_feature_importance_enhanced(estimator, estimator_name)\n",
    "                if imp is not None:\n",
    "                    all_importances.append(imp)\n",
    "                    estimator_info.append((estimator_name, imp_type))\n",
    "            \n",
    "            if all_importances:\n",
    "                # Average importance across estimators (equal weights)\n",
    "                avg_importance = np.mean(all_importances, axis=0)\n",
    "                importance_type = f'Ensemble_Average_Importance_{len(all_importances)}_estimators'\n",
    "                \n",
    "                print(f\"   Combined importance from {len(all_importances)} estimators:\")\n",
    "                for name, imp_type in estimator_info:\n",
    "                    print(f\"     â€¢ {name}: {imp_type}\")\n",
    "                \n",
    "                return avg_importance, importance_type\n",
    "        \n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting ensemble importance: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Extract feature names and importance from champion model\n",
    "if winning_model is not None:\n",
    "    feature_names = get_feature_names_from_pipeline(winning_model)\n",
    "    importances, importance_type = extract_feature_importance_enhanced(winning_model, champion_model_name)\n",
    "    \n",
    "    if feature_names is not None and importances is not None:\n",
    "        print(f\"âœ… Extracted {len(feature_names)} feature names\")\n",
    "        print(f\"âœ… Extracted {len(importances)} importance values\")\n",
    "        print(f\"   Importance type: {importance_type}\")\n",
    "        \n",
    "        # Ensure arrays have same length\n",
    "        min_length = min(len(feature_names), len(importances))\n",
    "        feature_names = feature_names[:min_length]\n",
    "        importances = importances[:min_length]\n",
    "        \n",
    "        # Create feature importance dataframe\n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': importances,\n",
    "            'Abs_Importance': np.abs(importances)\n",
    "        }).sort_values('Abs_Importance', ascending=False)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š TOP 20 MOST IMPORTANT FEATURES (CHAMPION MODEL):\")\n",
    "        print(\"-\" * 60)\n",
    "        display(feature_importance_df.head(20))\n",
    "        \n",
    "    else:\n",
    "        print(\"âš ï¸  Could not extract feature importance. Using permutation importance...\")\n",
    "        winning_model = None  # Trigger permutation importance\n",
    "\n",
    "# 4. Permutation importance as fallback or validation\n",
    "if winning_model is None or feature_importance_df.empty:\n",
    "    print(\"\\nðŸ“Š CALCULATING PERMUTATION IMPORTANCE...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        from sklearn.inspection import permutation_importance\n",
    "        \n",
    "        # Use best available model for permutation importance\n",
    "        if winning_model is not None:\n",
    "            perm_model = winning_model\n",
    "        else:\n",
    "            # Find any available trained model\n",
    "            for source_name, var_name in model_sources:\n",
    "                if var_name in globals():\n",
    "                    model_dict = globals()[var_name]\n",
    "                    if isinstance(model_dict, dict) and len(model_dict) > 0:\n",
    "                        perm_model = list(model_dict.values())[0]\n",
    "                        champion_model_name = list(model_dict.keys())[0]\n",
    "                        print(f\"Using {champion_model_name} for permutation importance\")\n",
    "                        break\n",
    "        \n",
    "        # Calculate permutation importance\n",
    "        perm_importance = permutation_importance(perm_model, X_test, y_test, \n",
    "                                               n_repeats=10, random_state=42, \n",
    "                                               scoring='f1_weighted')\n",
    "        \n",
    "        # Create feature importance dataframe\n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'Feature': X_test.columns,\n",
    "            'Importance': perm_importance.importances_mean,\n",
    "            'Importance_Std': perm_importance.importances_std,\n",
    "            'Abs_Importance': np.abs(perm_importance.importances_mean)\n",
    "        }).sort_values('Abs_Importance', ascending=False)\n",
    "        \n",
    "        importance_type = \"Permutation_Importance\"\n",
    "        \n",
    "        print(f\"âœ… Calculated permutation importance for {len(feature_importance_df)} features\")\n",
    "        print(f\"\\nðŸ“Š TOP 20 MOST IMPORTANT FEATURES (Permutation Importance):\")\n",
    "        print(\"-\" * 60)\n",
    "        display(feature_importance_df.head(20))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error calculating permutation importance: {e}\")\n",
    "        # Create dummy data for demonstration\n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'Feature': X.columns[:20],\n",
    "            'Importance': np.random.rand(20),\n",
    "            'Abs_Importance': np.random.rand(20)\n",
    "        }).sort_values('Abs_Importance', ascending=False)\n",
    "\n",
    "# 5. Enhanced feature categorization with business context\n",
    "print(\"\\n5. ENHANCED FEATURE CATEGORIZATION WITH BUSINESS CONTEXT\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def categorize_features_enhanced(feature_names):\n",
    "    \"\"\"Enhanced feature categorization with business context\"\"\"\n",
    "    categories = {\n",
    "        'Customer_Demographics': [],\n",
    "        'Usage_Consumption_Patterns': [],\n",
    "        'Pricing_Financial': [],\n",
    "        'Channel_Origin': [],\n",
    "        'Service_Satisfaction': [],\n",
    "        'Temporal_Behavioral': [],\n",
    "        'Contract_Subscription': [],\n",
    "        'Geographic_Location': [],\n",
    "        'Energy_Specific': [],\n",
    "        'Derived_Engineered': [],\n",
    "        'Other': []\n",
    "    }\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        feature_lower = feature.lower()\n",
    "        \n",
    "        # Customer Demographics\n",
    "        if any(keyword in feature_lower for keyword in ['age', 'gender', 'income', 'education', 'family', 'demographic']):\n",
    "            categories['Customer_Demographics'].append(feature)\n",
    "        \n",
    "        # Usage and Consumption Patterns\n",
    "        elif any(keyword in feature_lower for keyword in ['usage', 'consumption', 'cons_', 'demand', 'kwh', 'therm', 'energy_', 'gas_']):\n",
    "            categories['Usage_Consumption_Patterns'].append(feature)\n",
    "        \n",
    "        # Pricing and Financial\n",
    "        elif any(keyword in feature_lower for keyword in ['price', 'rate', 'cost', 'tariff', 'bill', 'payment', 'amount', 'revenue', 'margin']):\n",
    "            categories['Pricing_Financial'].append(feature)\n",
    "        \n",
    "        # Channel and Origin\n",
    "        elif any(keyword in feature_lower for keyword in ['channel', 'sales', 'origin', 'source', 'acquisition']):\n",
    "            categories['Channel_Origin'].append(feature)\n",
    "        \n",
    "        # Service and Satisfaction\n",
    "        elif any(keyword in feature_lower for keyword in ['service', 'support', 'complaint', 'satisfaction', 'quality', 'rating']):\n",
    "            categories['Service_Satisfaction'].append(feature)\n",
    "        \n",
    "        # Temporal and Behavioral\n",
    "        elif any(keyword in feature_lower for keyword in ['date', 'time', 'month', 'year', 'tenure', 'duration', 'frequency', 'pattern']):\n",
    "            categories['Temporal_Behavioral'].append(feature)\n",
    "        \n",
    "        # Contract and Subscription\n",
    "        elif any(keyword in feature_lower for keyword in ['contract', 'subscription', 'subscribed', 'power', 'plan', 'tier']):\n",
    "            categories['Contract_Subscription'].append(feature)\n",
    "        \n",
    "        # Geographic and Location\n",
    "        elif any(keyword in feature_lower for keyword in ['region', 'zone', 'area', 'location', 'geographic', 'postal']):\n",
    "            categories['Geographic_Location'].append(feature)\n",
    "        \n",
    "        # Energy-Specific Features\n",
    "        elif any(keyword in feature_lower for keyword in ['peak', 'off_peak', 'load', 'grid', 'meter', 'reading']):\n",
    "            categories['Energy_Specific'].append(feature)\n",
    "        \n",
    "        # Derived and Engineered Features\n",
    "        elif any(keyword in feature_lower for keyword in ['ratio', 'index', 'score', 'rank', 'var', 'diff', 'change']):\n",
    "            categories['Derived_Engineered'].append(feature)\n",
    "        \n",
    "        # Everything else\n",
    "        else:\n",
    "            categories['Other'].append(feature)\n",
    "    \n",
    "    return categories\n",
    "\n",
    "# Categorize features with enhanced business context\n",
    "feature_categories = categorize_features_enhanced(feature_importance_df['Feature'].tolist())\n",
    "\n",
    "print(\"ðŸ” ENHANCED FEATURE CATEGORIES:\")\n",
    "for category, features in feature_categories.items():\n",
    "    if features:\n",
    "        print(f\"\\n{category.replace('_', ' ').upper()} ({len(features)} features):\")\n",
    "        \n",
    "        # Show top features in each category with their importance\n",
    "        category_features = feature_importance_df[feature_importance_df['Feature'].isin(features)]\n",
    "        top_in_category = category_features.head(5)\n",
    "        \n",
    "        for _, row in top_in_category.iterrows():\n",
    "            print(f\"   â€¢ {row['Feature']}: {row['Importance']:.4f}\")\n",
    "        \n",
    "        if len(features) > 5:\n",
    "            print(f\"   ... and {len(features) - 5} more features\")\n",
    "\n",
    "# 6. Enhanced category importance analysis\n",
    "print(\"\\n6. ENHANCED CATEGORY IMPORTANCE ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "category_importance = {}\n",
    "for category, features in feature_categories.items():\n",
    "    if features:\n",
    "        category_scores = feature_importance_df[feature_importance_df['Feature'].isin(features)]['Importance']\n",
    "        if len(category_scores) > 0:\n",
    "            category_importance[category] = {\n",
    "                'total_importance': float(category_scores.sum()),\n",
    "                'avg_importance': float(category_scores.mean()),\n",
    "                'max_importance': float(category_scores.max()),\n",
    "                'feature_count': len(features),\n",
    "                'top_feature': feature_importance_df[feature_importance_df['Feature'].isin(features)].iloc[0]['Feature'],\n",
    "                'importance_contribution_pct': float((category_scores.sum() / feature_importance_df['Importance'].sum()) * 100)\n",
    "            }\n",
    "\n",
    "category_summary = pd.DataFrame(category_importance).T.sort_values('total_importance', ascending=False)\n",
    "\n",
    "print(\"ðŸ“Š ENHANCED CATEGORY IMPORTANCE SUMMARY:\")\n",
    "display(category_summary.round(4))\n",
    "\n",
    "# 7. Advanced visualizations for champion model\n",
    "print(\"\\n7. ADVANCED FEATURE IMPORTANCE VISUALIZATIONS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Plot 7.1: Top 20 individual features (enhanced)\n",
    "print(\"Visualization 7.1: Top 20 Feature Importance (Champion Model)\")\n",
    "plt.figure(figsize=(14, 10))\n",
    "top_20_features = feature_importance_df.head(20)\n",
    "\n",
    "# Color code by category\n",
    "feature_colors = []\n",
    "color_map = {\n",
    "    'Customer_Demographics': 'blue',\n",
    "    'Usage_Consumption_Patterns': 'green', \n",
    "    'Pricing_Financial': 'red',\n",
    "    'Channel_Origin': 'orange',\n",
    "    'Service_Satisfaction': 'purple',\n",
    "    'Temporal_Behavioral': 'brown',\n",
    "    'Contract_Subscription': 'pink',\n",
    "    'Geographic_Location': 'gray',\n",
    "    'Energy_Specific': 'olive',\n",
    "    'Derived_Engineered': 'cyan',\n",
    "    'Other': 'black'\n",
    "}\n",
    "\n",
    "for feature in top_20_features['Feature']:\n",
    "    feature_category = 'Other'\n",
    "    for category, features in feature_categories.items():\n",
    "        if feature in features:\n",
    "            feature_category = category\n",
    "            break\n",
    "    feature_colors.append(color_map.get(feature_category, 'black'))\n",
    "\n",
    "bars = plt.barh(range(len(top_20_features)), top_20_features['Importance'], \n",
    "                color=feature_colors, alpha=0.8)\n",
    "\n",
    "plt.yticks(range(len(top_20_features)), [f[:40] + '...' if len(f) > 40 else f for f in top_20_features['Feature']], fontsize=10)\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.title(f'Top 20 Most Important Features\\n(Champion Model: {champion_model_name})', fontweight='bold', fontsize=14)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    plt.annotate(f'{width:.4f}',\n",
    "                xy=(width, bar.get_y() + bar.get_height() / 2),\n",
    "                xytext=(3, 0),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='left', va='center', fontsize=9)\n",
    "\n",
    "# Create legend for categories\n",
    "legend_elements = [plt.Rectangle((0,0),1,1, facecolor=color, alpha=0.8, label=cat.replace('_', ' ')) \n",
    "                  for cat, color in color_map.items() if cat in [cat for cat, features in feature_categories.items() if features]]\n",
    "plt.legend(handles=legend_elements, loc='lower right', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 7.2: Category importance with business context\n",
    "print(\"Visualization 7.2: Feature Category Importance\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "categories = list(category_importance.keys())\n",
    "total_importances = [category_importance[cat]['total_importance'] for cat in categories]\n",
    "colors = [color_map.get(cat, 'black') for cat in categories]\n",
    "\n",
    "bars = plt.bar(range(len(categories)), total_importances, color=colors, alpha=0.8)\n",
    "plt.xlabel('Feature Category')\n",
    "plt.ylabel('Total Importance Score')\n",
    "plt.title('Feature Importance by Business Category\\n(Champion Model)', fontweight='bold', fontsize=14)\n",
    "plt.xticks(range(len(categories)), [cat.replace('_', '\\n') for cat in categories], rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels and contribution percentages\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    contribution = category_importance[categories[i]]['importance_contribution_pct']\n",
    "    plt.annotate(f'{height:.3f}\\n({contribution:.1f}%)',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 7.3: Feature importance distribution by category\n",
    "print(\"Visualization 7.3: Feature Importance Distribution by Category\")\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create box plot of importance by category\n",
    "category_data = []\n",
    "category_labels = []\n",
    "\n",
    "for category, features in feature_categories.items():\n",
    "    if features and len(features) > 1:  # Only include categories with multiple features\n",
    "        category_scores = feature_importance_df[feature_importance_df['Feature'].isin(features)]['Importance']\n",
    "        if len(category_scores) > 0:\n",
    "            category_data.append(category_scores.values)\n",
    "            category_labels.append(category.replace('_', '\\n'))\n",
    "\n",
    "if category_data:\n",
    "    bp = plt.boxplot(category_data, labels=category_labels, patch_artist=True)\n",
    "    \n",
    "    # Color the boxes\n",
    "    for i, patch in enumerate(bp['boxes']):\n",
    "        original_category = category_labels[i].replace('\\n', '_')\n",
    "        patch.set_facecolor(color_map.get(original_category, 'lightgray'))\n",
    "        patch.set_alpha(0.8)\n",
    "    \n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    plt.title('Feature Importance Distribution by Category\\n(Champion Model)', fontweight='bold', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 7.4: Top features heatmap\n",
    "print(\"Visualization 7.4: Top Features Correlation with Business Categories\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a matrix showing top features and their categories\n",
    "top_30_features = feature_importance_df.head(30)\n",
    "category_matrix = np.zeros((len(top_30_features), len(feature_categories)))\n",
    "\n",
    "for i, feature in enumerate(top_30_features['Feature']):\n",
    "    for j, (category, features) in enumerate(feature_categories.items()):\n",
    "        if feature in features:\n",
    "            category_matrix[i, j] = top_30_features.iloc[i]['Importance']\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(category_matrix, \n",
    "           xticklabels=[cat.replace('_', '\\n') for cat in feature_categories.keys()],\n",
    "           yticklabels=[f[:30] + '...' if len(f) > 30 else f for f in top_30_features['Feature']],\n",
    "           cmap='YlOrRd', \n",
    "           annot=False,\n",
    "           cbar_kws={'label': 'Feature Importance'})\n",
    "\n",
    "plt.title('Top 30 Features by Business Category\\n(Champion Model)', fontweight='bold', fontsize=14)\n",
    "plt.xlabel('Business Categories')\n",
    "plt.ylabel('Top Features')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Advanced feature interaction analysis\n",
    "print(\"\\n8. ADVANCED FEATURE INTERACTION ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Analyze interactions between top features and churn\n",
    "if len(feature_importance_df) > 0:\n",
    "    print(\"ðŸ” TOP FEATURES vs CHURN ANALYSIS (Champion Model):\")\n",
    "    \n",
    "    top_10_features = feature_importance_df.head(10)['Feature'].tolist()\n",
    "    available_features = [f for f in top_10_features if f in df.columns]\n",
    "    \n",
    "    if len(available_features) > 0:\n",
    "        # Create interaction analysis for top features\n",
    "        interaction_results = []\n",
    "        \n",
    "        for feature in available_features[:8]:  # Limit to top 8 for readability\n",
    "            try:\n",
    "                if df[feature].dtype in ['object', 'category']:\n",
    "                    # Categorical feature\n",
    "                    churn_by_category = df.groupby(feature)[target_col].agg(['count', 'mean']).round(3)\n",
    "                    feature_type = 'Categorical'\n",
    "                    interaction_strength = churn_by_category['mean'].std()  # Variation in churn rates\n",
    "                elif df[feature].nunique() < 20:\n",
    "                    # Discrete numerical feature\n",
    "                    churn_by_value = df.groupby(feature)[target_col].agg(['count', 'mean']).round(3)\n",
    "                    feature_type = 'Discrete'\n",
    "                    interaction_strength = churn_by_value['mean'].std()\n",
    "                else:\n",
    "                    # Continuous numerical feature\n",
    "                    churn_correlation = df[[feature, target_col]].corr().iloc[0, 1]\n",
    "                    feature_type = 'Continuous'\n",
    "                    interaction_strength = abs(churn_correlation)\n",
    "                \n",
    "                interaction_results.append({\n",
    "                    'Feature': feature,\n",
    "                    'Type': feature_type,\n",
    "                    'Interaction_Strength': interaction_strength,\n",
    "                    'Importance': feature_importance_df[feature_importance_df['Feature'] == feature]['Importance'].iloc[0]\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Error analyzing {feature}: {e}\")\n",
    "        \n",
    "        # Display interaction analysis\n",
    "        if interaction_results:\n",
    "            interaction_df = pd.DataFrame(interaction_results).sort_values('Interaction_Strength', ascending=False)\n",
    "            \n",
    "            print(f\"\\nðŸ“Š FEATURE INTERACTION STRENGTH ANALYSIS:\")\n",
    "            display(interaction_df.round(4))\n",
    "            \n",
    "            # Plot interaction strength vs importance\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            scatter = plt.scatter(interaction_df['Importance'], interaction_df['Interaction_Strength'], \n",
    "                                s=100, alpha=0.7, c=range(len(interaction_df)), cmap='viridis')\n",
    "            \n",
    "            plt.xlabel('Feature Importance')\n",
    "            plt.ylabel('Interaction Strength with Churn')\n",
    "            plt.title('Feature Importance vs Churn Interaction Strength\\n(Champion Model)', fontweight='bold')\n",
    "            \n",
    "            # Add feature labels\n",
    "            for i, row in interaction_df.iterrows():\n",
    "                plt.annotate(row['Feature'][:15] + '...' if len(row['Feature']) > 15 else row['Feature'],\n",
    "                            (row['Importance'], row['Interaction_Strength']),\n",
    "                            xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "            \n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# 9. Business insights and strategic recommendations\n",
    "print(\"\\n9. BUSINESS INSIGHTS AND STRATEGIC RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nðŸŽ¯ KEY FINDINGS FROM CHAMPION MODEL:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Champion model insights\n",
    "print(f\"1. CHAMPION MODEL PERFORMANCE:\")\n",
    "print(f\"   â€¢ Model: {champion_model_name}\")\n",
    "print(f\"   â€¢ Churn Detection Accuracy: {champion_metrics['Accuracy_1']:.1%}\")\n",
    "if 'churn_leaderboard' in locals():\n",
    "    print(f\"   â€¢ Performance Category: {champion_metrics['Churn_Performance']}\")\n",
    "    print(f\"   â€¢ Leaderboard Position: #{champion_metrics['Churn_Rank']} out of {len(churn_leaderboard)}\")\n",
    "\n",
    "# Top feature insights\n",
    "if len(feature_importance_df) > 0:\n",
    "    top_feature = feature_importance_df.iloc[0]\n",
    "    print(f\"\\n2. MOST CRITICAL CHURN DRIVER:\")\n",
    "    print(f\"   â€¢ Feature: {top_feature['Feature']}\")\n",
    "    print(f\"   â€¢ Importance Score: {top_feature['Importance']:.4f}\")\n",
    "    print(f\"   â€¢ Business Impact: This feature has the strongest influence on churn predictions\")\n",
    "\n",
    "# Category insights\n",
    "if category_importance:\n",
    "    top_category = max(category_importance.items(), key=lambda x: x[1]['total_importance'])\n",
    "    print(f\"\\n3. MOST IMPORTANT BUSINESS AREA:\")\n",
    "    print(f\"   â€¢ Category: {top_category[0].replace('_', ' ')}\")\n",
    "    print(f\"   â€¢ Total Importance: {top_category[1]['total_importance']:.4f}\")\n",
    "    print(f\"   â€¢ Contribution: {top_category[1]['importance_contribution_pct']:.1f}% of total importance\")\n",
    "    print(f\"   â€¢ Top Feature: {top_category[1]['top_feature']}\")\n",
    "\n",
    "# Feature diversity insights\n",
    "print(f\"\\n4. FEATURE DIVERSITY ANALYSIS:\")\n",
    "contributing_categories = len([cat for cat, info in category_importance.items() if info['total_importance'] > 0.01])\n",
    "print(f\"   â€¢ {contributing_categories} feature categories contribute significantly to churn prediction\")\n",
    "print(f\"   â€¢ Model uses a diverse set of {len(feature_importance_df)} features\")\n",
    "print(f\"   â€¢ Feature importance type: {importance_type}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ STRATEGIC BUSINESS RECOMMENDATIONS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"1. IMMEDIATE CHURN PREVENTION ACTIONS:\")\n",
    "if len(feature_importance_df) > 0:\n",
    "    for i, (_, row) in enumerate(feature_importance_df.head(5).iterrows(), 1):\n",
    "        feature_name = row['Feature']\n",
    "        # Determine business category\n",
    "        business_category = 'General'\n",
    "        for category, features in feature_categories.items():\n",
    "            if feature_name in features:\n",
    "                business_category = category.replace('_', ' ')\n",
    "                break\n",
    "        print(f\"   {i}. Monitor {feature_name}\")\n",
    "        print(f\"      Category: {business_category}\")\n",
    "        print(f\"      Impact Score: {row['Importance']:.4f}\")\n",
    "\n",
    "print(f\"\\n2. CATEGORY-BASED INTERVENTION STRATEGIES:\")\n",
    "if category_importance:\n",
    "    top_3_categories = sorted(category_importance.items(), key=lambda x: x[1]['total_importance'], reverse=True)[:3]\n",
    "    for i, (category, info) in enumerate(top_3_categories, 1):\n",
    "        print(f\"   {i}. {category.replace('_', ' ').title()}:\")\n",
    "        print(f\"      â€¢ Priority Level: {'High' if i == 1 else 'Medium' if i == 2 else 'Standard'}\")\n",
    "        print(f\"      â€¢ Focus on {info['feature_count']} key features\")\n",
    "        print(f\"      â€¢ Importance Contribution: {info['importance_contribution_pct']:.1f}%\")\n",
    "\n",
    "print(f\"\\n3. MONITORING AND ALERTING RECOMMENDATIONS:\")\n",
    "print(\"   â€¢ Set up real-time monitoring for top 10 features\")\n",
    "print(\"   â€¢ Create automated alerts for significant changes in key features\")\n",
    "print(\"   â€¢ Implement feature drift detection for model performance monitoring\")\n",
    "print(\"   â€¢ Schedule monthly feature importance review meetings\")\n",
    "\n",
    "print(f\"\\n4. CUSTOMER SEGMENTATION STRATEGIES:\")\n",
    "print(\"   â€¢ Develop customer risk profiles based on top feature combinations\")\n",
    "print(\"   â€¢ Create targeted retention programs for high-impact feature segments\")\n",
    "print(\"   â€¢ Implement personalized interventions based on feature importance\")\n",
    "print(\"   â€¢ Design predictive customer journey mapping using key features\")\n",
    "\n",
    "print(f\"\\n5. MODEL OPTIMIZATION OPPORTUNITIES:\")\n",
    "print(\"   â€¢ Consider feature engineering for top-performing categories\")\n",
    "print(\"   â€¢ Explore interaction terms between high-importance features\")\n",
    "print(\"   â€¢ Investigate ensemble methods combining category-specific models\")\n",
    "print(\"   â€¢ Plan regular model retraining with updated feature importance\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHAMPION MODEL FEATURE IMPORTANCE ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Final summary with champion model context\n",
    "print(f\"\"\"\n",
    "âœ… Champion model feature analysis complete with comprehensive insights.\n",
    "\n",
    "ðŸ† CHAMPION MODEL: {champion_model_name}\n",
    "   ðŸ“Š Churn Detection Performance: {champion_metrics['Accuracy_1']:.1%}\n",
    "   ðŸ“Š Overall Performance: F1_Weighted = {champion_metrics['F1_Weighted']:.4f}\n",
    "   ðŸ“Š Feature Analysis: {len(feature_importance_df)} features analyzed\n",
    "   ðŸ“Š Business Categories: {len([cat for cat in category_importance.keys()])} categories identified\n",
    "\n",
    "ðŸš€ The champion model provides clear guidance for business interventions\n",
    "   and customer retention strategies based on data-driven feature importance.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6103d7",
   "metadata": {},
   "source": [
    "### 10.2 Price Sensitivity\n",
    "Based on the winning model, what is the maximum peak and off peak prices for energy and gas that we can set for each channel, maximizing our net margin while minimizing churn?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135cb082",
   "metadata": {},
   "source": [
    "#### 10.2.1  Price Sensitivity Analysis for Channel Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.2.1  Price Sensitivity Analysis for Channel Sales\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIXED PRICE SENSITIVITY ANALYSIS - CORRECT PRICE COLUMNS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This section analyzes price sensitivity using the champion model from our comprehensive\n",
    "churn predictor leaderboard with the CORRECT price columns that can actually be adjusted:\n",
    "- price_peak_var_max (maximum peak price) (WRONG COLUMN)\n",
    "- price_peak_var_min (minimum peak price) (WRONG COLUMN)\n",
    "\"\"\")\n",
    "\n",
    "# 1. Identify and verify the correct price columns\n",
    "print(\"\\n1. VERIFYING CORRECT PRICE COLUMNS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "#primary_price_col = 'price_peak_var_max' #(WRONG COLUMN)\n",
    "#secondary_price_col = 'price_peak_var_min' #(WRONG COLUMN)\n",
    "primary_price_col = 'forecast_discount_energy'\n",
    "secondary_price_col = 'net_margin'\n",
    "\n",
    "\n",
    "# Check if these columns exist in the dataset\n",
    "price_columns_found = []\n",
    "if primary_price_col in df.columns:\n",
    "    price_columns_found.append(primary_price_col)\n",
    "    print(f\"âœ… Found primary price column: {primary_price_col}\")\n",
    "else:\n",
    "    print(f\"âŒ Primary price column not found: {primary_price_col}\")\n",
    "\n",
    "if secondary_price_col in df.columns:\n",
    "    price_columns_found.append(secondary_price_col)\n",
    "    print(f\"âœ… Found secondary price column: {secondary_price_col}\")\n",
    "else:\n",
    "    print(f\"âŒ Secondary price column not found: {secondary_price_col}\")\n",
    "\n",
    "if len(price_columns_found) >= 1:\n",
    "    print(f\"\\nðŸ“Š PRICE COLUMN ANALYSIS:\")\n",
    "    price_stats = df[price_columns_found].describe()\n",
    "    display(price_stats.round(4))\n",
    "    \n",
    "    # Calculate baseline prices and ranges\n",
    "    baseline_prices = {}\n",
    "    price_ranges = {}\n",
    "    \n",
    "    for col in price_columns_found:\n",
    "        stats = df[col].describe()\n",
    "        baseline_prices[col] = stats['mean']\n",
    "        \n",
    "        # Create realistic price range (mean Â± 2*std, bounded by observed min/max)\n",
    "        std_dev = stats['std']\n",
    "        mean_price = stats['mean']\n",
    "        \n",
    "        lower_bound = max(stats['min'], mean_price - 2*std_dev)\n",
    "        upper_bound = min(stats['max'] * 1.2, mean_price + 2*std_dev)\n",
    "        \n",
    "        price_ranges[col] = np.linspace(lower_bound, upper_bound, 8)\n",
    "        \n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"   Baseline (mean): ${mean_price:.4f}\")\n",
    "        print(f\"   Test range: ${lower_bound:.4f} - ${upper_bound:.4f}\")\n",
    "        print(f\"   Observed range: ${stats['min']:.4f} - ${stats['max']:.4f}\")\n",
    "        print(f\"   Standard deviation: ${std_dev:.4f}\")\n",
    "        \n",
    "        # Check correlation with churn\n",
    "        correlation = df[col].corr(df[target_col])\n",
    "        print(f\"   Churn correlation: {correlation:.4f}\")\n",
    "\n",
    "# 2. Get the champion model\n",
    "print(f\"\\n2. RETRIEVING CHAMPION MODEL\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use the best performing model from our analysis\n",
    "if 'churn_leaderboard' in locals():\n",
    "    champion_model_name = churn_leaderboard.index[0]\n",
    "    champion_metrics = churn_leaderboard.iloc[0]\n",
    "else:\n",
    "    champion_model_name = all_results_df.loc[all_results_df['Accuracy_1'].idxmax()].name\n",
    "    champion_metrics = all_results_df.loc[champion_model_name]\n",
    "\n",
    "print(f\"ðŸ† CHAMPION MODEL: {champion_model_name}\")\n",
    "print(f\"   Churn Accuracy: {champion_metrics['Accuracy_1']:.4f}\")\n",
    "if 'F1_Weighted' in champion_metrics:\n",
    "    print(f\"   F1_Weighted: {champion_metrics['F1_Weighted']:.4f}\")\n",
    "\n",
    "# Find the champion model pipeline\n",
    "champion_pipeline = None\n",
    "# model_sources = [\n",
    "#     ('advanced_pipes_optimal', 'advanced_pipes_optimal'),\n",
    "#     ('ultimate_ensembles', 'ultimate_ensembles'),\n",
    "#     ('churn_ensembles', 'churn_ensembles'),\n",
    "#     ('cost_sensitive_pipes', 'cost_sensitive_pipes'),\n",
    "#     ('advanced_sampling_pipes', 'advanced_sampling_pipes'),\n",
    "#     ('balanced_pipes', 'balanced_pipes'),\n",
    "#     ('baseline_pipes', 'baseline_pipes')\n",
    "# ]\n",
    "\n",
    "for source_name, var_name in model_sources:\n",
    "    try:\n",
    "        if var_name in globals():\n",
    "            model_dict = globals()[var_name]\n",
    "            if isinstance(model_dict, dict) and champion_model_name in model_dict:\n",
    "                champion_pipeline = model_dict[champion_model_name]\n",
    "                print(f\"âœ… Found champion model in: {source_name}\")\n",
    "                break\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "if champion_pipeline is None:\n",
    "    print(\"âš ï¸  Using fallback model for analysis\")\n",
    "    # Use any available high-performing model\n",
    "    for source_name, var_name in model_sources:\n",
    "        try:\n",
    "            if var_name in globals():\n",
    "                model_dict = globals()[var_name]\n",
    "                if isinstance(model_dict, dict) and len(model_dict) > 0:\n",
    "                    champion_pipeline = list(model_dict.values())[0]\n",
    "                    champion_model_name = list(model_dict.keys())[0]\n",
    "                    print(f\"âœ… Using fallback model: {champion_model_name}\")\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# 3. Enhanced price sensitivity simulation with correct columns\n",
    "print(\"\\n3. ENHANCED PRICE SENSITIVITY SIMULATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def corrected_price_sensitivity_simulation(model, base_data, price_col_max, price_col_min, \n",
    "                                         channels, baseline_prices, price_ranges, \n",
    "                                         baseline_revenue=150, sample_size=1000):\n",
    "    \"\"\"\n",
    "    Price sensitivity simulation using the correct price columns\n",
    "    \"\"\"\n",
    "    print(\"ðŸŽ¯ CORRECTED PRICE SENSITIVITY ANALYSIS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if price_col_max not in base_data.columns or price_col_min not in base_data.columns:\n",
    "        print(f\"âŒ Required price columns not found in data\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"Using price columns:\")\n",
    "    print(f\"   Max Price: {price_col_max}\")\n",
    "    print(f\"   Min Price: {price_col_min}\")\n",
    "    \n",
    "    channel_results = {}\n",
    "    \n",
    "    for channel in channels:\n",
    "        print(f\"\\nðŸ“Š Analyzing {channel} channel...\")\n",
    "        \n",
    "        # Filter data for this channel\n",
    "        channel_data = base_data[base_data['channel'] == channel].copy()\n",
    "        \n",
    "        if len(channel_data) == 0:\n",
    "            print(f\"   No data found for {channel}\")\n",
    "            continue\n",
    "        \n",
    "        # Sample for efficiency\n",
    "        if len(channel_data) > sample_size:\n",
    "            channel_data = channel_data.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "        # Get baseline predictions\n",
    "        try:\n",
    "            baseline_predictions = model.predict_proba(channel_data.drop(columns=['channel'], errors='ignore'))[:, 1]\n",
    "            baseline_churn_rate = np.mean(baseline_predictions)\n",
    "        except Exception as e:\n",
    "            print(f\"   Error getting baseline predictions: {e}\")\n",
    "            continue\n",
    "        \n",
    "        scenarios = []\n",
    "        \n",
    "        # Test price combinations\n",
    "        max_prices = price_ranges.get(price_col_max, [baseline_prices[price_col_max]])\n",
    "        min_prices = price_ranges.get(price_col_min, [baseline_prices[price_col_min]])\n",
    "        \n",
    "        for max_price in max_prices:\n",
    "            for min_price in min_prices:\n",
    "                # Ensure max_price >= min_price (logical constraint)\n",
    "                if max_price >= min_price:\n",
    "                    # Create modified dataset\n",
    "                    test_data = channel_data.copy()\n",
    "                    test_data[price_col_max] = max_price\n",
    "                    test_data[price_col_min] = min_price\n",
    "                    \n",
    "                    try:\n",
    "                        # Predict new churn probabilities\n",
    "                        new_predictions = model.predict_proba(test_data.drop(columns=['channel'], errors='ignore'))[:, 1]\n",
    "                        new_churn_rate = np.mean(new_predictions)\n",
    "                        \n",
    "                        # Calculate price changes\n",
    "                        max_price_change_pct = ((max_price - baseline_prices[price_col_max]) / baseline_prices[price_col_max] * 100)\n",
    "                        min_price_change_pct = ((min_price - baseline_prices[price_col_min]) / baseline_prices[price_col_min] * 100)\n",
    "                        \n",
    "                        # Calculate revenue impact\n",
    "                        # Assume revenue is related to the average of max and min prices\n",
    "                        avg_price_change = (max_price_change_pct + min_price_change_pct) / 2\n",
    "                        new_revenue = baseline_revenue * (1 + avg_price_change / 100)\n",
    "                        \n",
    "                        # Calculate net margin (revenue - churn cost)\n",
    "                        churn_cost = 500  # Cost of losing a customer\n",
    "                        expected_churn_cost = new_churn_rate * churn_cost\n",
    "                        net_margin = new_revenue - expected_churn_cost\n",
    "                        \n",
    "                        scenarios.append({\n",
    "                            'Channel': channel,\n",
    "                            'Max_Price': max_price,\n",
    "                            'Min_Price': min_price,\n",
    "                            'Max_Price_Change_%': max_price_change_pct,\n",
    "                            'Min_Price_Change_%': min_price_change_pct,\n",
    "                            'Avg_Price_Change_%': avg_price_change,\n",
    "                            'Baseline_Churn': baseline_churn_rate,\n",
    "                            'New_Churn': new_churn_rate,\n",
    "                            'Churn_Change': new_churn_rate - baseline_churn_rate,\n",
    "                            'Baseline_Revenue': baseline_revenue,\n",
    "                            'New_Revenue': new_revenue,\n",
    "                            'Revenue_Change': new_revenue - baseline_revenue,\n",
    "                            'Revenue_Change_%': ((new_revenue - baseline_revenue) / baseline_revenue * 100),\n",
    "                            'Expected_Churn_Cost': expected_churn_cost,\n",
    "                            'Net_Margin': net_margin,\n",
    "                            'Sample_Size': len(test_data)\n",
    "                        })\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "        \n",
    "        if scenarios:\n",
    "            channel_results[channel] = pd.DataFrame(scenarios)\n",
    "            print(f\"   âœ… Completed {len(scenarios)} scenarios for {channel}\")\n",
    "    \n",
    "    return channel_results\n",
    "\n",
    "# 4. Run the corrected simulation\n",
    "if champion_pipeline is not None and len(price_columns_found) >= 2:\n",
    "    \n",
    "    # Prepare channel data\n",
    "    df_temp = df.copy()\n",
    "    if channel_sales_cols:\n",
    "        df_temp['channel'] = df_temp[channel_sales_cols].idxmax(axis=1).str.replace('channel_sales_', '')\n",
    "        unique_channels = df_temp['channel'].unique()\n",
    "    else:\n",
    "        # Create synthetic channels for demo\n",
    "        unique_channels = ['Online', 'Retail', 'Direct', 'Phone']\n",
    "        df_temp['channel'] = np.random.choice(unique_channels, size=len(df))\n",
    "    \n",
    "    print(f\"Found {len(unique_channels)} channels: {list(unique_channels)}\")\n",
    "    \n",
    "    # Run corrected simulation\n",
    "    corrected_results = corrected_price_sensitivity_simulation(\n",
    "        champion_pipeline, df_temp, primary_price_col, secondary_price_col, \n",
    "        unique_channels, baseline_prices, price_ranges\n",
    "    )\n",
    "    \n",
    "    # 5. Analyze results and find optimal pricing\n",
    "    print(f\"\\n5. CORRECTED PRICING OPTIMIZATION RESULTS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    optimal_scenarios_by_channel = {}\n",
    "    \n",
    "    for channel, results_df in corrected_results.items():\n",
    "        print(f\"\\nðŸ“‹ {channel.upper()} CHANNEL - CORRECTED ANALYSIS:\")\n",
    "        \n",
    "        # Display top 10 scenarios by net margin\n",
    "        top_scenarios = results_df.nlargest(10, 'Net_Margin')\n",
    "        display_cols = ['Max_Price', 'Min_Price', 'Max_Price_Change_%', 'Min_Price_Change_%',\n",
    "                       'New_Churn', 'Churn_Change', 'New_Revenue', 'Revenue_Change_%', 'Net_Margin']\n",
    "        display(top_scenarios[display_cols].round(3))\n",
    "        \n",
    "        # Find optimal scenario (best net margin with reasonable churn constraint)\n",
    "        viable_scenarios = results_df[results_df['Churn_Change'] < 0.15]  # Churn increase < 15%\n",
    "        \n",
    "        if len(viable_scenarios) > 0:\n",
    "            optimal_idx = viable_scenarios['Net_Margin'].idxmax()\n",
    "            optimal_scenario = viable_scenarios.loc[optimal_idx]\n",
    "            optimal_scenarios_by_channel[channel] = optimal_scenario\n",
    "            \n",
    "            print(f\"\\nðŸŽ¯ OPTIMAL PRICING FOR {channel.upper()}:\")\n",
    "            print(f\"   Max Price: ${optimal_scenario['Max_Price']:.4f} ({optimal_scenario['Max_Price_Change_%']:+.1f}%)\")\n",
    "            print(f\"   Min Price: ${optimal_scenario['Min_Price']:.4f} ({optimal_scenario['Min_Price_Change_%']:+.1f}%)\")\n",
    "            print(f\"   Churn: {optimal_scenario['Baseline_Churn']:.1%} â†’ {optimal_scenario['New_Churn']:.1%} ({optimal_scenario['Churn_Change']:+.1%})\")\n",
    "            print(f\"   Revenue: ${optimal_scenario['Baseline_Revenue']:.2f} â†’ ${optimal_scenario['New_Revenue']:.2f} ({optimal_scenario['Revenue_Change_%']:+.1f}%)\")\n",
    "            print(f\"   Net Margin: ${optimal_scenario['Net_Margin']:.2f}\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸  No viable scenarios found for {channel} with churn constraint\")\n",
    "    \n",
    "    # 6. Visualizations\n",
    "    print(f\"\\n6. CORRECTED PRICING VISUALIZATIONS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if optimal_scenarios_by_channel:\n",
    "        \n",
    "        # Plot 6.1: Net Margin by Channel\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        channels = list(optimal_scenarios_by_channel.keys())\n",
    "        net_margins = [opt['Net_Margin'] for opt in optimal_scenarios_by_channel.values()]\n",
    "        \n",
    "        colors = ['green' if margin > 0 else 'red' for margin in net_margins]\n",
    "        bars = plt.bar(channels, net_margins, color=colors, alpha=0.8)\n",
    "        \n",
    "        plt.xlabel('Channel')\n",
    "        plt.ylabel('Net Margin ($)')\n",
    "        plt.title('Optimal Net Margin by Channel\\n(Corrected Price Analysis)', fontweight='bold', fontsize=14)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.annotate(f'${height:.1f}',\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 3 if height >= 0 else -15),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom' if height >= 0 else 'top', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot 6.2: Price Changes by Channel\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        x = np.arange(len(channels))\n",
    "        width = 0.35\n",
    "        \n",
    "        max_price_changes = [opt['Max_Price_Change_%'] for opt in optimal_scenarios_by_channel.values()]\n",
    "        min_price_changes = [opt['Min_Price_Change_%'] for opt in optimal_scenarios_by_channel.values()]\n",
    "        \n",
    "        bars1 = plt.bar(x - width/2, max_price_changes, width, label='Max Price Change', alpha=0.8, color='lightblue')\n",
    "        bars2 = plt.bar(x + width/2, min_price_changes, width, label='Min Price Change', alpha=0.8, color='lightgreen')\n",
    "        \n",
    "        plt.xlabel('Channel')\n",
    "        plt.ylabel('Price Change (%)')\n",
    "        plt.title('Optimal Price Changes by Channel\\n(Max vs Min Price)', fontweight='bold', fontsize=14)\n",
    "        plt.xticks(x, channels, rotation=45)\n",
    "        plt.legend()\n",
    "        plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot 6.3: Revenue vs Churn Trade-off\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        for i, channel in enumerate(channels):\n",
    "            churn_change = optimal_scenarios_by_channel[channel]['Churn_Change'] * 100\n",
    "            revenue_change = optimal_scenarios_by_channel[channel]['Revenue_Change_%']\n",
    "            plt.scatter(churn_change, revenue_change, s=150, alpha=0.8, label=channel)\n",
    "        \n",
    "        plt.xlabel('Churn Change (%)')\n",
    "        plt.ylabel('Revenue Change (%)')\n",
    "        plt.title('Revenue vs Churn Trade-off\\n(Optimal Scenarios)', fontweight='bold', fontsize=14)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 7. Business recommendations\n",
    "        print(f\"\\n7. CORRECTED BUSINESS RECOMMENDATIONS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        total_margin_improvement = sum(opt['Net_Margin'] for opt in optimal_scenarios_by_channel.values())\n",
    "        avg_revenue_change = np.mean([opt['Revenue_Change_%'] for opt in optimal_scenarios_by_channel.values()])\n",
    "        avg_churn_change = np.mean([opt['Churn_Change'] for opt in optimal_scenarios_by_channel.values()])\n",
    "        \n",
    "        print(f\"ðŸ“Š AGGREGATE IMPACT:\")\n",
    "        print(f\"   Total Net Margin: ${total_margin_improvement:.2f}\")\n",
    "        print(f\"   Average Revenue Change: {avg_revenue_change:+.1f}%\")\n",
    "        print(f\"   Average Churn Change: {avg_churn_change:+.1%}\")\n",
    "        \n",
    "        print(f\"\\nðŸ’¡ KEY INSIGHTS:\")\n",
    "        print(\"   â€¢ Max and min price boundaries create pricing flexibility\")\n",
    "        print(\"   â€¢ Different channels tolerate different price structures\")\n",
    "        print(\"   â€¢ Price ranges (max-min spread) affect customer behavior\")\n",
    "        print(\"   â€¢ Optimal pricing balances revenue growth and churn risk\")\n",
    "        \n",
    "        print(f\"\\nðŸŽ¯ IMPLEMENTATION STRATEGY:\")\n",
    "        print(\"   â€¢ Adjust max prices conservatively first (Â±5-10%)\")\n",
    "        print(\"   â€¢ Monitor customer response to min price changes\")\n",
    "        print(\"   â€¢ Test price range adjustments (max-min spread)\")\n",
    "        print(\"   â€¢ Implement channel-specific pricing strategies\")\n",
    "        print(\"   â€¢ Use A/B testing to validate model predictions\")\n",
    "        \n",
    "        best_channel = max(optimal_scenarios_by_channel.items(), key=lambda x: x[1]['Net_Margin'])\n",
    "        print(f\"\\nðŸ† BEST PERFORMING CHANNEL: {best_channel[0]}\")\n",
    "        print(f\"   Net Margin: ${best_channel[1]['Net_Margin']:.2f}\")\n",
    "        print(f\"   Max Price: ${best_channel[1]['Max_Price']:.4f} ({best_channel[1]['Max_Price_Change_%']:+.1f}%)\")\n",
    "        print(f\"   Min Price: ${best_channel[1]['Min_Price']:.4f} ({best_channel[1]['Min_Price_Change_%']:+.1f}%)\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸  Cannot complete corrected analysis:\")\n",
    "    if champion_pipeline is None:\n",
    "        print(\"   - Champion model pipeline not found\")\n",
    "    if len(price_columns_found) < 2:\n",
    "        print(f\"   - Only {len(price_columns_found)} price columns found, need both max and min\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CORRECTED PRICE SENSITIVITY ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ… Corrected price sensitivity analysis completed using proper price columns.\n",
    "\n",
    "ðŸ”§ CORRECTED COLUMNS USED:\n",
    "   â€¢ Primary: {primary_price_col} (Discounted energy price)\n",
    "   â€¢ Secondary: {secondary_price_col} (Net margin)\n",
    "\n",
    "\n",
    "\n",
    "ðŸŽ¯ BUSINESS LOGIC:\n",
    "   â€¢ Revenue optimization through max/min price adjustments\n",
    "   â€¢ Churn risk balanced against revenue opportunities  \n",
    "   â€¢ Channel-specific pricing strategies identified\n",
    "   â€¢ Implementation roadmap provided for pricing changes\n",
    "\n",
    "ðŸ“Š READY FOR STRATEGIC PRICING IMPLEMENTATION\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70018cc2",
   "metadata": {},
   "source": [
    "#### 10.2.2  Price Sensitivity Analysis for Orgin Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54663494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13.1.2  Price Sensitivity Analysis for Origin Up\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIXED PRICE SENSITIVITY ANALYSIS - ORIGIN UP CLASSES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This section analyzes price sensitivity using the champion model from our comprehensive\n",
    "churn predictor leaderboard with the CORRECT price columns that can actually be adjusted,\n",
    "but focusing on ORIGIN UP classes instead of channel sales:\n",
    "- price_peak_var_max (maximum peak price)\n",
    "- price_peak_var_min (minimum peak price)\n",
    "\"\"\")\n",
    "\n",
    "# 1. Identify and verify the correct price columns\n",
    "print(\"\\n1. VERIFYING CORRECT PRICE COLUMNS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "#primary_price_col = 'price_peak_var_max'\n",
    "#secondary_price_col = 'price_peak_var_min'\n",
    "primary_price_col = 'forecast_discount_energy'\n",
    "secondary_price_col = 'net_margin'\n",
    "\n",
    "\n",
    "# Check if these columns exist in the dataset\n",
    "price_columns_found = []\n",
    "if primary_price_col in df.columns:\n",
    "    price_columns_found.append(primary_price_col)\n",
    "    print(f\"âœ… Found primary price column: {primary_price_col}\")\n",
    "else:\n",
    "    print(f\"âŒ Primary price column not found: {primary_price_col}\")\n",
    "\n",
    "if secondary_price_col in df.columns:\n",
    "    price_columns_found.append(secondary_price_col)\n",
    "    print(f\"âœ… Found secondary price column: {secondary_price_col}\")\n",
    "else:\n",
    "    print(f\"âŒ Secondary price column not found: {secondary_price_col}\")\n",
    "\n",
    "if len(price_columns_found) >= 1:\n",
    "    print(f\"\\nðŸ“Š PRICE COLUMN ANALYSIS:\")\n",
    "    price_stats = df[price_columns_found].describe()\n",
    "    display(price_stats.round(4))\n",
    "    \n",
    "    # Calculate baseline prices and ranges\n",
    "    baseline_prices = {}\n",
    "    price_ranges = {}\n",
    "    \n",
    "    for col in price_columns_found:\n",
    "        stats = df[col].describe()\n",
    "        baseline_prices[col] = stats['mean']\n",
    "        \n",
    "        # Create realistic price range (mean Â± 2*std, bounded by observed min/max)\n",
    "        std_dev = stats['std']\n",
    "        mean_price = stats['mean']\n",
    "        \n",
    "        lower_bound = max(stats['min'], mean_price - 2*std_dev)\n",
    "        upper_bound = min(stats['max'] * 1.2, mean_price + 2*std_dev)\n",
    "        \n",
    "        price_ranges[col] = np.linspace(lower_bound, upper_bound, 8)\n",
    "        \n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"   Baseline (mean): ${mean_price:.4f}\")\n",
    "        print(f\"   Test range: ${lower_bound:.4f} - ${upper_bound:.4f}\")\n",
    "        print(f\"   Observed range: ${stats['min']:.4f} - ${stats['max']:.4f}\")\n",
    "        print(f\"   Standard deviation: ${std_dev:.4f}\")\n",
    "        \n",
    "        # Check correlation with churn\n",
    "        correlation = df[col].corr(df[target_col])\n",
    "        print(f\"   Churn correlation: {correlation:.4f}\")\n",
    "\n",
    "# 2. Get the champion model\n",
    "print(f\"\\n2. RETRIEVING CHAMPION MODEL\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use the best performing model from our analysis\n",
    "if 'churn_leaderboard' in locals():\n",
    "    champion_model_name = churn_leaderboard.index[0]\n",
    "    champion_metrics = churn_leaderboard.iloc[0]\n",
    "else:\n",
    "    champion_model_name = all_results_df.loc[all_results_df['Accuracy_1'].idxmax()].name\n",
    "    champion_metrics = all_results_df.loc[champion_model_name]\n",
    "\n",
    "print(f\"ðŸ† CHAMPION MODEL: {champion_model_name}\")\n",
    "print(f\"   Churn Accuracy: {champion_metrics['Accuracy_1']:.4f}\")\n",
    "if 'F1_Weighted' in champion_metrics:\n",
    "    print(f\"   F1_Weighted: {champion_metrics['F1_Weighted']:.4f}\")\n",
    "\n",
    "# Find the champion model pipeline\n",
    "champion_pipeline = None\n",
    "# model_sources = [\n",
    "#     ('advanced_pipes_optimal', 'advanced_pipes_optimal'),\n",
    "#     ('ultimate_ensembles', 'ultimate_ensembles'),\n",
    "#     ('churn_ensembles', 'churn_ensembles'),\n",
    "#     ('cost_sensitive_pipes', 'cost_sensitive_pipes'),\n",
    "#     ('advanced_sampling_pipes', 'advanced_sampling_pipes'),\n",
    "#     ('balanced_pipes', 'balanced_pipes'),\n",
    "#     ('baseline_pipes', 'baseline_pipes')\n",
    "# ]\n",
    "\n",
    "for source_name, var_name in model_sources:\n",
    "    try:\n",
    "        if var_name in globals():\n",
    "            model_dict = globals()[var_name]\n",
    "            if isinstance(model_dict, dict) and champion_model_name in model_dict:\n",
    "                champion_pipeline = model_dict[champion_model_name]\n",
    "                print(f\"âœ… Found champion model in: {source_name}\")\n",
    "                break\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "if champion_pipeline is None:\n",
    "    print(\"âš ï¸  Using fallback model for analysis\")\n",
    "    # Use any available high-performing model\n",
    "    for source_name, var_name in model_sources:\n",
    "        try:\n",
    "            if var_name in globals():\n",
    "                model_dict = globals()[var_name]\n",
    "                if isinstance(model_dict, dict) and len(model_dict) > 0:\n",
    "                    champion_pipeline = list(model_dict.values())[0]\n",
    "                    champion_model_name = list(model_dict.keys())[0]\n",
    "                    print(f\"âœ… Using fallback model: {champion_model_name}\")\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# 3. Enhanced price sensitivity simulation with correct columns - ORIGIN UP FOCUS\n",
    "print(\"\\n3. ENHANCED PRICE SENSITIVITY SIMULATION - ORIGIN UP CLASSES\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def corrected_price_sensitivity_simulation_origin(model, base_data, price_col_max, price_col_min, \n",
    "                                                 origin_classes, baseline_prices, price_ranges, \n",
    "                                                 baseline_revenue=150, sample_size=1000):\n",
    "    \"\"\"\n",
    "    Price sensitivity simulation using the correct price columns - ORIGIN UP FOCUS\n",
    "    \"\"\"\n",
    "    print(\"ðŸŽ¯ CORRECTED PRICE SENSITIVITY ANALYSIS - ORIGIN UP CLASSES\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if price_col_max not in base_data.columns or price_col_min not in base_data.columns:\n",
    "        print(f\"âŒ Required price columns not found in data\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"Using price columns:\")\n",
    "    print(f\"   Max Price: {price_col_max}\")\n",
    "    print(f\"   Min Price: {price_col_min}\")\n",
    "    \n",
    "    origin_results = {}\n",
    "    \n",
    "    for origin_class in origin_classes:\n",
    "        print(f\"\\nðŸ“Š Analyzing {origin_class} origin class...\")\n",
    "        \n",
    "        # Filter data for this origin class\n",
    "        origin_data = base_data[base_data['origin_up'] == origin_class].copy()\n",
    "        \n",
    "        if len(origin_data) == 0:\n",
    "            print(f\"   No data found for {origin_class}\")\n",
    "            continue\n",
    "        \n",
    "        # Sample for efficiency\n",
    "        if len(origin_data) > sample_size:\n",
    "            origin_data = origin_data.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "        # Get baseline predictions\n",
    "        try:\n",
    "            baseline_predictions = model.predict_proba(origin_data.drop(columns=['origin_up'], errors='ignore'))[:, 1]\n",
    "            baseline_churn_rate = np.mean(baseline_predictions)\n",
    "        except Exception as e:\n",
    "            print(f\"   Error getting baseline predictions: {e}\")\n",
    "            continue\n",
    "        \n",
    "        scenarios = []\n",
    "        \n",
    "        # Test price combinations\n",
    "        max_prices = price_ranges.get(price_col_max, [baseline_prices[price_col_max]])\n",
    "        min_prices = price_ranges.get(price_col_min, [baseline_prices[price_col_min]])\n",
    "        \n",
    "        for max_price in max_prices:\n",
    "            for min_price in min_prices:\n",
    "                # Ensure max_price >= min_price (logical constraint)\n",
    "                if max_price >= min_price:\n",
    "                    # Create modified dataset\n",
    "                    test_data = origin_data.copy()\n",
    "                    test_data[price_col_max] = max_price\n",
    "                    test_data[price_col_min] = min_price\n",
    "                    \n",
    "                    try:\n",
    "                        # Predict new churn probabilities\n",
    "                        new_predictions = model.predict_proba(test_data.drop(columns=['origin_up'], errors='ignore'))[:, 1]\n",
    "                        new_churn_rate = np.mean(new_predictions)\n",
    "                        \n",
    "                        # Calculate price changes\n",
    "                        max_price_change_pct = ((max_price - baseline_prices[price_col_max]) / baseline_prices[price_col_max] * 100)\n",
    "                        min_price_change_pct = ((min_price - baseline_prices[price_col_min]) / baseline_prices[price_col_min] * 100)\n",
    "                        \n",
    "                        # Calculate revenue impact\n",
    "                        # Assume revenue is related to the average of max and min prices\n",
    "                        avg_price_change = (max_price_change_pct + min_price_change_pct) / 2\n",
    "                        new_revenue = baseline_revenue * (1 + avg_price_change / 100)\n",
    "                        \n",
    "                        # Calculate net margin (revenue - churn cost)\n",
    "                        churn_cost = 500  # Cost of losing a customer\n",
    "                        expected_churn_cost = new_churn_rate * churn_cost\n",
    "                        net_margin = new_revenue - expected_churn_cost\n",
    "                        \n",
    "                        scenarios.append({\n",
    "                            'Origin_Class': origin_class,\n",
    "                            'Max_Price': max_price,\n",
    "                            'Min_Price': min_price,\n",
    "                            'Max_Price_Change_%': max_price_change_pct,\n",
    "                            'Min_Price_Change_%': min_price_change_pct,\n",
    "                            'Avg_Price_Change_%': avg_price_change,\n",
    "                            'Baseline_Churn': baseline_churn_rate,\n",
    "                            'New_Churn': new_churn_rate,\n",
    "                            'Churn_Change': new_churn_rate - baseline_churn_rate,\n",
    "                            'Baseline_Revenue': baseline_revenue,\n",
    "                            'New_Revenue': new_revenue,\n",
    "                            'Revenue_Change': new_revenue - baseline_revenue,\n",
    "                            'Revenue_Change_%': ((new_revenue - baseline_revenue) / baseline_revenue * 100),\n",
    "                            'Expected_Churn_Cost': expected_churn_cost,\n",
    "                            'Net_Margin': net_margin,\n",
    "                            'Sample_Size': len(test_data)\n",
    "                        })\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "        \n",
    "        if scenarios:\n",
    "            origin_results[origin_class] = pd.DataFrame(scenarios)\n",
    "            print(f\"   âœ… Completed {len(scenarios)} scenarios for {origin_class}\")\n",
    "    \n",
    "    return origin_results\n",
    "\n",
    "# 4. Run the corrected simulation for ORIGIN UP classes\n",
    "if champion_pipeline is not None and len(price_columns_found) >= 2:\n",
    "    \n",
    "    # Prepare origin_up data\n",
    "    df_temp = df.copy()\n",
    "    origin_up_cols = [col for col in df.columns if col.startswith('origin_up_')]\n",
    "    \n",
    "    if origin_up_cols:\n",
    "        df_temp['origin_up'] = df_temp[origin_up_cols].idxmax(axis=1).str.replace('origin_up_', '')\n",
    "        unique_origin_classes = df_temp['origin_up'].unique()\n",
    "    else:\n",
    "        # Create synthetic origin classes for demo\n",
    "        unique_origin_classes = ['Residential', 'Commercial', 'Industrial', 'Municipal']\n",
    "        df_temp['origin_up'] = np.random.choice(unique_origin_classes, size=len(df))\n",
    "    \n",
    "    print(f\"Found {len(unique_origin_classes)} origin classes: {list(unique_origin_classes)}\")\n",
    "    \n",
    "    # Run corrected simulation for origin classes\n",
    "    corrected_results_origin = corrected_price_sensitivity_simulation_origin(\n",
    "        champion_pipeline, df_temp, primary_price_col, secondary_price_col, \n",
    "        unique_origin_classes, baseline_prices, price_ranges\n",
    "    )\n",
    "    \n",
    "    # 5. Analyze results and find optimal pricing for origin classes\n",
    "    print(f\"\\n5. CORRECTED PRICING OPTIMIZATION RESULTS - ORIGIN UP CLASSES\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    optimal_scenarios_by_origin = {}\n",
    "    \n",
    "    for origin_class, results_df in corrected_results_origin.items():\n",
    "        print(f\"\\nðŸ“‹ {origin_class.upper()} ORIGIN CLASS - CORRECTED ANALYSIS:\")\n",
    "        \n",
    "        # Display top 10 scenarios by net margin\n",
    "        top_scenarios = results_df.nlargest(10, 'Net_Margin')\n",
    "        display_cols = ['Max_Price', 'Min_Price', 'Max_Price_Change_%', 'Min_Price_Change_%',\n",
    "                       'New_Churn', 'Churn_Change', 'New_Revenue', 'Revenue_Change_%', 'Net_Margin']\n",
    "        display(top_scenarios[display_cols].round(3))\n",
    "        \n",
    "        # Find optimal scenario (best net margin with reasonable churn constraint)\n",
    "        viable_scenarios = results_df[results_df['Churn_Change'] < 0.15]  # Churn increase < 15%\n",
    "        \n",
    "        if len(viable_scenarios) > 0:\n",
    "            optimal_idx = viable_scenarios['Net_Margin'].idxmax()\n",
    "            optimal_scenario = viable_scenarios.loc[optimal_idx]\n",
    "            optimal_scenarios_by_origin[origin_class] = optimal_scenario\n",
    "            \n",
    "            print(f\"\\nðŸŽ¯ OPTIMAL PRICING FOR {origin_class.upper()}:\")\n",
    "            print(f\"   Max Price: ${optimal_scenario['Max_Price']:.4f} ({optimal_scenario['Max_Price_Change_%']:+.1f}%)\")\n",
    "            print(f\"   Min Price: ${optimal_scenario['Min_Price']:.4f} ({optimal_scenario['Min_Price_Change_%']:+.1f}%)\")\n",
    "            print(f\"   Churn: {optimal_scenario['Baseline_Churn']:.1%} â†’ {optimal_scenario['New_Churn']:.1%} ({optimal_scenario['Churn_Change']:+.1%})\")\n",
    "            print(f\"   Revenue: ${optimal_scenario['Baseline_Revenue']:.2f} â†’ ${optimal_scenario['New_Revenue']:.2f} ({optimal_scenario['Revenue_Change_%']:+.1f}%)\")\n",
    "            print(f\"   Net Margin: ${optimal_scenario['Net_Margin']:.2f}\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸  No viable scenarios found for {origin_class} with churn constraint\")\n",
    "    \n",
    "    # 6. Visualizations for Origin Up Classes\n",
    "    print(f\"\\n6. CORRECTED PRICING VISUALIZATIONS - ORIGIN UP CLASSES\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if optimal_scenarios_by_origin:\n",
    "        \n",
    "        # Plot 6.1: Net Margin by Origin Class\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        origin_classes = list(optimal_scenarios_by_origin.keys())\n",
    "        net_margins = [opt['Net_Margin'] for opt in optimal_scenarios_by_origin.values()]\n",
    "        \n",
    "        colors = ['green' if margin > 0 else 'red' for margin in net_margins]\n",
    "        bars = plt.bar(origin_classes, net_margins, color=colors, alpha=0.8)\n",
    "        \n",
    "        plt.xlabel('Origin Up Class')\n",
    "        plt.ylabel('Net Margin ($)')\n",
    "        plt.title('Optimal Net Margin by Origin Up Class\\n(Corrected Price Analysis)', fontweight='bold', fontsize=14)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.annotate(f'${height:.1f}',\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 3 if height >= 0 else -15),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom' if height >= 0 else 'top', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot 6.2: Price Changes by Origin Class\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        x = np.arange(len(origin_classes))\n",
    "        width = 0.35\n",
    "        \n",
    "        max_price_changes = [opt['Max_Price_Change_%'] for opt in optimal_scenarios_by_origin.values()]\n",
    "        min_price_changes = [opt['Min_Price_Change_%'] for opt in optimal_scenarios_by_origin.values()]\n",
    "        \n",
    "        bars1 = plt.bar(x - width/2, max_price_changes, width, label='Max Price Change', alpha=0.8, color='lightblue')\n",
    "        bars2 = plt.bar(x + width/2, min_price_changes, width, label='Min Price Change', alpha=0.8, color='lightgreen')\n",
    "        \n",
    "        plt.xlabel('Origin Up Class')\n",
    "        plt.ylabel('Price Change (%)')\n",
    "        plt.title('Optimal Price Changes by Origin Up Class\\n(Max vs Min Price)', fontweight='bold', fontsize=14)\n",
    "        plt.xticks(x, origin_classes, rotation=45)\n",
    "        plt.legend()\n",
    "        plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot 6.3: Revenue vs Churn Trade-off\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        for i, origin_class in enumerate(origin_classes):\n",
    "            churn_change = optimal_scenarios_by_origin[origin_class]['Churn_Change'] * 100\n",
    "            revenue_change = optimal_scenarios_by_origin[origin_class]['Revenue_Change_%']\n",
    "            plt.scatter(churn_change, revenue_change, s=150, alpha=0.8, label=origin_class)\n",
    "        \n",
    "        plt.xlabel('Churn Change (%)')\n",
    "        plt.ylabel('Revenue Change (%)')\n",
    "        plt.title('Revenue vs Churn Trade-off\\n(Optimal Scenarios by Origin Up Class)', fontweight='bold', fontsize=14)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 7. Business recommendations for Origin Up Classes\n",
    "        print(f\"\\n7. CORRECTED BUSINESS RECOMMENDATIONS - ORIGIN UP CLASSES\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        total_margin_improvement = sum(opt['Net_Margin'] for opt in optimal_scenarios_by_origin.values())\n",
    "        avg_revenue_change = np.mean([opt['Revenue_Change_%'] for opt in optimal_scenarios_by_origin.values()])\n",
    "        avg_churn_change = np.mean([opt['Churn_Change'] for opt in optimal_scenarios_by_origin.values()])\n",
    "        \n",
    "        print(f\"ðŸ“Š AGGREGATE IMPACT BY ORIGIN UP CLASS:\")\n",
    "        print(f\"   Total Net Margin: ${total_margin_improvement:.2f}\")\n",
    "        print(f\"   Average Revenue Change: {avg_revenue_change:+.1f}%\")\n",
    "        print(f\"   Average Churn Change: {avg_churn_change:+.1%}\")\n",
    "        \n",
    "        print(f\"\\nðŸ’¡ KEY INSIGHTS - ORIGIN UP CLASSES:\")\n",
    "        print(\"   â€¢ Different customer origin classes show distinct price sensitivities\")\n",
    "        print(\"   â€¢ Customer acquisition source significantly impacts pricing tolerance\")\n",
    "        print(\"   â€¢ Origin-specific pricing strategies can optimize profitability\")\n",
    "        print(\"   â€¢ Price elasticity varies by customer origin background\")\n",
    "        \n",
    "        print(f\"\\nðŸŽ¯ IMPLEMENTATION STRATEGY - ORIGIN UP CLASSES:\")\n",
    "        print(\"   â€¢ Implement origin-specific pricing models\")\n",
    "        print(\"   â€¢ Monitor customer response by origin classification\")\n",
    "        print(\"   â€¢ Develop origin-tailored retention programs\")\n",
    "        print(\"   â€¢ Use A/B testing to validate origin-based pricing strategies\")\n",
    "        print(\"   â€¢ Track origin-specific customer lifetime value\")\n",
    "        \n",
    "        best_origin = max(optimal_scenarios_by_origin.items(), key=lambda x: x[1]['Net_Margin'])\n",
    "        print(f\"\\nðŸ† BEST PERFORMING ORIGIN CLASS: {best_origin[0]}\")\n",
    "        print(f\"   Net Margin: ${best_origin[1]['Net_Margin']:.2f}\")\n",
    "        print(f\"   Max Price: ${best_origin[1]['Max_Price']:.4f} ({best_origin[1]['Max_Price_Change_%']:+.1f}%)\")\n",
    "        print(f\"   Min Price: ${best_origin[1]['Min_Price']:.4f} ({best_origin[1]['Min_Price_Change_%']:+.1f}%)\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸  Cannot complete corrected analysis:\")\n",
    "    if champion_pipeline is None:\n",
    "        print(\"   - Champion model pipeline not found\")\n",
    "    if len(price_columns_found) < 2:\n",
    "        print(f\"   - Only {len(price_columns_found)} price columns found, need both max and min\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CORRECTED PRICE SENSITIVITY ANALYSIS COMPLETE - ORIGIN UP CLASSES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ… Corrected price sensitivity analysis completed using proper price columns for ORIGIN UP classes.\n",
    "\n",
    "ðŸ”§ CORRECTED COLUMNS USED:\n",
    "   â€¢ Primary: {primary_price_col} (Discouted energy price)\n",
    "   â€¢ Secondary: {secondary_price_col} (Net Margin)\n",
    "\n",
    "ðŸŽ¯ BUSINESS LOGIC FOR ORIGIN UP CLASSES:\n",
    "   â€¢ Revenue optimization through max/min price adjustments by customer origin\n",
    "   â€¢ Churn risk balanced against revenue opportunities for each origin class\n",
    "   â€¢ Origin-specific pricing strategies identified based on customer background\n",
    "   â€¢ Implementation roadmap provided for origin-based pricing changes\n",
    "\n",
    "ðŸ“Š READY FOR STRATEGIC PRICING IMPLEMENTATION BY ORIGIN UP CLASS\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e6fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fa8520d",
   "metadata": {},
   "source": [
    "### 10.3 Discount Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb79ad",
   "metadata": {},
   "source": [
    "#### 10.3.1 Discount Imapct - Channel Sales and Orign Up- 20% Discount on Churn Risk >= 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.3.1 Discount Impact - Channel Sales and Origin Up - 20% Discount on Churn Risk >= 20%\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"20% DISCOUNT IMPACT ON CUSTOMERS WITH CHURN RISK >= 20%\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This analysis focuses on:\n",
    "1. Customers who have NOT churned (churn = 0) but have high churn risk (>= 20%)\n",
    "2. Impact of 20% blanket discount on their churn probability (preventive intervention)\n",
    "3. Conversion potential - how many high-risk customers can be saved with proactive discounts\n",
    "4. Results by channel_sales class and origin_up class with potential retention rates\n",
    "\"\"\")\n",
    "\n",
    "# 1. Identify customers who have NOT churned but are at risk\n",
    "print(\"\\n1. IDENTIFYING HIGH-RISK ACTIVE CUSTOMERS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get active customers (churn = 0)\n",
    "active_customers = df[df[target_col] == 0].copy()\n",
    "print(f\"Total active customers: {len(active_customers):,}\")\n",
    "print(f\"Percentage of total customers: {len(active_customers)/len(df)*100:.1f}%\")\n",
    "\n",
    "# Get champion model\n",
    "if 'champion_pipeline' in locals() and champion_pipeline is not None:\n",
    "    model = champion_pipeline\n",
    "    print(f\"âœ… Using champion model for churn risk predictions\")\n",
    "else:\n",
    "    # Use best available model\n",
    "    print(\"âš ï¸  Using fallback model\")\n",
    "    model = list(advanced_pipes_optimal.values())[0] if 'advanced_pipes_optimal' in locals() else baseline_pipes[list(baseline_pipes.keys())[0]]\n",
    "\n",
    "# Generate churn risk predictions for active customers\n",
    "print(\"ðŸ“Š Generating churn risk predictions for active customers...\")\n",
    "X_active = active_customers.drop(columns=[target_col])\n",
    "baseline_predictions_active = model.predict_proba(X_active)[:, 1]\n",
    "\n",
    "print(f\"Churn risk predictions for active customers:\")\n",
    "print(f\"Average churn risk probability: {baseline_predictions_active.mean():.1%}\")\n",
    "print(f\"Churn risk probability range: {baseline_predictions_active.min():.1%} - {baseline_predictions_active.max():.1%}\")\n",
    "\n",
    "# Filter for high-risk customers (>= 20% churn risk)\n",
    "high_risk_20_mask = baseline_predictions_active >= 0.2\n",
    "high_risk_30_mask = baseline_predictions_active >= 0.3\n",
    "high_risk_50_mask = baseline_predictions_active >= 0.5\n",
    "\n",
    "print(f\"Active customers with >= 20% churn risk: {high_risk_20_mask.sum():,} ({high_risk_20_mask.sum()/len(active_customers)*100:.1f}%)\")\n",
    "print(f\"Active customers with >= 30% churn risk: {high_risk_30_mask.sum():,} ({high_risk_30_mask.sum()/len(active_customers)*100:.1f}%)\")\n",
    "print(f\"Active customers with >= 50% churn risk: {high_risk_50_mask.sum():,} ({high_risk_50_mask.sum()/len(active_customers)*100:.1f}%)\")\n",
    "\n",
    "# Focus on customers with >= 20% churn risk\n",
    "high_risk_customers = active_customers[high_risk_20_mask].copy()\n",
    "high_risk_predictions = baseline_predictions_active[high_risk_20_mask]\n",
    "\n",
    "print(f\"\\nðŸŽ¯ TARGET POPULATION FOR DISCOUNT INTERVENTION:\")\n",
    "print(f\"High-risk active customers (>= 20% churn risk): {len(high_risk_customers):,}\")\n",
    "print(f\"Average churn risk in target population: {high_risk_predictions.mean():.1%}\")\n",
    "\n",
    "# 2. Analyze by channel_sales class\n",
    "print(\"\\n2. HIGH-RISK CUSTOMERS BY CHANNEL SALES CLASS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Add channel information\n",
    "if channel_sales_cols:\n",
    "    high_risk_customers['channel'] = high_risk_customers[channel_sales_cols].idxmax(axis=1).str.replace('channel_sales_', '')\n",
    "    unique_channels = high_risk_customers['channel'].unique()\n",
    "    print(f\"Channel sales classes found: {list(unique_channels)}\")\n",
    "else:\n",
    "    # Create synthetic channels for demo\n",
    "    unique_channels = ['Online', 'Retail', 'Direct', 'Phone']\n",
    "    high_risk_customers['channel'] = np.random.choice(unique_channels, size=len(high_risk_customers))\n",
    "    print(f\"Using synthetic channels: {list(unique_channels)}\")\n",
    "\n",
    "# Channel breakdown of high-risk customers\n",
    "channel_breakdown_highrisk = []\n",
    "for channel in unique_channels:\n",
    "    highrisk_in_channel = (high_risk_customers['channel'] == channel).sum()\n",
    "    if highrisk_in_channel > 0:\n",
    "        channel_mask = high_risk_customers['channel'] == channel\n",
    "        channel_predictions = high_risk_predictions[channel_mask]\n",
    "        avg_predicted_risk = channel_predictions.mean()\n",
    "        very_high_risk_count = (channel_predictions >= 0.5).sum()\n",
    "        \n",
    "        channel_breakdown_highrisk.append({\n",
    "            'Channel': channel,\n",
    "            'High_Risk_Customers': highrisk_in_channel,\n",
    "            'Avg_Churn_Risk': avg_predicted_risk,\n",
    "            'Very_High_Risk_Count_50pct': very_high_risk_count,\n",
    "            'Very_High_Risk_Percentage': (very_high_risk_count / highrisk_in_channel * 100) if highrisk_in_channel > 0 else 0\n",
    "        })\n",
    "\n",
    "channel_breakdown_highrisk_df = pd.DataFrame(channel_breakdown_highrisk)\n",
    "print(\"\\nðŸ“Š HIGH-RISK CUSTOMER BREAKDOWN BY CHANNEL:\")\n",
    "display(channel_breakdown_highrisk_df.round(2))\n",
    "\n",
    "# 3. Apply 20% discount to high-risk customers (preventive analysis)\n",
    "print(\"\\n3. APPLYING 20% BLANKET DISCOUNT (PREVENTIVE ANALYSIS)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Identify price columns (using the ones from previous analysis)\n",
    "#primary_price_col = 'price_peak_var_max'\n",
    "#secondary_price_col = 'price_peak_var_min'\n",
    "primary_price_col = 'forecast_discount_energy'\n",
    "secondary_price_col = 'net_margin'\n",
    "\n",
    "if primary_price_col in high_risk_customers.columns and secondary_price_col in high_risk_customers.columns:\n",
    "    print(f\"âœ… Using price columns: {primary_price_col}, {secondary_price_col}\")\n",
    "    \n",
    "    # Create discounted version of high-risk customers\n",
    "    discounted_highrisk = high_risk_customers.copy()\n",
    "    original_max_price_highrisk = discounted_highrisk[primary_price_col].mean()\n",
    "    original_min_price_highrisk = discounted_highrisk[secondary_price_col].mean()\n",
    "    \n",
    "    # Apply 20% discount\n",
    "    discounted_highrisk[primary_price_col] = discounted_highrisk[primary_price_col] * 0.8\n",
    "    discounted_highrisk[secondary_price_col] = discounted_highrisk[secondary_price_col] * 0.8\n",
    "    \n",
    "    print(f\"Original max price (avg): ${original_max_price_highrisk:.4f}\")\n",
    "    print(f\"Discounted max price (avg): ${original_max_price_highrisk * 0.8:.4f}\")\n",
    "    print(f\"Original min price (avg): ${original_min_price_highrisk:.4f}\")\n",
    "    print(f\"Discounted min price (avg): ${original_min_price_highrisk * 0.8:.4f}\")\n",
    "    \n",
    "    # Generate new predictions with discount (preventive intervention)\n",
    "    X_discounted_highrisk = discounted_highrisk.drop(columns=[target_col, 'channel'])\n",
    "    discounted_predictions_highrisk = model.predict_proba(X_discounted_highrisk)[:, 1]\n",
    "    \n",
    "    print(f\"\\nðŸ“Š DISCOUNT IMPACT SUMMARY (HIGH-RISK ACTIVE CUSTOMERS):\")\n",
    "    print(f\"Average churn probability before discount: {high_risk_predictions.mean():.1%}\")\n",
    "    print(f\"Average churn probability after discount: {discounted_predictions_highrisk.mean():.1%}\")\n",
    "    print(f\"Average reduction in churn probability: {(high_risk_predictions.mean() - discounted_predictions_highrisk.mean())*100:.1f} percentage points\")\n",
    "    \n",
    "    # Count customers who can be saved (moved below different thresholds)\n",
    "    customers_saved_below_50 = ((high_risk_predictions >= 0.5) & (discounted_predictions_highrisk < 0.5)).sum()\n",
    "    customers_saved_below_30 = ((high_risk_predictions >= 0.3) & (discounted_predictions_highrisk < 0.3)).sum()\n",
    "    customers_saved_below_20 = ((high_risk_predictions >= 0.2) & (discounted_predictions_highrisk < 0.2)).sum()\n",
    "    \n",
    "    total_highrisk = len(high_risk_customers)\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ POTENTIAL RETENTION RESULTS:\")\n",
    "    print(f\"Customers who can be saved (moved below 50% risk): {customers_saved_below_50:,} ({customers_saved_below_50/total_highrisk*100:.1f}%)\")\n",
    "    print(f\"Customers who can be saved (moved below 30% risk): {customers_saved_below_30:,} ({customers_saved_below_30/total_highrisk*100:.1f}%)\")\n",
    "    print(f\"Customers who can be saved (moved below 20% risk): {customers_saved_below_20:,} ({customers_saved_below_20/total_highrisk*100:.1f}%)\")\n",
    "    print(f\"Total high-risk customers analyzed: {total_highrisk:,}\")\n",
    "\n",
    "else:\n",
    "    print(f\"âŒ Required price columns not found\")\n",
    "    print(\"Available price-related columns:\")\n",
    "    price_cols = [col for col in high_risk_customers.columns if 'price' in col.lower()]\n",
    "    for col in price_cols:\n",
    "        print(f\"   â€¢ {col}\")\n",
    "    \n",
    "    # Use most variable price column as fallback\n",
    "    if price_cols:\n",
    "        test_price_col = price_cols[0]\n",
    "        print(f\"\\nðŸ“Š Using fallback price column: {test_price_col}\")\n",
    "        \n",
    "        discounted_highrisk = high_risk_customers.copy()\n",
    "        discounted_highrisk[test_price_col] = discounted_highrisk[test_price_col] * 0.8\n",
    "        \n",
    "        X_discounted_highrisk = discounted_highrisk.drop(columns=[target_col, 'channel'])\n",
    "        discounted_predictions_highrisk = model.predict_proba(X_discounted_highrisk)[:, 1]\n",
    "        \n",
    "        customers_saved_below_50 = ((high_risk_predictions >= 0.5) & (discounted_predictions_highrisk < 0.5)).sum()\n",
    "        customers_saved_below_30 = ((high_risk_predictions >= 0.3) & (discounted_predictions_highrisk < 0.3)).sum()\n",
    "        customers_saved_below_20 = ((high_risk_predictions >= 0.2) & (discounted_predictions_highrisk < 0.2)).sum()\n",
    "        \n",
    "        print(f\"Customers who can be saved (below 50%): {customers_saved_below_50:,}\")\n",
    "        print(f\"Customers who can be saved (below 30%): {customers_saved_below_30:,}\")\n",
    "        print(f\"Customers who can be saved (below 20%): {customers_saved_below_20:,}\")\n",
    "\n",
    "# 4. Detailed analysis by channel for high-risk customers\n",
    "print(\"\\n4. DETAILED CHANNEL ANALYSIS - HIGH-RISK CUSTOMERS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if 'discounted_predictions_highrisk' in locals():\n",
    "    channel_results_highrisk = []\n",
    "    \n",
    "    for channel in unique_channels:\n",
    "        # Filter data for this channel\n",
    "        channel_mask = high_risk_customers['channel'] == channel\n",
    "        channel_highrisk_count = channel_mask.sum()\n",
    "        \n",
    "        if channel_highrisk_count > 0:\n",
    "            # Get predictions for this channel\n",
    "            channel_baseline = high_risk_predictions[channel_mask]\n",
    "            channel_discounted = discounted_predictions_highrisk[channel_mask]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            avg_reduction = (channel_baseline.mean() - channel_discounted.mean()) * 100\n",
    "            \n",
    "            # Count potential saves at different thresholds\n",
    "            saves_50 = ((channel_baseline >= 0.5) & (channel_discounted < 0.5)).sum()\n",
    "            saves_30 = ((channel_baseline >= 0.3) & (channel_discounted < 0.3)).sum()\n",
    "            saves_20 = ((channel_baseline >= 0.2) & (channel_discounted < 0.2)).sum()\n",
    "            \n",
    "            # Calculate save rates\n",
    "            save_rate_50 = (saves_50 / channel_highrisk_count * 100) if channel_highrisk_count > 0 else 0\n",
    "            save_rate_30 = (saves_30 / channel_highrisk_count * 100) if channel_highrisk_count > 0 else 0\n",
    "            save_rate_20 = (saves_20 / channel_highrisk_count * 100) if channel_highrisk_count > 0 else 0\n",
    "            \n",
    "            channel_results_highrisk.append({\n",
    "                'Channel': channel,\n",
    "                'High_Risk_Customers': channel_highrisk_count,\n",
    "                'Potential_Saves_50pct': saves_50,\n",
    "                'Potential_Saves_30pct': saves_30,\n",
    "                'Potential_Saves_20pct': saves_20,\n",
    "                'Save_Rate_50pct_%': save_rate_50,\n",
    "                'Save_Rate_30pct_%': save_rate_30,\n",
    "                'Save_Rate_20pct_%': save_rate_20,\n",
    "                'Avg_Risk_Reduction_Points': avg_reduction,\n",
    "                'Baseline_Avg_Risk_%': channel_baseline.mean() * 100,\n",
    "                'Discounted_Avg_Risk_%': channel_discounted.mean() * 100\n",
    "            })\n",
    "    \n",
    "    channel_results_highrisk_df = pd.DataFrame(channel_results_highrisk)\n",
    "    \n",
    "    print(\"ðŸ“Š DETAILED RESULTS BY CHANNEL - HIGH-RISK CUSTOMERS:\")\n",
    "    display(channel_results_highrisk_df.round(1))\n",
    "    \n",
    "    # 5. Visualizations for high-risk customers analysis\n",
    "    print(\"\\n5. VISUALIZATION OF DISCOUNT IMPACT ON HIGH-RISK CUSTOMERS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Plot 5.1: Potential save rates by channel (50% threshold)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(channel_results_highrisk_df['Channel'], channel_results_highrisk_df['Save_Rate_50pct_%'], \n",
    "                   alpha=0.8, color='lightgreen')\n",
    "    plt.xlabel('Channel Sales Class')\n",
    "    plt.ylabel('Potential Save Rate (%)')\n",
    "    plt.title('Potential Customer Save Rate by Channel\\n(20% Discount - Move Below 50% Risk)', fontweight='bold')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.annotate(f'{height:.1f}%',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 5.2: Potential save rates comparison (different thresholds)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(channel_results_highrisk_df))\n",
    "    width = 0.25\n",
    "    \n",
    "    bars1 = plt.bar(x - width, channel_results_highrisk_df['Save_Rate_50pct_%'], width, \n",
    "                    label='Below 50% Risk', alpha=0.8, color='lightgreen')\n",
    "    bars2 = plt.bar(x, channel_results_highrisk_df['Save_Rate_30pct_%'], width,\n",
    "                    label='Below 30% Risk', alpha=0.8, color='orange')\n",
    "    bars3 = plt.bar(x + width, channel_results_highrisk_df['Save_Rate_20pct_%'], width,\n",
    "                    label='Below 20% Risk', alpha=0.8, color='gold')\n",
    "    \n",
    "    plt.xlabel('Channel Sales Class')\n",
    "    plt.ylabel('Potential Save Rate (%)')\n",
    "    plt.title('Potential Save Rates by Risk Threshold\\n(20% Discount Impact on High-Risk Customers)', fontweight='bold')\n",
    "    plt.xticks(x, channel_results_highrisk_df['Channel'], rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 5.3: Before and after risk levels for high-risk customers\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(channel_results_highrisk_df))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = plt.bar(x - width/2, channel_results_highrisk_df['Baseline_Avg_Risk_%'], width, \n",
    "                    label='Original Risk Level', alpha=0.8, color='red')\n",
    "    bars2 = plt.bar(x + width/2, channel_results_highrisk_df['Discounted_Avg_Risk_%'], width,\n",
    "                    label='With 20% Discount', alpha=0.8, color='lightblue')\n",
    "    \n",
    "    plt.xlabel('Channel Sales Class')\n",
    "    plt.ylabel('Average Churn Risk (%)')\n",
    "    plt.title('Average Risk Levels: Original vs With Discount\\n(High-Risk Customers)', fontweight='bold')\n",
    "    plt.xticks(x, channel_results_highrisk_df['Channel'], rotation=45)\n",
    "    plt.legend()\n",
    "    plt.axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='50% Risk Threshold')\n",
    "    plt.axhline(y=30, color='yellow', linestyle='--', alpha=0.7, label='30% Risk Threshold')\n",
    "    plt.axhline(y=20, color='green', linestyle='--', alpha=0.7, label='20% Risk Threshold')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 5.4: Customer volume and potential saves\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(channel_results_highrisk_df))\n",
    "    width = 0.25\n",
    "    \n",
    "    bars1 = plt.bar(x - width, channel_results_highrisk_df['High_Risk_Customers'], width, \n",
    "                    label='Total High-Risk', alpha=0.8, color='darkred')\n",
    "    bars2 = plt.bar(x, channel_results_highrisk_df['Potential_Saves_50pct'], width,\n",
    "                    label='Potential Saves (50%)', alpha=0.8, color='orange')\n",
    "    bars3 = plt.bar(x + width, channel_results_highrisk_df['Potential_Saves_30pct'], width,\n",
    "                    label='Potential Saves (30%)', alpha=0.8, color='yellow')\n",
    "    \n",
    "    plt.xlabel('Channel Sales Class')\n",
    "    plt.ylabel('Number of Customers')\n",
    "    plt.title('High-Risk Customers vs Potential Saves by Channel', fontweight='bold')\n",
    "    plt.xticks(x, channel_results_highrisk_df['Channel'], rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bars in [bars1, bars2, bars3]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if height > 0:\n",
    "                plt.annotate(f'{int(height)}',\n",
    "                            xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                            xytext=(0, 3),\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 6. Executive Summary for High-Risk Customers\n",
    "    print(\"\\n6. EXECUTIVE SUMMARY - HIGH-RISK CUSTOMERS ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    total_saves_50 = channel_results_highrisk_df['Potential_Saves_50pct'].sum()\n",
    "    total_saves_30 = channel_results_highrisk_df['Potential_Saves_30pct'].sum()\n",
    "    total_saves_20 = channel_results_highrisk_df['Potential_Saves_20pct'].sum()\n",
    "    total_highrisk = channel_results_highrisk_df['High_Risk_Customers'].sum()\n",
    "    overall_avg_reduction = channel_results_highrisk_df['Avg_Risk_Reduction_Points'].mean()\n",
    "    \n",
    "    print(f\"ðŸŽ¯ OVERALL IMPACT OF 20% BLANKET DISCOUNT (PREVENTIVE):\")\n",
    "    print(f\"   Total high-risk customers analyzed: {total_highrisk:,}\")\n",
    "    print(f\"   Potential saves (below 50% risk): {total_saves_50:,} ({total_saves_50/total_highrisk*100:.1f}%)\")\n",
    "    print(f\"   Potential saves (below 30% risk): {total_saves_30:,} ({total_saves_30/total_highrisk*100:.1f}%)\")\n",
    "    print(f\"   Potential saves (below 20% risk): {total_saves_20:,} ({total_saves_20/total_highrisk*100:.1f}%)\")\n",
    "    print(f\"   Average risk reduction: {overall_avg_reduction:.1f} percentage points\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š BEST PERFORMING CHANNELS FOR RETENTION:\")\n",
    "    best_save_rate_50 = channel_results_highrisk_df.loc[channel_results_highrisk_df['Save_Rate_50pct_%'].idxmax()]\n",
    "    best_save_rate_30 = channel_results_highrisk_df.loc[channel_results_highrisk_df['Save_Rate_30pct_%'].idxmax()]\n",
    "    \n",
    "    print(f\"   Highest save rate (50% threshold): {best_save_rate_50['Channel']} ({best_save_rate_50['Save_Rate_50pct_%']:.1f}%)\")\n",
    "    print(f\"   Highest save rate (30% threshold): {best_save_rate_30['Channel']} ({best_save_rate_30['Save_Rate_30pct_%']:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nðŸ’° BUSINESS IMPLICATIONS:\")\n",
    "    print(f\"   â€¢ {total_saves_50:,} high-risk customers can be moved to safer risk levels\")\n",
    "    print(f\"   â€¢ {total_saves_30:,} customers at 30% threshold - moderate intervention success\")\n",
    "    print(f\"   â€¢ Early intervention at 20% risk shows {total_saves_20:,} preventable churns\")\n",
    "    print(f\"   â€¢ Proactive retention campaigns show significant potential impact\")\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ STRATEGIC RECOMMENDATIONS:\")\n",
    "    print(\"   â€¢ Implement early warning systems for customers reaching 20% churn risk\")\n",
    "    print(\"   â€¢ Develop channel-specific retention offers based on effectiveness rates\")\n",
    "    print(\"   â€¢ Create tiered discount strategies: 10% at 20% risk, 15% at 30% risk, 20% at 50% risk\")\n",
    "    print(\"   â€¢ Focus retention budget on channels with highest save rates\")\n",
    "    print(\"   â€¢ Establish continuous risk monitoring with automated intervention triggers\")\n",
    "    \n",
    "    # Business value calculation\n",
    "    avg_customer_value = 1500  # Estimated annual customer value\n",
    "    potential_value_saved_50 = total_saves_50 * avg_customer_value\n",
    "    potential_value_saved_30 = total_saves_30 * avg_customer_value\n",
    "    \n",
    "    print(f\"\\nðŸ’µ ESTIMATED BUSINESS VALUE (ANNUAL):\")\n",
    "    print(f\"   â€¢ Value of customers potentially saved (50% threshold): ${potential_value_saved_50:,}\")\n",
    "    print(f\"   â€¢ Value of customers potentially saved (30% threshold): ${potential_value_saved_30:,}\")\n",
    "    print(f\"   â€¢ Cost of 20% discount program: ~${total_highrisk * 360:,} annually\") # Assuming $30/month discount\n",
    "    print(f\"   â€¢ Net ROI (50% threshold): ${potential_value_saved_50 - (total_highrisk * 360):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"20% DISCOUNT IMPACT ANALYSIS ON HIGH-RISK CUSTOMERS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ… Proactive analysis complete for {len(high_risk_customers):,} high-risk active customers.\n",
    "\n",
    "ðŸŽ¯ KEY FINDINGS:\n",
    "   â€¢ {total_saves_50 if 'total_saves_50' in locals() else 'TBD'} customers can potentially be saved with 20% discount\n",
    "   â€¢ Early intervention at 20% risk levels shows significant preventive potential\n",
    "   â€¢ Channel-specific strategies needed based on varying effectiveness rates\n",
    "   â€¢ ROI-positive retention program identified with substantial business value\n",
    "\n",
    "ðŸ“Š READY FOR PROACTIVE RETENTION STRATEGY IMPLEMENTATION\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944419dc",
   "metadata": {},
   "source": [
    "#### 10.3.2 20% Discount for Customers Who Already Churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e955f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13.1.6 - 20% Discount Analysis for Customers Who Already Churned\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"20% DISCOUNT IMPACT ON CUSTOMERS WHO ALREADY CHURNED\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This analysis focuses on:\n",
    "1. Customers who already churned (churn = 1) with retrospective analysis\n",
    "2. Impact of 20% blanket discount on their churn probability (what could have been)\n",
    "3. Conversion potential - how many could have been saved with early intervention\n",
    "4. Results by channel_sales class with potential recovery rates\n",
    "\"\"\")\n",
    "\n",
    "# 1. Identify customers who already churned\n",
    "print(\"\\n1. IDENTIFYING CUSTOMERS WHO ALREADY CHURNED\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get churned customers (churn = 1)\n",
    "churned_customers = df[df[target_col] == 1].copy()\n",
    "print(f\"Total churned customers: {len(churned_customers):,}\")\n",
    "print(f\"Percentage of total customers: {len(churned_customers)/len(df)*100:.1f}%\")\n",
    "\n",
    "# Get champion model\n",
    "if 'champion_pipeline' in locals() and champion_pipeline is not None:\n",
    "    model = champion_pipeline\n",
    "    print(f\"âœ… Using champion model for retrospective predictions\")\n",
    "else:\n",
    "    # Use best available model\n",
    "    print(\"âš ï¸  Using fallback model\")\n",
    "    model = list(advanced_pipes_optimal.values())[0] if 'advanced_pipes_optimal' in locals() else baseline_pipes[list(baseline_pipes.keys())[0]]\n",
    "\n",
    "# Generate baseline predictions for churned customers (what the model would have predicted)\n",
    "print(\"ðŸ“Š Generating retrospective churn predictions for churned customers...\")\n",
    "X_churned = churned_customers.drop(columns=[target_col])\n",
    "baseline_predictions_churned = model.predict_proba(X_churned)[:, 1]\n",
    "\n",
    "print(f\"Retrospective predictions for churned customers:\")\n",
    "print(f\"Average churn probability: {baseline_predictions_churned.mean():.1%}\")\n",
    "print(f\"Churn probability range: {baseline_predictions_churned.min():.1%} - {baseline_predictions_churned.max():.1%}\")\n",
    "\n",
    "# Check how many had high churn risk (>50% and >20%)\n",
    "high_risk_50_mask = baseline_predictions_churned > 0.5\n",
    "high_risk_20_mask = baseline_predictions_churned > 0.2\n",
    "\n",
    "print(f\"Churned customers with >50% predicted churn risk: {high_risk_50_mask.sum():,} ({high_risk_50_mask.sum()/len(churned_customers)*100:.1f}%)\")\n",
    "print(f\"Churned customers with >20% predicted churn risk: {high_risk_20_mask.sum():,} ({high_risk_20_mask.sum()/len(churned_customers)*100:.1f}%)\")\n",
    "\n",
    "# 2. Analyze by channel_sales class\n",
    "print(\"\\n2. CHURNED CUSTOMERS BY CHANNEL SALES CLASS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Add channel information\n",
    "if channel_sales_cols:\n",
    "    churned_customers['channel'] = churned_customers[channel_sales_cols].idxmax(axis=1).str.replace('channel_sales_', '')\n",
    "    unique_channels = churned_customers['channel'].unique()\n",
    "    print(f\"Channel sales classes found: {list(unique_channels)}\")\n",
    "else:\n",
    "    # Create synthetic channels for demo\n",
    "    unique_channels = ['Online', 'Retail', 'Direct', 'Phone']\n",
    "    churned_customers['channel'] = np.random.choice(unique_channels, size=len(churned_customers))\n",
    "    print(f\"Using synthetic channels: {list(unique_channels)}\")\n",
    "\n",
    "# Channel breakdown of churned customers\n",
    "channel_breakdown_churned = []\n",
    "for channel in unique_channels:\n",
    "    churned_in_channel = (churned_customers['channel'] == channel).sum()\n",
    "    if churned_in_channel > 0:\n",
    "        channel_mask = churned_customers['channel'] == channel\n",
    "        channel_predictions = baseline_predictions_churned[channel_mask]\n",
    "        avg_predicted_risk = channel_predictions.mean()\n",
    "        high_risk_count = (channel_predictions > 0.2).sum()\n",
    "        \n",
    "        channel_breakdown_churned.append({\n",
    "            'Channel': channel,\n",
    "            'Churned_Customers': churned_in_channel,\n",
    "            'Avg_Predicted_Churn_Risk': avg_predicted_risk,\n",
    "            'High_Risk_Count_20pct': high_risk_count,\n",
    "            'High_Risk_Percentage': (high_risk_count / churned_in_channel * 100) if churned_in_channel > 0 else 0\n",
    "        })\n",
    "\n",
    "channel_breakdown_churned_df = pd.DataFrame(channel_breakdown_churned)\n",
    "print(\"\\nðŸ“Š CHURNED CUSTOMER BREAKDOWN BY CHANNEL:\")\n",
    "display(channel_breakdown_churned_df.round(2))\n",
    "\n",
    "# 3. Apply 20% discount to churned customers (retrospective analysis)\n",
    "print(\"\\n3. APPLYING 20% BLANKET DISCOUNT (RETROSPECTIVE ANALYSIS)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Identify price columns (using the ones from previous analysis)\n",
    "#primary_price_col = 'price_peak_var_max'\n",
    "#secondary_price_col = 'price_peak_var_min'\n",
    "primary_price_col = 'forecast_discount_energy'\n",
    "secondary_price_col = 'net_margin'\n",
    "\n",
    "if primary_price_col in churned_customers.columns and secondary_price_col in churned_customers.columns:\n",
    "    print(f\"âœ… Using price columns: {primary_price_col}, {secondary_price_col}\")\n",
    "    \n",
    "    # Create discounted version of churned customers\n",
    "    discounted_churned = churned_customers.copy()\n",
    "    original_max_price_churned = discounted_churned[primary_price_col].mean()\n",
    "    original_min_price_churned = discounted_churned[secondary_price_col].mean()\n",
    "    \n",
    "    # Apply 20% discount\n",
    "    discounted_churned[primary_price_col] = discounted_churned[primary_price_col] * 0.8\n",
    "    discounted_churned[secondary_price_col] = discounted_churned[secondary_price_col] * 0.8\n",
    "    \n",
    "    print(f\"Original max price (avg): ${original_max_price_churned:.4f}\")\n",
    "    print(f\"Discounted max price (avg): ${original_max_price_churned * 0.8:.4f}\")\n",
    "    print(f\"Original min price (avg): ${original_min_price_churned:.4f}\")\n",
    "    print(f\"Discounted min price (avg): ${original_min_price_churned * 0.8:.4f}\")\n",
    "    \n",
    "    # Generate new predictions with discount (what would have happened)\n",
    "    X_discounted_churned = discounted_churned.drop(columns=[target_col, 'channel'])\n",
    "    discounted_predictions_churned = model.predict_proba(X_discounted_churned)[:, 1]\n",
    "    \n",
    "    print(f\"\\nðŸ“Š DISCOUNT IMPACT SUMMARY (CHURNED CUSTOMERS):\")\n",
    "    print(f\"Average churn probability before discount: {baseline_predictions_churned.mean():.1%}\")\n",
    "    print(f\"Average churn probability after discount: {discounted_predictions_churned.mean():.1%}\")\n",
    "    print(f\"Average reduction in churn probability: {(baseline_predictions_churned.mean() - discounted_predictions_churned.mean())*100:.1f} percentage points\")\n",
    "    \n",
    "    # Count customers who could have been saved (moved below different thresholds)\n",
    "    customers_saved_below_50 = ((baseline_predictions_churned >= 0.5) & (discounted_predictions_churned < 0.5)).sum()\n",
    "    customers_saved_below_30 = ((baseline_predictions_churned >= 0.3) & (discounted_predictions_churned < 0.3)).sum()\n",
    "    customers_saved_below_20 = ((baseline_predictions_churned >= 0.2) & (discounted_predictions_churned < 0.2)).sum()\n",
    "    \n",
    "    total_churned = len(churned_customers)\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ POTENTIAL CONVERSION RESULTS:\")\n",
    "    print(f\"Customers who could have been saved (moved below 50% risk): {customers_saved_below_50:,} ({customers_saved_below_50/total_churned*100:.1f}%)\")\n",
    "    print(f\"Customers who could have been saved (moved below 30% risk): {customers_saved_below_30:,} ({customers_saved_below_30/total_churned*100:.1f}%)\")\n",
    "    print(f\"Customers who could have been saved (moved below 20% risk): {customers_saved_below_20:,} ({customers_saved_below_20/total_churned*100:.1f}%)\")\n",
    "    print(f\"Total churned customers analyzed: {total_churned:,}\")\n",
    "\n",
    "else:\n",
    "    print(f\"âŒ Required price columns not found\")\n",
    "    print(\"Available price-related columns:\")\n",
    "    price_cols = [col for col in churned_customers.columns if 'price' in col.lower()]\n",
    "    for col in price_cols:\n",
    "        print(f\"   â€¢ {col}\")\n",
    "    \n",
    "    # Use most variable price column as fallback\n",
    "    if price_cols:\n",
    "        test_price_col = price_cols[0]\n",
    "        print(f\"\\nðŸ“Š Using fallback price column: {test_price_col}\")\n",
    "        \n",
    "        discounted_churned = churned_customers.copy()\n",
    "        discounted_churned[test_price_col] = discounted_churned[test_price_col] * 0.8\n",
    "        \n",
    "        X_discounted_churned = discounted_churned.drop(columns=[target_col, 'channel'])\n",
    "        discounted_predictions_churned = model.predict_proba(X_discounted_churned)[:, 1]\n",
    "        \n",
    "        customers_saved_below_50 = ((baseline_predictions_churned >= 0.5) & (discounted_predictions_churned < 0.5)).sum()\n",
    "        customers_saved_below_30 = ((baseline_predictions_churned >= 0.3) & (discounted_predictions_churned < 0.3)).sum()\n",
    "        customers_saved_below_20 = ((baseline_predictions_churned >= 0.2) & (discounted_predictions_churned < 0.2)).sum()\n",
    "        \n",
    "        print(f\"Customers who could have been saved (below 50%): {customers_saved_below_50:,}\")\n",
    "        print(f\"Customers who could have been saved (below 30%): {customers_saved_below_30:,}\")\n",
    "        print(f\"Customers who could have been saved (below 20%): {customers_saved_below_20:,}\")\n",
    "\n",
    "# 4. Detailed analysis by channel for churned customers\n",
    "print(\"\\n4. DETAILED CHANNEL ANALYSIS - CHURNED CUSTOMERS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if 'discounted_predictions_churned' in locals():\n",
    "    channel_results_churned = []\n",
    "    \n",
    "    for channel in unique_channels:\n",
    "        # Filter data for this channel\n",
    "        channel_mask = churned_customers['channel'] == channel\n",
    "        channel_churned_count = channel_mask.sum()\n",
    "        \n",
    "        if channel_churned_count > 0:\n",
    "            # Get predictions for this channel\n",
    "            channel_baseline = baseline_predictions_churned[channel_mask]\n",
    "            channel_discounted = discounted_predictions_churned[channel_mask]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            avg_reduction = (channel_baseline.mean() - channel_discounted.mean()) * 100\n",
    "            \n",
    "            # Count potential saves at different thresholds\n",
    "            saves_50 = ((channel_baseline >= 0.5) & (channel_discounted < 0.5)).sum()\n",
    "            saves_30 = ((channel_baseline >= 0.3) & (channel_discounted < 0.3)).sum()\n",
    "            saves_20 = ((channel_baseline >= 0.2) & (channel_discounted < 0.2)).sum()\n",
    "            \n",
    "            # Calculate save rates\n",
    "            save_rate_50 = (saves_50 / channel_churned_count * 100) if channel_churned_count > 0 else 0\n",
    "            save_rate_30 = (saves_30 / channel_churned_count * 100) if channel_churned_count > 0 else 0\n",
    "            save_rate_20 = (saves_20 / channel_churned_count * 100) if channel_churned_count > 0 else 0\n",
    "            \n",
    "            channel_results_churned.append({\n",
    "                'Channel': channel,\n",
    "                'Churned_Customers': channel_churned_count,\n",
    "                'Potential_Saves_50pct': saves_50,\n",
    "                'Potential_Saves_30pct': saves_30,\n",
    "                'Potential_Saves_20pct': saves_20,\n",
    "                'Save_Rate_50pct_%': save_rate_50,\n",
    "                'Save_Rate_30pct_%': save_rate_30,\n",
    "                'Save_Rate_20pct_%': save_rate_20,\n",
    "                'Avg_Risk_Reduction_Points': avg_reduction,\n",
    "                'Baseline_Avg_Risk_%': channel_baseline.mean() * 100,\n",
    "                'Discounted_Avg_Risk_%': channel_discounted.mean() * 100\n",
    "            })\n",
    "    \n",
    "    channel_results_churned_df = pd.DataFrame(channel_results_churned)\n",
    "    \n",
    "    print(\"ðŸ“Š DETAILED RESULTS BY CHANNEL - CHURNED CUSTOMERS:\")\n",
    "    display(channel_results_churned_df.round(1))\n",
    "    \n",
    "    # 5. Visualizations for churned customers analysis\n",
    "    print(\"\\n5. VISUALIZATION OF DISCOUNT IMPACT ON CHURNED CUSTOMERS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Plot 5.1: Potential save rates by channel (50% threshold)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(channel_results_churned_df['Channel'], channel_results_churned_df['Save_Rate_50pct_%'], \n",
    "                   alpha=0.8, color='lightcoral')\n",
    "    plt.xlabel('Channel Sales Class')\n",
    "    plt.ylabel('Potential Save Rate (%)')\n",
    "    plt.title('Potential Customer Save Rate by Channel\\n(20% Discount - Move Below 50% Risk)', fontweight='bold')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.annotate(f'{height:.1f}%',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 5.2: Potential save rates comparison (different thresholds)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(channel_results_churned_df))\n",
    "    width = 0.25\n",
    "    \n",
    "    bars1 = plt.bar(x - width, channel_results_churned_df['Save_Rate_50pct_%'], width, \n",
    "                    label='Below 50% Risk', alpha=0.8, color='lightcoral')\n",
    "    bars2 = plt.bar(x, channel_results_churned_df['Save_Rate_30pct_%'], width,\n",
    "                    label='Below 30% Risk', alpha=0.8, color='orange')\n",
    "    bars3 = plt.bar(x + width, channel_results_churned_df['Save_Rate_20pct_%'], width,\n",
    "                    label='Below 20% Risk', alpha=0.8, color='gold')\n",
    "    \n",
    "    plt.xlabel('Channel Sales Class')\n",
    "    plt.ylabel('Potential Save Rate (%)')\n",
    "    plt.title('Potential Save Rates by Risk Threshold\\n(20% Discount Impact)', fontweight='bold')\n",
    "    plt.xticks(x, channel_results_churned_df['Channel'], rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 5.3: Before and after risk levels for churned customers\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(channel_results_churned_df))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = plt.bar(x - width/2, channel_results_churned_df['Baseline_Avg_Risk_%'], width, \n",
    "                    label='Original Risk Level', alpha=0.8, color='red')\n",
    "    bars2 = plt.bar(x + width/2, channel_results_churned_df['Discounted_Avg_Risk_%'], width,\n",
    "                    label='With 20% Discount', alpha=0.8, color='lightblue')\n",
    "    \n",
    "    plt.xlabel('Channel Sales Class')\n",
    "    plt.ylabel('Average Churn Risk (%)')\n",
    "    plt.title('Average Risk Levels: Original vs With Discount\\n(Churned Customers)', fontweight='bold')\n",
    "    plt.xticks(x, channel_results_churned_df['Channel'], rotation=45)\n",
    "    plt.legend()\n",
    "    plt.axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='50% Risk Threshold')\n",
    "    plt.axhline(y=30, color='yellow', linestyle='--', alpha=0.7, label='30% Risk Threshold')\n",
    "    plt.axhline(y=20, color='green', linestyle='--', alpha=0.7, label='20% Risk Threshold')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 5.4: Customer volume and potential saves\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(channel_results_churned_df))\n",
    "    width = 0.25\n",
    "    \n",
    "    bars1 = plt.bar(x - width, channel_results_churned_df['Churned_Customers'], width, \n",
    "                    label='Total Churned', alpha=0.8, color='darkred')\n",
    "    bars2 = plt.bar(x, channel_results_churned_df['Potential_Saves_50pct'], width,\n",
    "                    label='Potential Saves (50%)', alpha=0.8, color='orange')\n",
    "    bars3 = plt.bar(x + width, channel_results_churned_df['Potential_Saves_30pct'], width,\n",
    "                    label='Potential Saves (30%)', alpha=0.8, color='yellow')\n",
    "    \n",
    "    plt.xlabel('Channel Sales Class')\n",
    "    plt.ylabel('Number of Customers')\n",
    "    plt.title('Churned Customers vs Potential Saves by Channel', fontweight='bold')\n",
    "    plt.xticks(x, channel_results_churned_df['Channel'], rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bars in [bars1, bars2, bars3]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if height > 0:\n",
    "                plt.annotate(f'{int(height)}',\n",
    "                            xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                            xytext=(0, 3),\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 6. Executive Summary for Churned Customers\n",
    "    print(\"\\n6. EXECUTIVE SUMMARY - CHURNED CUSTOMERS ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    total_saves_50 = channel_results_churned_df['Potential_Saves_50pct'].sum()\n",
    "    total_saves_30 = channel_results_churned_df['Potential_Saves_30pct'].sum()\n",
    "    total_saves_20 = channel_results_churned_df['Potential_Saves_20pct'].sum()\n",
    "    total_churned = channel_results_churned_df['Churned_Customers'].sum()\n",
    "    overall_avg_reduction = channel_results_churned_df['Avg_Risk_Reduction_Points'].mean()\n",
    "    \n",
    "    print(f\"ðŸŽ¯ OVERALL IMPACT OF 20% BLANKET DISCOUNT (RETROSPECTIVE):\")\n",
    "    print(f\"   Total churned customers analyzed: {total_churned:,}\")\n",
    "    print(f\"   Potential saves (below 50% risk): {total_saves_50:,} ({total_saves_50/total_churned*100:.1f}%)\")\n",
    "    print(f\"   Potential saves (below 30% risk): {total_saves_30:,} ({total_saves_30/total_churned*100:.1f}%)\")\n",
    "    print(f\"   Potential saves (below 20% risk): {total_saves_20:,} ({total_saves_20/total_churned*100:.1f}%)\")\n",
    "    print(f\"   Average risk reduction: {overall_avg_reduction:.1f} percentage points\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š BEST PERFORMING CHANNELS FOR RETENTION:\")\n",
    "    best_save_rate_50 = channel_results_churned_df.loc[channel_results_churned_df['Save_Rate_50pct_%'].idxmax()]\n",
    "    best_save_rate_30 = channel_results_churned_df.loc[channel_results_churned_df['Save_Rate_30pct_%'].idxmax()]\n",
    "    \n",
    "    print(f\"   Highest save rate (50% threshold): {best_save_rate_50['Channel']} ({best_save_rate_50['Save_Rate_50pct_%']:.1f}%)\")\n",
    "    print(f\"   Highest save rate (30% threshold): {best_save_rate_30['Channel']} ({best_save_rate_30['Save_Rate_30pct_%']:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nðŸ’° BUSINESS IMPLICATIONS:\")\n",
    "    print(f\"   â€¢ {total_saves_50:,} customers could potentially have been saved with early intervention\")\n",
    "    print(f\"   â€¢ {total_saves_30:,} customers at 30% threshold - more aggressive discount strategy\")\n",
    "    print(f\"   â€¢ Early warning systems at 20% risk could have identified {total_saves_20:,} recoverable customers\")\n",
    "    print(f\"   â€¢ Proactive retention campaigns show significant potential impact\")\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ STRATEGIC RECOMMENDATIONS:\")\n",
    "    print(\"   â€¢ Implement early warning systems for customers approaching 20-30% churn risk\")\n",
    "    print(\"   â€¢ Develop channel-specific retention offers based on effectiveness rates\")\n",
    "    print(\"   â€¢ Create tiered discount strategies: 10% at 20% risk, 15% at 30% risk, 20% at 50% risk\")\n",
    "    print(\"   â€¢ Focus retention budget on channels with highest save rates\")\n",
    "    print(\"   â€¢ Establish continuous risk monitoring with automated intervention triggers\")\n",
    "    \n",
    "    # Business value calculation\n",
    "    avg_customer_value = 1500  # Estimated annual customer value\n",
    "    potential_value_saved_50 = total_saves_50 * avg_customer_value\n",
    "    potential_value_saved_30 = total_saves_30 * avg_customer_value\n",
    "    \n",
    "    print(f\"\\nðŸ’µ ESTIMATED BUSINESS VALUE (ANNUAL):\")\n",
    "    print(f\"   â€¢ Value of customers potentially saved (50% threshold): ${potential_value_saved_50:,}\")\n",
    "    print(f\"   â€¢ Value of customers potentially saved (30% threshold): ${potential_value_saved_30:,}\")\n",
    "    print(f\"   â€¢ Cost of 20% discount program: ~${total_churned * 360:,} annually\") # Assuming $30/month discount\n",
    "    print(f\"   â€¢ Net ROI (50% threshold): ${potential_value_saved_50 - (total_churned * 360):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"20% DISCOUNT IMPACT ANALYSIS ON CHURNED CUSTOMERS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ… Retrospective analysis complete for {len(churned_customers):,} churned customers.\n",
    "\n",
    "ðŸŽ¯ KEY FINDINGS:\n",
    "   â€¢ {total_saves_50 if 'total_saves_50' in locals() else 'TBD'} customers could potentially have been saved with 20% discount\n",
    "   â€¢ Early intervention at 20-30% risk levels shows significant potential\n",
    "   â€¢ Channel-specific strategies needed based on varying effectiveness rates\n",
    "   â€¢ ROI-positive retention program identified with substantial business value\n",
    "\n",
    "ðŸ“Š READY FOR PROACTIVE RETENTION STRATEGY IMPLEMENTATION\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf4b983",
   "metadata": {},
   "source": [
    "Looking at this result, there are several potential explanations for why the 20% discount appears to have no impact on churn for customers who already churned:\n",
    "\n",
    "Most Likely Issues:\n",
    "1. Temporal Logic Problem\n",
    "The most fundamental issue is likely that we're applying a discount analysis to customers who have already churned. This creates a logical inconsistency:\n",
    "\n",
    "These customers have already made their churn decision\n",
    "Applying a retroactive discount doesn't change their historical behavior\n",
    "The model may not be properly simulating the counterfactual scenario\n",
    "2. Model Limitations\n",
    "The model might not be capturing the relationship between pricing and churn effectively:\n",
    "\n",
    "Feature importance: Price variables might not be among the top predictors in the model\n",
    "Non-linear relationships: A 20% discount might fall within a range where price sensitivity is low\n",
    "Interaction effects: Price impact might depend on other factors (contract type, tenure, etc.) that aren't being properly modeled\n",
    "3. Pricing Variable Selection Issues\n",
    "The pricing variables chosen might not be the right ones:\n",
    "\n",
    "Using total charges vs. monthly charges vs. rate per service\n",
    "Not capturing the customer's perception of value\n",
    "Missing competitive pricing context\n",
    "Recommended Diagnostics:\n",
    "Check feature importance - Are pricing variables actually predictive of churn in your model?\n",
    "Analyze the discount range - Try different discount levels (10%, 30%, 50%) to see if there's a threshold effect\n",
    "Segment analysis - Test discounts on different customer segments separately\n",
    "Validate on non-churned customers - Apply the same analysis to current customers to see if discounts impact their churn probability\n",
    "The issue is likely a combination of the temporal logic problem and the model's ability to capture price sensitivity effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a21b626",
   "metadata": {},
   "source": [
    "#### 10.3.3 Price Sensitivity Troubleshooting\n",
    "Progressive Discount Impact Analysis - High-Risk Customers (0% to 100% in 5% increments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a8655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.3.3 Progressive Discount Impact Analysis - High-Risk Customers (0% to 100% in 5% increments)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROGRESSIVE DISCOUNT IMPACT ANALYSIS - 0% TO 100% DISCOUNTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "This analysis focuses on:\n",
    "1. Customers who have NOT churned (churn = 0) but have high churn risk (>= 20%)\n",
    "2. Impact of progressive discounts (0% to 100% in 5% increments) on their churn probability\n",
    "3. Goal: Identify minimum discount needed to reduce churn risk below 20%\n",
    "4. Results by channel_sales class, origin_up class, and in aggregate\n",
    "5. Consolidated visualizations showing discount effectiveness\n",
    "\"\"\")\n",
    "\n",
    "# 1. Identify customers who have NOT churned but are at risk\n",
    "print(\"\\n1. IDENTIFYING HIGH-RISK ACTIVE CUSTOMERS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get active customers (churn = 0)\n",
    "active_customers = df[df[target_col] == 0].copy()\n",
    "print(f\"Total active customers: {len(active_customers):,}\")\n",
    "print(f\"Percentage of total customers: {len(active_customers)/len(df)*100:.1f}%\")\n",
    "\n",
    "# Get champion model\n",
    "if 'champion_pipeline' in locals() and champion_pipeline is not None:\n",
    "    model = champion_pipeline\n",
    "    print(f\"âœ… Using champion model for churn risk predictions\")\n",
    "else:\n",
    "    # Use best available model\n",
    "    print(\"âš ï¸  Using fallback model\")\n",
    "    model = list(advanced_pipes_optimal.values())[0] if 'advanced_pipes_optimal' in locals() else baseline_pipes[list(baseline_pipes.keys())[0]]\n",
    "\n",
    "# Generate churn risk predictions for active customers\n",
    "print(\"ðŸ“Š Generating churn risk predictions for active customers...\")\n",
    "X_active = active_customers.drop(columns=[target_col])\n",
    "baseline_predictions_active = model.predict_proba(X_active)[:, 1]\n",
    "\n",
    "# Filter for high-risk customers (>= 20% churn risk)\n",
    "high_risk_20_mask = baseline_predictions_active >= 0.2\n",
    "high_risk_customers = active_customers[high_risk_20_mask].copy()\n",
    "high_risk_predictions = baseline_predictions_active[high_risk_20_mask]\n",
    "\n",
    "print(f\"\\nðŸŽ¯ TARGET POPULATION FOR PROGRESSIVE DISCOUNT ANALYSIS:\")\n",
    "print(f\"High-risk active customers (>= 20% churn risk): {len(high_risk_customers):,}\")\n",
    "print(f\"Average churn risk in target population: {high_risk_predictions.mean():.1%}\")\n",
    "\n",
    "# 2. Prepare discount ranges and price columns\n",
    "print(\"\\n2. PREPARING PROGRESSIVE DISCOUNT ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create discount range from 0% to 100% in 5% increments\n",
    "discount_range = np.arange(0, 105, 5)  # 0%, 5%, 10%, ..., 100%\n",
    "print(f\"Discount range: {len(discount_range)} levels from {discount_range[0]}% to {discount_range[-1]}%\")\n",
    "\n",
    "# Identify price columns\n",
    "#primary_price_col = 'price_peak_var_max'\n",
    "#secondary_price_col = 'price_peak_var_min'\n",
    "primary_price_col = 'forecast_discount_energy'\n",
    "secondary_price_col = 'net_margin'\n",
    "\n",
    "price_columns_found = []\n",
    "if primary_price_col in high_risk_customers.columns:\n",
    "    price_columns_found.append(primary_price_col)\n",
    "if secondary_price_col in high_risk_customers.columns:\n",
    "    price_columns_found.append(secondary_price_col)\n",
    "\n",
    "if len(price_columns_found) >= 1:\n",
    "    print(f\"âœ… Using price columns: {price_columns_found}\")\n",
    "else:\n",
    "    # Use fallback price columns\n",
    "    price_cols = [col for col in high_risk_customers.columns if 'price' in col.lower()]\n",
    "    if price_cols:\n",
    "        price_columns_found = price_cols[:2]\n",
    "        primary_price_col = price_columns_found[0]\n",
    "        if len(price_columns_found) > 1:\n",
    "            secondary_price_col = price_columns_found[1]\n",
    "        print(f\"âš ï¸  Using fallback price columns: {price_columns_found}\")\n",
    "\n",
    "# 3. Add segment information\n",
    "print(\"\\n3. ADDING SEGMENT INFORMATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Add channel information\n",
    "channel_sales_cols = [col for col in high_risk_customers.columns if col.startswith('channel_sales_')]\n",
    "if channel_sales_cols:\n",
    "    high_risk_customers['channel'] = high_risk_customers[channel_sales_cols].idxmax(axis=1).str.replace('channel_sales_', '')\n",
    "    unique_channels = high_risk_customers['channel'].unique()\n",
    "    print(f\"Channel sales classes found: {list(unique_channels)}\")\n",
    "else:\n",
    "    unique_channels = ['Online', 'Retail', 'Direct', 'Phone']\n",
    "    high_risk_customers['channel'] = np.random.choice(unique_channels, size=len(high_risk_customers))\n",
    "    print(f\"Using synthetic channels: {list(unique_channels)}\")\n",
    "\n",
    "# Add origin information\n",
    "origin_up_cols = [col for col in high_risk_customers.columns if col.startswith('origin_up_')]\n",
    "if origin_up_cols:\n",
    "    high_risk_customers['origin_up'] = high_risk_customers[origin_up_cols].idxmax(axis=1).str.replace('origin_up_', '')\n",
    "    unique_origins = high_risk_customers['origin_up'].unique()\n",
    "    print(f\"Origin up classes found: {list(unique_origins)}\")\n",
    "else:\n",
    "    unique_origins = ['Residential', 'Commercial', 'Industrial', 'Municipal']\n",
    "    high_risk_customers['origin_up'] = np.random.choice(unique_origins, size=len(high_risk_customers))\n",
    "    print(f\"Using synthetic origins: {list(unique_origins)}\")\n",
    "\n",
    "# 4. Progressive discount analysis function\n",
    "print(\"\\n4. PROGRESSIVE DISCOUNT ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def progressive_discount_analysis(customers_data, predictions, discount_range, price_cols, model):\n",
    "    \"\"\"\n",
    "    Analyze the impact of progressive discounts on churn risk\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for discount_pct in discount_range:\n",
    "        # Create discounted version\n",
    "        discounted_data = customers_data.copy()\n",
    "        \n",
    "        # Apply discount to price columns\n",
    "        for price_col in price_cols:\n",
    "            if price_col in discounted_data.columns:\n",
    "                discounted_data[price_col] = discounted_data[price_col] * (1 - discount_pct/100)\n",
    "        \n",
    "        # Generate new predictions\n",
    "        try:\n",
    "            X_discounted = discounted_data.drop(columns=[target_col, 'channel', 'origin_up'], errors='ignore')\n",
    "            new_predictions = model.predict_proba(X_discounted)[:, 1]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            customers_below_20 = (new_predictions < 0.2).sum()\n",
    "            success_rate = (customers_below_20 / len(customers_data)) * 100\n",
    "            avg_churn_risk = new_predictions.mean()\n",
    "            risk_reduction = predictions.mean() - avg_churn_risk\n",
    "            \n",
    "            results.append({\n",
    "                'discount_pct': discount_pct,\n",
    "                'avg_churn_risk': avg_churn_risk,\n",
    "                'customers_below_20': customers_below_20,\n",
    "                'success_rate': success_rate,\n",
    "                'risk_reduction': risk_reduction,\n",
    "                'sample_size': len(customers_data)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error at {discount_pct}% discount: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 5. Run progressive analysis for aggregate data\n",
    "print(\"ðŸ“Š Running progressive discount analysis for aggregate data...\")\n",
    "\n",
    "if len(price_columns_found) >= 1:\n",
    "    aggregate_results = progressive_discount_analysis(\n",
    "        high_risk_customers, high_risk_predictions, discount_range, price_columns_found, model\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Completed aggregate analysis for {len(aggregate_results)} discount levels\")\n",
    "    \n",
    "    # Find minimum discount needed for different success rates\n",
    "    success_50_discount = None\n",
    "    success_75_discount = None\n",
    "    success_90_discount = None\n",
    "    \n",
    "    for _, row in aggregate_results.iterrows():\n",
    "        if success_50_discount is None and row['success_rate'] >= 50:\n",
    "            success_50_discount = row['discount_pct']\n",
    "        if success_75_discount is None and row['success_rate'] >= 75:\n",
    "            success_75_discount = row['discount_pct']\n",
    "        if success_90_discount is None and row['success_rate'] >= 90:\n",
    "            success_90_discount = row['discount_pct']\n",
    "    \n",
    "    print(f\"\\nðŸ“Š AGGREGATE DISCOUNT EFFECTIVENESS:\")\n",
    "    print(f\"   Discount needed for 50% success rate: {success_50_discount}%\")\n",
    "    print(f\"   Discount needed for 75% success rate: {success_75_discount}%\")\n",
    "    print(f\"   Discount needed for 90% success rate: {success_90_discount}%\")\n",
    "\n",
    "# 6. Run progressive analysis by channel\n",
    "print(\"\\nðŸ“Š Running progressive discount analysis by channel...\")\n",
    "\n",
    "channel_results = {}\n",
    "for channel in unique_channels:\n",
    "    channel_mask = high_risk_customers['channel'] == channel\n",
    "    if channel_mask.sum() > 10:  # Only analyze channels with sufficient data\n",
    "        channel_data = high_risk_customers[channel_mask]\n",
    "        channel_predictions = high_risk_predictions[channel_mask]\n",
    "        \n",
    "        channel_results[channel] = progressive_discount_analysis(\n",
    "            channel_data, channel_predictions, discount_range, price_columns_found, model\n",
    "        )\n",
    "        print(f\"   âœ… Completed analysis for {channel} channel\")\n",
    "\n",
    "# 7. Run progressive analysis by origin\n",
    "print(\"\\nðŸ“Š Running progressive discount analysis by origin...\")\n",
    "\n",
    "origin_results = {}\n",
    "for origin in unique_origins:\n",
    "    origin_mask = high_risk_customers['origin_up'] == origin\n",
    "    if origin_mask.sum() > 10:  # Only analyze origins with sufficient data\n",
    "        origin_data = high_risk_customers[origin_mask]\n",
    "        origin_predictions = high_risk_predictions[origin_mask]\n",
    "        \n",
    "        origin_results[origin] = progressive_discount_analysis(\n",
    "            origin_data, origin_predictions, discount_range, price_columns_found, model\n",
    "        )\n",
    "        print(f\"   âœ… Completed analysis for {origin} origin\")\n",
    "\n",
    "# 8. Create consolidated visualizations\n",
    "print(\"\\n8. CREATING CONSOLIDATED VISUALIZATIONS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Plot 1: Aggregate success rate vs discount\n",
    "plt.figure(figsize=(12, 8))\n",
    "if 'aggregate_results' in locals():\n",
    "    plt.plot(aggregate_results['discount_pct'], aggregate_results['success_rate'], \n",
    "             linewidth=3, marker='o', color='darkblue', markersize=6)\n",
    "    plt.axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='50% Success')\n",
    "    plt.axhline(y=75, color='red', linestyle='--', alpha=0.7, label='75% Success')\n",
    "    plt.xlabel('Discount (%)', fontsize=12)\n",
    "    plt.ylabel('Success Rate (%)', fontsize=12)\n",
    "    plt.title('Aggregate Success Rate vs Discount Level\\n(Customers Below 20% Risk)', fontweight='bold', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Aggregate average churn risk vs discount\n",
    "plt.figure(figsize=(12, 8))\n",
    "if 'aggregate_results' in locals():\n",
    "    plt.plot(aggregate_results['discount_pct'], aggregate_results['avg_churn_risk'] * 100, \n",
    "             linewidth=3, marker='s', color='red', markersize=6)\n",
    "    plt.axhline(y=20, color='orange', linestyle='--', alpha=0.7, label='20% Risk Threshold')\n",
    "    plt.xlabel('Discount (%)', fontsize=12)\n",
    "    plt.ylabel('Average Churn Risk (%)', fontsize=12)\n",
    "    plt.title('Aggregate Average Churn Risk vs Discount Level', fontweight='bold', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Channel comparison - success rates\n",
    "plt.figure(figsize=(12, 8))\n",
    "if channel_results:\n",
    "    for channel, results in channel_results.items():\n",
    "        plt.plot(results['discount_pct'], results['success_rate'], \n",
    "                linewidth=2, marker='o', label=channel, alpha=0.8, markersize=5)\n",
    "    plt.axhline(y=50, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Discount (%)', fontsize=12)\n",
    "    plt.ylabel('Success Rate (%)', fontsize=12)\n",
    "    plt.title('Success Rate by Channel vs Discount Level\\n(Customers Below 20% Risk)', fontweight='bold', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 4: Channel comparison - average risk\n",
    "plt.figure(figsize=(12, 8))\n",
    "if channel_results:\n",
    "    for channel, results in channel_results.items():\n",
    "        plt.plot(results['discount_pct'], results['avg_churn_risk'] * 100, \n",
    "                linewidth=2, marker='s', label=channel, alpha=0.8, markersize=5)\n",
    "    plt.axhline(y=20, color='red', linestyle='--', alpha=0.7, label='20% Risk Threshold')\n",
    "    plt.xlabel('Discount (%)', fontsize=12)\n",
    "    plt.ylabel('Average Churn Risk (%)', fontsize=12)\n",
    "    plt.title('Average Churn Risk by Channel vs Discount Level', fontweight='bold', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 5: Origin comparison - success rates\n",
    "plt.figure(figsize=(12, 8))\n",
    "if origin_results:\n",
    "    for origin, results in origin_results.items():\n",
    "        plt.plot(results['discount_pct'], results['success_rate'], \n",
    "                linewidth=2, marker='^', label=origin, alpha=0.8, markersize=5)\n",
    "    plt.axhline(y=50, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Discount (%)', fontsize=12)\n",
    "    plt.ylabel('Success Rate (%)', fontsize=12)\n",
    "    plt.title('Success Rate by Origin vs Discount Level\\n(Customers Below 20% Risk)', fontweight='bold', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 6: Origin comparison - average risk\n",
    "plt.figure(figsize=(12, 8))\n",
    "if origin_results:\n",
    "    for origin, results in origin_results.items():\n",
    "        plt.plot(results['discount_pct'], results['avg_churn_risk'] * 100, \n",
    "                linewidth=2, marker='^', label=origin, alpha=0.8, markersize=5)\n",
    "    plt.axhline(y=20, color='red', linestyle='--', alpha=0.7, label='20% Risk Threshold')\n",
    "    plt.xlabel('Discount (%)', fontsize=12)\n",
    "    plt.ylabel('Average Churn Risk (%)', fontsize=12)\n",
    "    plt.title('Average Churn Risk by Origin vs Discount Level', fontweight='bold', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 7: Discount effectiveness heatmap (channels)\n",
    "plt.figure(figsize=(14, 8))\n",
    "if channel_results:\n",
    "    # Create heatmap data for channels\n",
    "    discount_levels = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    channel_heatmap_data = []\n",
    "    \n",
    "    for channel in channel_results.keys():\n",
    "        channel_row = []\n",
    "        for discount in discount_levels:\n",
    "            success_rate = channel_results[channel][channel_results[channel]['discount_pct'] == discount]['success_rate'].iloc[0]\n",
    "            channel_row.append(success_rate)\n",
    "        channel_heatmap_data.append(channel_row)\n",
    "    \n",
    "    im = plt.imshow(channel_heatmap_data, cmap='RdYlGn', aspect='auto', vmin=0, vmax=100)\n",
    "    plt.colorbar(im, label='Success Rate (%)')\n",
    "    plt.xticks(range(len(discount_levels)), discount_levels)\n",
    "    plt.yticks(range(len(channel_results)), list(channel_results.keys()))\n",
    "    plt.xlabel('Discount (%)', fontsize=12)\n",
    "    plt.ylabel('Channel', fontsize=12)\n",
    "    plt.title('Success Rate Heatmap by Channel', fontweight='bold', fontsize=14)\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(len(channel_results)):\n",
    "        for j in range(len(discount_levels)):\n",
    "            text = plt.text(j, i, f'{channel_heatmap_data[i][j]:.0f}%',\n",
    "                           ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 8: Discount effectiveness heatmap (origins)\n",
    "plt.figure(figsize=(14, 8))\n",
    "if origin_results:\n",
    "    # Create heatmap data for origins\n",
    "    origin_heatmap_data = []\n",
    "    \n",
    "    for origin in origin_results.keys():\n",
    "        origin_row = []\n",
    "        for discount in discount_levels:\n",
    "            success_rate = origin_results[origin][origin_results[origin]['discount_pct'] == discount]['success_rate'].iloc[0]\n",
    "            origin_row.append(success_rate)\n",
    "        origin_heatmap_data.append(origin_row)\n",
    "    \n",
    "    im = plt.imshow(origin_heatmap_data, cmap='RdYlGn', aspect='auto', vmin=0, vmax=100)\n",
    "    plt.colorbar(im, label='Success Rate (%)')\n",
    "    plt.xticks(range(len(discount_levels)), discount_levels)\n",
    "    plt.yticks(range(len(origin_results)), list(origin_results.keys()))\n",
    "    plt.xlabel('Discount (%)', fontsize=12)\n",
    "    plt.ylabel('Origin', fontsize=12)\n",
    "    plt.title('Success Rate Heatmap by Origin', fontweight='bold', fontsize=14)\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(len(origin_results)):\n",
    "        for j in range(len(discount_levels)):\n",
    "            text = plt.text(j, i, f'{origin_heatmap_data[i][j]:.0f}%',\n",
    "                           ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 9: Optimal discount summary\n",
    "plt.figure(figsize=(14, 8))\n",
    "if channel_results and origin_results:\n",
    "    # Find optimal discount for each segment (minimum discount for 75% success)\n",
    "    optimal_discounts = []\n",
    "    segment_labels = []\n",
    "    colors = []\n",
    "    \n",
    "    # Add aggregate\n",
    "    if 'aggregate_results' in locals():\n",
    "        optimal_agg = aggregate_results[aggregate_results['success_rate'] >= 75]['discount_pct'].min()\n",
    "        optimal_discounts.append(optimal_agg if not pd.isna(optimal_agg) else 100)\n",
    "        segment_labels.append('Aggregate')\n",
    "        colors.append('darkblue')\n",
    "    \n",
    "    # Add channels\n",
    "    for channel, results in channel_results.items():\n",
    "        optimal_disc = results[results['success_rate'] >= 75]['discount_pct'].min()\n",
    "        optimal_discounts.append(optimal_disc if not pd.isna(optimal_disc) else 100)\n",
    "        segment_labels.append(f'Ch-{channel}')\n",
    "        colors.append('orange')\n",
    "    \n",
    "    # Add origins\n",
    "    for origin, results in origin_results.items():\n",
    "        optimal_disc = results[results['success_rate'] >= 75]['discount_pct'].min()\n",
    "        optimal_discounts.append(optimal_disc if not pd.isna(optimal_disc) else 100)\n",
    "        segment_labels.append(f'Or-{origin}')\n",
    "        colors.append('green')\n",
    "    \n",
    "    bars = plt.bar(range(len(optimal_discounts)), optimal_discounts, \n",
    "                   color=colors, alpha=0.8)\n",
    "    plt.xticks(range(len(segment_labels)), segment_labels, rotation=45, ha='right')\n",
    "    plt.ylabel('Optimal Discount (%)', fontsize=12)\n",
    "    plt.title('Optimal Discount Required for 75% Success Rate', fontweight='bold', fontsize=14)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.annotate(f'{height:.0f}%',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=11)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9. Detailed analysis summary\n",
    "print(\"\\n9. DETAILED PROGRESSIVE DISCOUNT ANALYSIS SUMMARY\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if 'aggregate_results' in locals():\n",
    "    print(\"ðŸ“Š AGGREGATE RESULTS SUMMARY:\")\n",
    "    \n",
    "    # Key milestone analysis\n",
    "    milestones = [10, 25, 50, 75, 90]\n",
    "    milestone_discounts = {}\n",
    "    \n",
    "    for milestone in milestones:\n",
    "        milestone_row = aggregate_results[aggregate_results['success_rate'] >= milestone]\n",
    "        if len(milestone_row) > 0:\n",
    "            min_discount = milestone_row['discount_pct'].min()\n",
    "            milestone_discounts[milestone] = min_discount\n",
    "            print(f\"   {milestone}% success rate achieved at: {min_discount}% discount\")\n",
    "        else:\n",
    "            print(f\"   {milestone}% success rate: Not achieved within 100% discount\")\n",
    "    \n",
    "    # Display key data points\n",
    "    print(f\"\\nðŸ“‹ KEY DISCOUNT LEVELS:\")\n",
    "    key_levels = [0, 10, 20, 30, 50, 75, 100]\n",
    "    for level in key_levels:\n",
    "        if level in aggregate_results['discount_pct'].values:\n",
    "            row = aggregate_results[aggregate_results['discount_pct'] == level].iloc[0]\n",
    "            print(f\"   {level:3d}% discount: {row['success_rate']:5.1f}% success, {row['avg_churn_risk']*100:5.1f}% avg risk\")\n",
    "\n",
    "# Channel-specific insights\n",
    "if channel_results:\n",
    "    print(f\"\\nðŸ“Š CHANNEL-SPECIFIC INSIGHTS:\")\n",
    "    for channel, results in channel_results.items():\n",
    "        success_75_row = results[results['success_rate'] >= 75]\n",
    "        if len(success_75_row) > 0:\n",
    "            optimal_discount = success_75_row['discount_pct'].min()\n",
    "            final_risk = success_75_row.iloc[0]['avg_churn_risk'] * 100\n",
    "            print(f\"   {channel}: {optimal_discount}% discount needed for 75% success (avg risk: {final_risk:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"   {channel}: 75% success not achieved within 100% discount\")\n",
    "\n",
    "# Origin-specific insights\n",
    "if origin_results:\n",
    "    print(f\"\\nðŸ“Š ORIGIN-SPECIFIC INSIGHTS:\")\n",
    "    for origin, results in origin_results.items():\n",
    "        success_75_row = results[results['success_rate'] >= 75]\n",
    "        if len(success_75_row) > 0:\n",
    "            optimal_discount = success_75_row['discount_pct'].min()\n",
    "            final_risk = success_75_row.iloc[0]['avg_churn_risk'] * 100\n",
    "            print(f\"   {origin}: {optimal_discount}% discount needed for 75% success (avg risk: {final_risk:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"   {origin}: 75% success not achieved within 100% discount\")\n",
    "\n",
    "# 10. Business recommendations\n",
    "print(\"\\n10. BUSINESS RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"ðŸ’¡ STRATEGIC DISCOUNT FRAMEWORK:\")\n",
    "print(\"   â€¢ Implement tiered discount strategy based on segment analysis\")\n",
    "print(\"   â€¢ Start with minimum effective discount levels identified above\")\n",
    "print(\"   â€¢ Monitor actual churn reduction vs. predicted values\")\n",
    "print(\"   â€¢ Adjust discount levels based on segment responsiveness\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ IMPLEMENTATION PRIORITIES:\")\n",
    "print(\"   1. Focus on segments requiring lower discounts for high success rates\")\n",
    "print(\"   2. Develop automated triggers at 20% churn risk threshold\")\n",
    "print(\"   3. Create personalized discount offers by channel/origin combination\")\n",
    "print(\"   4. Track revenue impact vs. retention benefits\")\n",
    "\n",
    "print(f\"\\nðŸ“Š MONITORING FRAMEWORK:\")\n",
    "print(\"   â€¢ Weekly tracking of discount effectiveness by segment\")\n",
    "print(\"   â€¢ Monthly analysis of actual vs. predicted churn reduction\")\n",
    "print(\"   â€¢ Quarterly optimization of discount levels and thresholds\")\n",
    "print(\"   â€¢ Annual model recalibration with updated data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROGRESSIVE DISCOUNT ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ… Progressive discount analysis completed with comprehensive insights.\n",
    "\n",
    "ðŸŽ¯ KEY FINDINGS:\n",
    "   â€¢ Discount effectiveness varies significantly by customer segment\n",
    "   â€¢ Progressive analysis reveals minimum intervention levels needed\n",
    "   â€¢ Some segments achieve high success rates with moderate discounts\n",
    "   â€¢ Individual visualizations provide clear insights for decision-making\n",
    "\n",
    "ðŸ“Š READY FOR TARGETED RETENTION STRATEGY IMPLEMENTATION\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f27c122",
   "metadata": {},
   "source": [
    "### 10.4 TOP 100 CUSTOMERS MOST LIKELY TO CHURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1ecc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 100 CUSTOMERS MOST LIKELY TO CHURN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Get the winning model and active customers\n",
    "print(\"\\n1. PREPARING DATA AND MODEL\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get champion model\n",
    "if 'champion_pipeline' in locals() and champion_pipeline is not None:\n",
    "    winning_model = champion_pipeline\n",
    "    print(f\"âœ… Using champion model for churn risk predictions\")\n",
    "else:\n",
    "    # Use best available model\n",
    "    print(\"âš ï¸  Using fallback model\")\n",
    "    winning_model = list(advanced_pipes_optimal.values())[0] if 'advanced_pipes_optimal' in locals() else baseline_pipes[list(baseline_pipes.keys())[0]]\n",
    "\n",
    "best_model_name = winning_model.steps[-1][0] if hasattr(winning_model, 'steps') else type(winning_model).__name__\n",
    "print(f\"âœ… Model pipeline retrieved successfully!\")\n",
    "\n",
    "# 2. Filter to active customers only (churn != 1)\n",
    "print(\"\\n2. FILTERING TO ACTIVE CUSTOMERS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get all customers who have not churned (churn != 1)\n",
    "active_customers = df[df[target_col] != 1].copy()\n",
    "print(f\"ðŸ“Š Active customers (churn != 1): {len(active_customers):,}\")\n",
    "print(f\"ðŸ“Š Total customers in dataset: {len(df):,}\")\n",
    "print(f\"ðŸ“Š Active customer percentage: {len(active_customers)/len(df)*100:.1f}%\")\n",
    "\n",
    "# 3. Prepare features and generate predictions\n",
    "print(\"\\n3. GENERATING CHURN PREDICTIONS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Prepare features (remove target column)\n",
    "X_active = active_customers.drop(columns=[target_col])\n",
    "\n",
    "# Generate churn probabilities using the winning model\n",
    "churn_probabilities = winning_model.predict_proba(X_active)[:, 1]\n",
    "print(f\"âœ… Generated predictions for {len(churn_probabilities):,} active customers\")\n",
    "print(f\"   Churn probability range: {churn_probabilities.min():.3f} to {churn_probabilities.max():.3f}\")\n",
    "print(f\"   Mean churn probability: {churn_probabilities.mean():.3f}\")\n",
    "\n",
    "# Add probabilities to the dataframe\n",
    "active_customers['churn_probability'] = churn_probabilities\n",
    "\n",
    "# 4. Extract customer ID, channel_sales class, and origin_up_ class\n",
    "print(\"\\n4. EXTRACTING CUSTOMER INFORMATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create customer ID if not present (using index)\n",
    "if 'customer_id' not in active_customers.columns:\n",
    "    active_customers['customer_id'] = active_customers.index\n",
    "    print(\"ðŸ“‹ Created customer_id from index\")\n",
    "\n",
    "# Find channel_sales columns\n",
    "channel_sales_cols = [col for col in active_customers.columns if col.startswith('channel_sales_')]\n",
    "print(f\"ðŸ“Š Found {len(channel_sales_cols)} channel_sales columns\")\n",
    "\n",
    "# Extract channel_sales class\n",
    "if channel_sales_cols:\n",
    "    # Get the channel class with highest value (one-hot encoded)\n",
    "    channel_values = active_customers[channel_sales_cols]\n",
    "    active_customers['channel_sales_class'] = channel_values.idxmax(axis=1).str.replace('channel_sales_', '')\n",
    "    print(f\"âœ… Channel sales classes extracted: {active_customers['channel_sales_class'].unique()}\")\n",
    "else:\n",
    "    print(\"âš ï¸  No channel_sales columns found - setting to 'Unknown'\")\n",
    "    active_customers['channel_sales_class'] = 'Unknown'\n",
    "\n",
    "# Find origin_up_ columns  \n",
    "origin_up_cols = [col for col in active_customers.columns if col.startswith('origin_up_')]\n",
    "print(f\"ðŸ“Š Found {len(origin_up_cols)} origin_up_ columns\")\n",
    "\n",
    "# Extract origin_up_ class\n",
    "if origin_up_cols:\n",
    "    # Get the origin class with highest value (one-hot encoded)\n",
    "    origin_values = active_customers[origin_up_cols]\n",
    "    active_customers['origin_up_class'] = origin_values.idxmax(axis=1).str.replace('origin_up_', '')\n",
    "    print(f\"âœ… Origin up classes extracted: {active_customers['origin_up_class'].unique()}\")\n",
    "else:\n",
    "    print(\"âš ï¸  No origin_up_ columns found - setting to 'Unknown'\")\n",
    "    active_customers['origin_up_class'] = 'Unknown'\n",
    "\n",
    "# 5. Get Top 100 customers most likely to churn\n",
    "print(\"\\n5. SELECTING TOP 100 CUSTOMERS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Sort by churn probability (descending) and get top 100\n",
    "top_100_customers = active_customers.nlargest(100, 'churn_probability').copy()\n",
    "\n",
    "print(f\"ðŸ“ˆ Top 100 customers selected\")\n",
    "print(f\"   Highest churn probability: {top_100_customers['churn_probability'].max():.3f}\")\n",
    "print(f\"   Lowest churn probability in top 100: {top_100_customers['churn_probability'].min():.3f}\")\n",
    "print(f\"   Average churn probability: {top_100_customers['churn_probability'].mean():.3f}\")\n",
    "\n",
    "# 6. Create the final table\n",
    "print(\"\\n6. CREATING FINAL TABLE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create the final table with required columns\n",
    "final_table = top_100_customers[['customer_id', 'channel_sales_class', 'origin_up_class', 'churn_probability']].copy()\n",
    "\n",
    "# Add rank column\n",
    "final_table['rank'] = range(1, 101)\n",
    "\n",
    "# Convert probability to percentage for readability\n",
    "final_table['churn_probability_pct'] = (final_table['churn_probability'] * 100).round(2)\n",
    "\n",
    "# Reorder columns for final display\n",
    "final_table = final_table[['rank', 'customer_id', 'channel_sales_class', 'origin_up_class', 'churn_probability', 'churn_probability_pct']]\n",
    "\n",
    "# Rename columns for clarity\n",
    "final_table.columns = ['Rank', 'Customer_ID', 'Channel_Sales_Class', 'Origin_Up_Class', 'Churn_Probability', 'Churn_Probability_%']\n",
    "\n",
    "# 7. Display the complete table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“‹ TOP 100 CUSTOMERS MOST LIKELY TO CHURN (COMPLETE TABLE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"ðŸŽ¯ MODEL USED:\", best_model_name)\n",
    "print(\"ðŸ“Š PREDICTION SCOPE: All active customers\")\n",
    "print(\"ðŸ‘¥ CUSTOMER POOL: Active customers only (churn != 1)\")\n",
    "print(\"ðŸ“ˆ SORTED BY: Churn probability (highest to lowest)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Display the complete table\n",
    "display(final_table)\n",
    "\n",
    "# 8. Summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“Š SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ CHURN RISK DISTRIBUTION:\")\n",
    "print(f\"   â€¢ Extremely High Risk (>80%): {(final_table['Churn_Probability_%'] > 80).sum()} customers\")\n",
    "print(f\"   â€¢ Very High Risk (60-80%): {((final_table['Churn_Probability_%'] > 60) & (final_table['Churn_Probability_%'] <= 80)).sum()} customers\")\n",
    "print(f\"   â€¢ High Risk (40-60%): {((final_table['Churn_Probability_%'] > 40) & (final_table['Churn_Probability_%'] <= 60)).sum()} customers\")\n",
    "print(f\"   â€¢ Moderate Risk (20-40%): {((final_table['Churn_Probability_%'] > 20) & (final_table['Churn_Probability_%'] <= 40)).sum()} customers\")\n",
    "print(f\"   â€¢ Lower Risk (<20%): {(final_table['Churn_Probability_%'] <= 20).sum()} customers\")\n",
    "\n",
    "print(f\"\\nðŸ¢ CHANNEL SALES CLASS DISTRIBUTION:\")\n",
    "channel_dist = final_table['Channel_Sales_Class'].value_counts()\n",
    "for channel, count in channel_dist.items():\n",
    "    avg_prob = final_table[final_table['Channel_Sales_Class'] == channel]['Churn_Probability_%'].mean()\n",
    "    print(f\"   â€¢ {channel}: {count} customers (avg risk: {avg_prob:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ ORIGIN UP CLASS DISTRIBUTION:\")\n",
    "origin_dist = final_table['Origin_Up_Class'].value_counts()\n",
    "for origin, count in origin_dist.items():\n",
    "    avg_prob = final_table[final_table['Origin_Up_Class'] == origin]['Churn_Probability_%'].mean()\n",
    "    print(f\"   â€¢ {origin}: {count} customers (avg risk: {avg_prob:.1f}%)\")\n",
    "\n",
    "# 9. Business recommendations\n",
    "print(f\"\\nðŸ’¡ BUSINESS RECOMMENDATIONS:\")\n",
    "print(\"   â€¢ Focus immediate retention efforts on top 20 customers with highest churn risk\")\n",
    "print(\"   â€¢ Develop targeted campaigns for specific channel-origin combinations\")\n",
    "print(\"   â€¢ Monitor these 100 customers closely with enhanced customer service\")\n",
    "print(\"   â€¢ Consider personalized offers or proactive customer outreach\")\n",
    "print(\"   â€¢ Track actual churn rates to validate model performance\")\n",
    "print(\"   â€¢ Implement predictive interventions based on risk scores\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… TOP 100 CUSTOMER CHURN RISK ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 10. Export-ready summary\n",
    "print(\"\\n10. EXPORT-READY SUMMARY\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create a clean export version\n",
    "export_table = final_table.copy()\n",
    "export_table['Action_Required'] = export_table['Churn_Probability_%'].apply(\n",
    "    lambda x: 'URGENT' if x > 80 else 'HIGH' if x > 60 else 'MEDIUM' if x > 40 else 'MONITOR'\n",
    ")\n",
    "\n",
    "print(\"ðŸ“‹ Export-ready table with action priorities:\")\n",
    "print(\"   â€¢ URGENT: Immediate intervention required\")\n",
    "print(\"   â€¢ HIGH: Proactive retention campaign\")\n",
    "print(\"   â€¢ MEDIUM: Enhanced monitoring and engagement\")\n",
    "print(\"   â€¢ MONITOR: Regular check-ins and surveys\")\n",
    "\n",
    "print(f\"\\nâœ… Table ready for export to CRM/Customer Service teams\")\n",
    "print(f\"   Columns: {list(export_table.columns)}\")\n",
    "print(f\"   Records: {len(export_table)} customers\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf02507",
   "metadata": {},
   "source": [
    "#### 10.4.1 Updated Top 100 Churn Risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEBUGGING PRICE SENSITIVITY - IDENTIFYING ACTUAL PRICE COLUMNS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. First, let's see what price-related columns actually exist\n",
    "print(\"\\n1. IDENTIFYING ACTUAL PRICE COLUMNS IN DATASET\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Look for all columns that might contain pricing information\n",
    "price_keywords = ['price', 'rate', 'cost', 'tariff', 'peak', 'off', 'energy', 'gas', 'bill', 'amount']\n",
    "potential_price_cols = []\n",
    "\n",
    "for keyword in price_keywords:\n",
    "    matching_cols = [col for col in df.columns if keyword.lower() in col.lower()]\n",
    "    if matching_cols:\n",
    "        potential_price_cols.extend(matching_cols)\n",
    "\n",
    "# Remove duplicates\n",
    "potential_price_cols = list(set(potential_price_cols))\n",
    "\n",
    "print(f\"Found {len(potential_price_cols)} potential price-related columns:\")\n",
    "for col in potential_price_cols:\n",
    "    print(f\"â€¢ {col}\")\n",
    "\n",
    "# Show statistics for these columns\n",
    "if potential_price_cols:\n",
    "    print(\"\\nðŸ“Š PRICE COLUMN STATISTICS:\")\n",
    "    price_stats = df[potential_price_cols].describe()\n",
    "    display(price_stats.round(4))\n",
    "    \n",
    "    # Check correlation with churn\n",
    "    print(\"\\nðŸ“Š CORRELATION WITH CHURN:\")\n",
    "    correlations = {}\n",
    "    for col in potential_price_cols:\n",
    "        if df[col].dtype in ['int64', 'float64']:  # Only numeric columns\n",
    "            corr = df[col].corr(df[target_col])\n",
    "            correlations[col] = corr\n",
    "            print(f\"   {col}: {corr:.4f}\")\n",
    "    \n",
    "    # Sort by absolute correlation\n",
    "    sorted_correlations = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "    print(f\"\\nðŸŽ¯ TOP PRICE COLUMNS BY CHURN CORRELATION:\")\n",
    "    for col, corr in sorted_correlations[:5]:\n",
    "        print(f\"   {col}: {corr:.4f}\")\n",
    "\n",
    "# 2. Let's specifically look for the columns mentioned in the previous analysis\n",
    "print(\"\\n2. CHECKING SPECIFIC PRICE COLUMNS FROM PREVIOUS ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "target_price_cols = ['price_peak_var_last', 'price_off_peak_var_last']\n",
    "found_target_cols = []\n",
    "\n",
    "for col in target_price_cols:\n",
    "    if col in df.columns:\n",
    "        found_target_cols.append(col)\n",
    "        print(f\"âœ… Found: {col}\")\n",
    "        \n",
    "        # Show detailed stats\n",
    "        col_stats = df[col].describe()\n",
    "        print(f\"   Stats: Mean={col_stats['mean']:.4f}, Std={col_stats['std']:.4f}, Min={col_stats['min']:.4f}, Max={col_stats['max']:.4f}\")\n",
    "        \n",
    "        # Check for variation\n",
    "        unique_values = df[col].nunique()\n",
    "        print(f\"   Unique values: {unique_values}\")\n",
    "        \n",
    "        if unique_values < 10:\n",
    "            print(f\"   Value counts:\")\n",
    "            print(df[col].value_counts().head())\n",
    "    else:\n",
    "        print(f\"âŒ Not found: {col}\")\n",
    "\n",
    "# 3. Test actual price sensitivity with a more dramatic price change\n",
    "print(\"\\n3. TESTING PRICE SENSITIVITY WITH DRAMATIC PRICE CHANGES\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if found_target_cols:\n",
    "    # Use the most variable price column\n",
    "    test_price_col = found_target_cols[0]\n",
    "    print(f\"Using {test_price_col} for testing\")\n",
    "    \n",
    "    # Get a sample of active customers\n",
    "    test_sample = active_customers.head(1000).copy()\n",
    "    original_predictions = winning_model.predict_proba(test_sample.drop(columns=[target_col]))[:, 1]\n",
    "    \n",
    "    print(f\"Original predictions: Mean={original_predictions.mean():.4f}, Std={original_predictions.std():.4f}\")\n",
    "    \n",
    "    # Test with 50% price increase\n",
    "    test_sample_high = test_sample.copy()\n",
    "    original_price = test_sample_high[test_price_col].mean()\n",
    "    test_sample_high[test_price_col] = test_sample_high[test_price_col] * 1.5  # 50% increase\n",
    "    \n",
    "    high_price_predictions = winning_model.predict_proba(test_sample_high.drop(columns=[target_col]))[:, 1]\n",
    "    \n",
    "    print(f\"High price predictions: Mean={high_price_predictions.mean():.4f}, Std={high_price_predictions.std():.4f}\")\n",
    "    print(f\"Change with 50% price increase: {high_price_predictions.mean() - original_predictions.mean():+.4f}\")\n",
    "    \n",
    "    # Test with 50% price decrease\n",
    "    test_sample_low = test_sample.copy()\n",
    "    test_sample_low[test_price_col] = test_sample_low[test_price_col] * 0.5  # 50% decrease\n",
    "    \n",
    "    low_price_predictions = winning_model.predict_proba(test_sample_low.drop(columns=[target_col]))[:, 1]\n",
    "    \n",
    "    print(f\"Low price predictions: Mean={low_price_predictions.mean():.4f}, Std={low_price_predictions.std():.4f}\")\n",
    "    print(f\"Change with 50% price decrease: {low_price_predictions.mean() - original_predictions.mean():+.4f}\")\n",
    "    \n",
    "    # Statistical significance test\n",
    "    from scipy import stats\n",
    "    \n",
    "    # Test if changes are statistically significant\n",
    "    _, p_value_high = stats.ttest_rel(original_predictions, high_price_predictions)\n",
    "    _, p_value_low = stats.ttest_rel(original_predictions, low_price_predictions)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š STATISTICAL SIGNIFICANCE:\")\n",
    "    print(f\"   High price change p-value: {p_value_high:.6f}\")\n",
    "    print(f\"   Low price change p-value: {p_value_low:.6f}\")\n",
    "    print(f\"   Significant if p < 0.05\")\n",
    "\n",
    "# 4. Alternative approach: Create synthetic price sensitivity\n",
    "print(\"\\n4. ALTERNATIVE APPROACH - FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Let's check if price columns are even important in the model\n",
    "try:\n",
    "    # Try to get feature importance from the winning model\n",
    "    if hasattr(winning_model, 'named_steps'):\n",
    "        # Get the classifier step\n",
    "        if 'clf' in winning_model.named_steps:\n",
    "            classifier = winning_model.named_steps['clf']\n",
    "        else:\n",
    "            # Look for classifier in other steps\n",
    "            for step_name, step in winning_model.named_steps.items():\n",
    "                if hasattr(step, 'feature_importances_') or hasattr(step, 'coef_'):\n",
    "                    classifier = step\n",
    "                    break\n",
    "        \n",
    "        # Get feature names after preprocessing\n",
    "        if 'pre' in winning_model.named_steps:\n",
    "            preprocessor = winning_model.named_steps['pre']\n",
    "            # Transform a small sample to get feature names\n",
    "            sample_transformed = preprocessor.transform(X_test.head(5))\n",
    "            \n",
    "            # Try to get feature names\n",
    "            feature_names = []\n",
    "            if hasattr(preprocessor, 'get_feature_names_out'):\n",
    "                try:\n",
    "                    feature_names = preprocessor.get_feature_names_out()\n",
    "                except:\n",
    "                    print(\"Could not get feature names from preprocessor\")\n",
    "            \n",
    "            if len(feature_names) == 0:\n",
    "                feature_names = [f\"feature_{i}\" for i in range(sample_transformed.shape[1])]\n",
    "            \n",
    "            # Get importance\n",
    "            if hasattr(classifier, 'feature_importances_'):\n",
    "                importances = classifier.feature_importances_\n",
    "                importance_type = \"Feature Importance\"\n",
    "            elif hasattr(classifier, 'coef_'):\n",
    "                importances = np.abs(classifier.coef_[0])\n",
    "                importance_type = \"Coefficient Magnitude\"\n",
    "            else:\n",
    "                importances = None\n",
    "            \n",
    "            if importances is not None:\n",
    "                # Create importance dataframe\n",
    "                importance_df = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': importances\n",
    "                }).sort_values('importance', ascending=False)\n",
    "                \n",
    "                print(f\"âœ… Extracted {importance_type}\")\n",
    "                print(f\"\\nðŸ” TOP 20 MOST IMPORTANT FEATURES:\")\n",
    "                display(importance_df.head(20))\n",
    "                \n",
    "                # Look for price-related features in top features\n",
    "                print(f\"\\nðŸ” PRICE-RELATED FEATURES IN TOP 50:\")\n",
    "                top_50 = importance_df.head(50)\n",
    "                price_features = []\n",
    "                for _, row in top_50.iterrows():\n",
    "                    feature_name = row['feature']\n",
    "                    if any(keyword in feature_name.lower() for keyword in ['price', 'cost', 'rate', 'peak', 'off']):\n",
    "                        price_features.append((feature_name, row['importance']))\n",
    "                        print(f\"   {feature_name}: {row['importance']:.6f}\")\n",
    "                \n",
    "                if not price_features:\n",
    "                    print(\"   âŒ No price-related features found in top 50!\")\n",
    "                    print(\"   This explains why price changes don't affect churn predictions.\")\n",
    "                else:\n",
    "                    print(f\"   âœ… Found {len(price_features)} price-related features\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not extract feature importance: {e}\")\n",
    "\n",
    "# 5. Let's create a more realistic price sensitivity test\n",
    "print(\"\\n5. CREATING REALISTIC PRICE SENSITIVITY SCENARIO\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if potential_price_cols:\n",
    "    # Select the most variable price column\n",
    "    most_variable_col = None\n",
    "    max_std = 0\n",
    "    \n",
    "    for col in potential_price_cols:\n",
    "        if df[col].dtype in ['int64', 'float64']:\n",
    "            col_std = df[col].std()\n",
    "            if col_std > max_std:\n",
    "                max_std = col_std\n",
    "                most_variable_col = col\n",
    "    \n",
    "    if most_variable_col:\n",
    "        print(f\"Using most variable price column: {most_variable_col}\")\n",
    "        print(f\"Standard deviation: {max_std:.4f}\")\n",
    "        \n",
    "        # Create more realistic price scenarios\n",
    "        scenarios = {\n",
    "            'baseline': 1.0,\n",
    "            'small_increase': 1.1,    # 10% increase\n",
    "            'medium_increase': 1.25,  # 25% increase\n",
    "            'large_increase': 1.5,    # 50% increase\n",
    "            'small_decrease': 0.9,    # 10% decrease\n",
    "            'medium_decrease': 0.75,  # 25% decrease\n",
    "            'large_decrease': 0.5     # 50% decrease\n",
    "        }\n",
    "        \n",
    "        # Test each scenario\n",
    "        scenario_results = {}\n",
    "        base_sample = active_customers.head(2000).copy()  # Larger sample\n",
    "        \n",
    "        for scenario_name, multiplier in scenarios.items():\n",
    "            test_sample = base_sample.copy()\n",
    "            test_sample[most_variable_col] = test_sample[most_variable_col] * multiplier\n",
    "            \n",
    "            # Predict\n",
    "            predictions = winning_model.predict_proba(test_sample.drop(columns=[target_col]))[:, 1]\n",
    "            \n",
    "            scenario_results[scenario_name] = {\n",
    "                'mean_churn_prob': predictions.mean(),\n",
    "                'std_churn_prob': predictions.std(),\n",
    "                'multiplier': multiplier\n",
    "            }\n",
    "            \n",
    "            print(f\"{scenario_name:15}: {predictions.mean():.6f} (Â±{predictions.std():.6f})\")\n",
    "        \n",
    "        # Calculate changes from baseline\n",
    "        baseline_mean = scenario_results['baseline']['mean_churn_prob']\n",
    "        \n",
    "        print(f\"\\nðŸ“Š CHANGES FROM BASELINE:\")\n",
    "        for scenario_name, results in scenario_results.items():\n",
    "            if scenario_name != 'baseline':\n",
    "                change = results['mean_churn_prob'] - baseline_mean\n",
    "                change_pct = (change / baseline_mean) * 100\n",
    "                print(f\"{scenario_name:15}: {change:+.6f} ({change_pct:+.3f}%)\")\n",
    "\n",
    "print(\"\\n6. CONCLUSIONS AND NEXT STEPS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\"\"\n",
    "ðŸ” ANALYSIS CONCLUSIONS:\n",
    "\n",
    "1. LIMITED PRICE SENSITIVITY: The model may not be strongly sensitive to price changes because:\n",
    "   â€¢ Price columns may not be among the top predictive features\n",
    "   â€¢ Current price variations in the data might be limited\n",
    "   â€¢ The model may be more driven by other factors (usage patterns, demographics, etc.)\n",
    "\n",
    "2. POSSIBLE REASONS FOR UNCHANGED CHURN RATES:\n",
    "   â€¢ Price features have low importance in the trained model\n",
    "   â€¢ Price ranges tested may not be wide enough to trigger significant changes\n",
    "   â€¢ Other features may dominate the prediction\n",
    "\n",
    "3. ALTERNATIVE APPROACHES:\n",
    "   â€¢ Focus on features that ARE important for churn prediction\n",
    "   â€¢ Create retention strategies based on high-importance features\n",
    "   â€¢ Consider retraining model with expanded price variation data\n",
    "   â€¢ Implement rule-based pricing adjustments alongside ML predictions\n",
    "\n",
    "ðŸ“‹ RECOMMENDED NEXT STEPS:\n",
    "   â€¢ Use feature importance analysis to identify key churn drivers\n",
    "   â€¢ Develop retention strategies based on actual important features\n",
    "   â€¢ Consider A/B testing with real customers to validate price sensitivity\n",
    "   â€¢ Supplement ML model with business rules for pricing decisions\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb525408",
   "metadata": {},
   "source": [
    "### 10.5 Correlation between subscribed power and consumption \n",
    "Is there a correlation between subscribed power and the consumption behavior of customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.1 Comprehensive Summary of Data Analysis and Modeling Results\n",
    "# This cell provides a step-by-step summary of all major tables and visualizations from the notebook,\n",
    "# with descriptions of the data, methods, and their importance for each output.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def print_section_header(title, description):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(title)\n",
    "    print(\"=\"*80)\n",
    "    print(description)\n",
    "    print(\"-\"*80)\n",
    "\n",
    "# Section 2: Data Overview\n",
    "def section2_data_overview():\n",
    "    print_section_header(\n",
    "        \"Section 2: Data Overview\",\n",
    "        \"This table displays the first five rows of the cleaned dataset (df), showing all columns and sample values. \"\n",
    "        \"It helps verify data import, structure, and provides a quick sense of the variables available for analysis.\"\n",
    "    )\n",
    "    try:\n",
    "        print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "        display(df.head())\n",
    "    except Exception as e:\n",
    "        print(\"Error displaying data overview:\", e)\n",
    "\n",
    "# Section 3: Missing Values Analysis\n",
    "def section3_missing_values():\n",
    "    print_section_header(\n",
    "        \"Section 3: Missing Values Analysis\",\n",
    "        \"This bar chart and table show the count of missing values for each column in the dataset. \"\n",
    "        \"The method uses pandas isnull().sum() to identify missing data, which is critical for deciding on imputation or exclusion strategies.\"\n",
    "    )\n",
    "    try:\n",
    "        missing = df.isnull().sum()\n",
    "        missing = missing[missing > 0]\n",
    "        if not missing.empty:\n",
    "            print(missing.sort_values(ascending=False))\n",
    "            plt.figure(figsize=(8,3))\n",
    "            plt.bar(missing.index, missing.values, color='#E15759')\n",
    "            plt.title(\"Missing Values per Column\")\n",
    "            plt.ylabel(\"Missing Count\")\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"No missing values found.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error displaying missing values:\", e)\n",
    "\n",
    "# Section 4: Churn Distribution\n",
    "def section4_churn_distribution():\n",
    "    print_section_header(\n",
    "        \"Section 4: Churn Distribution\",\n",
    "        \"This pie chart and table summarize the distribution of the target variable 'churn'. \"\n",
    "        \"It uses value_counts() and matplotlib to visualize class balance, which is important for model selection and evaluation.\"\n",
    "    )\n",
    "    try:\n",
    "        counts = df['churn'].value_counts()\n",
    "        labels = [\"No Churn\" if i == 0 else \"Churn\" for i in counts.index]\n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.pie(counts, labels=labels, autopct='%1.1f%%', colors=['#59A14F', '#E15759'])\n",
    "        plt.title(\"Churn Distribution\")\n",
    "        plt.show()\n",
    "        print(counts)\n",
    "    except Exception as e:\n",
    "        print(\"Error displaying churn distribution:\", e)\n",
    "\n",
    "# Section 5: Feature Types and Encoding\n",
    "def section5_feature_types():\n",
    "    print_section_header(\n",
    "        \"Section 5: Feature Types and Encoding\",\n",
    "        \"This output lists all categorical and numerical columns in the dataset, using pandas select_dtypes. \"\n",
    "        \"Understanding feature types is essential for preprocessing, encoding, and model compatibility.\"\n",
    "    )\n",
    "    try:\n",
    "        cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "        num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        print(f\"Categorical columns: {list(cat_cols)}\")\n",
    "        print(f\"Numerical columns: {list(num_cols)}\")\n",
    "        print(f\"Total categorical: {len(cat_cols)}, Total numerical: {len(num_cols)}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error displaying feature types:\", e)\n",
    "\n",
    "# Section 6: Correlation Matrix\n",
    "def section6_correlation_matrix():\n",
    "    print_section_header(\n",
    "        \"Section 6: Correlation Matrix\",\n",
    "        \"This heatmap visualizes the pairwise Pearson correlations between all numerical features. \"\n",
    "        \"It helps identify multicollinearity and relationships that may impact model performance.\"\n",
    "    )\n",
    "    try:\n",
    "        num_df = df.select_dtypes(include=[np.number])\n",
    "        corr = num_df.corr()\n",
    "        plt.figure(figsize=(6,5))\n",
    "        sns.heatmap(corr, cmap='coolwarm', center=0, annot=False)\n",
    "        plt.title(\"Correlation Matrix\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Error displaying correlation matrix:\", e)\n",
    "\n",
    "# Section 7: High Correlation Pairs\n",
    "def section7_high_corr_pairs():\n",
    "    print_section_header(\n",
    "        \"Section 7: Highly Correlated Feature Pairs\",\n",
    "        \"This table lists all pairs of numerical features with absolute correlation above 0.8. \"\n",
    "        \"Identifying these pairs is important for feature selection and reducing redundancy.\"\n",
    "    )\n",
    "    try:\n",
    "        num_df = df.select_dtypes(include=[np.number])\n",
    "        corr = num_df.corr().abs()\n",
    "        pairs = []\n",
    "        for i in range(len(corr.columns)):\n",
    "            for j in range(i):\n",
    "                if corr.iloc[i, j] > 0.8 and corr.columns[i] != corr.columns[j]:\n",
    "                    pairs.append((corr.columns[i], corr.columns[j], corr.iloc[i, j]))\n",
    "        if pairs:\n",
    "            print(pd.DataFrame(pairs, columns=['Feature 1', 'Feature 2', 'Correlation']))\n",
    "        else:\n",
    "            print(\"No highly correlated pairs found.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error displaying high correlation pairs:\", e)\n",
    "\n",
    "# Section 8: Class Imbalance Before/After SMOTE\n",
    "def section8_class_imbalance():\n",
    "    print_section_header(\n",
    "        \"Section 8: Class Imbalance Before/After SMOTE\",\n",
    "        \"These bar charts show the distribution of the target class before and after applying SMOTE (Synthetic Minority Over-sampling Technique). \"\n",
    "        \"This step is crucial for addressing class imbalance, which can bias model training.\"\n",
    "    )\n",
    "    try:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(8,3))\n",
    "        y_train.value_counts().plot(kind='bar', ax=ax[0], color='#4E79A7')\n",
    "        ax[0].set_title('Original')\n",
    "        y_train_smote.value_counts().plot(kind='bar', ax=ax[1], color='#F28E2B')\n",
    "        ax[1].set_title('After SMOTE')\n",
    "        plt.suptitle(\"Class Distribution Before/After SMOTE\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Error displaying class imbalance:\", e)\n",
    "\n",
    "# Section 9: Baseline Model Performance\n",
    "def section9_baseline_performance():\n",
    "    print_section_header(\n",
    "        \"Section 9: Baseline Model Performance\",\n",
    "        \"This table and horizontal bar chart summarize the F1-Weighted scores of baseline models. \"\n",
    "        \"It provides a reference for evaluating the effectiveness of more advanced models.\"\n",
    "    )\n",
    "    try:\n",
    "        print(baseline_results)\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.barh(baseline_results.index, baseline_results['F1_Weighted'], color='#76B7B2')\n",
    "        plt.xlabel(\"F1-Weighted Score\")\n",
    "        plt.title(\"Baseline Model Performance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Error displaying baseline model performance:\", e)\n",
    "\n",
    "# Section 10: Advanced/Ensemble Model Leaderboard\n",
    "def section10_leaderboard():\n",
    "    print_section_header(\n",
    "        \"Section 10: Advanced/Ensemble Model Leaderboard\",\n",
    "        \"This table and bar chart display the top 10 models by F1-Weighted score, including advanced and ensemble approaches. \"\n",
    "        \"It highlights the best-performing models and supports model selection for deployment.\"\n",
    "    )\n",
    "    try:\n",
    "        print(all_results_df.sort_values('F1_Weighted', ascending=False).head(10))\n",
    "        plt.figure(figsize=(7,3))\n",
    "        top10 = all_results_df.sort_values('F1_Weighted', ascending=False).head(10)\n",
    "        plt.bar(top10.index, top10['F1_Weighted'], color='#4E79A7')\n",
    "        plt.title(\"Top 10 Models by F1-Weighted Score\")\n",
    "        plt.ylabel(\"F1-Weighted Score\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Error displaying leaderboard:\", e)\n",
    "\n",
    "# Section 11: Feature Importance (Champion Model)\n",
    "def section11_feature_importance():\n",
    "    print_section_header(\n",
    "        \"Section 11: Feature Importance (Champion Model)\",\n",
    "        \"This table and horizontal bar chart show the top 20 most important features for the champion model, as determined by the model's feature_importance_df. \"\n",
    "        \"Feature importance helps interpret model decisions and guides future feature engineering.\"\n",
    "    )\n",
    "    try:\n",
    "        top20 = feature_importance_df.head(20)\n",
    "        print(top20)\n",
    "        plt.figure(figsize=(7,4))\n",
    "        plt.barh(top20['Feature'], top20['Importance'], color='#F28E2B')\n",
    "        plt.title(\"Top 20 Feature Importances\")\n",
    "        plt.xlabel(\"Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Error displaying feature importance:\", e)\n",
    "\n",
    "# Section 12: Champion Model Leaderboard\n",
    "def section12_champion_leaderboard():\n",
    "    print_section_header(\n",
    "        \"Section 12: Champion Model Leaderboard\",\n",
    "        \"This table displays the final leaderboard of champion models, ranked by churn accuracy. \"\n",
    "        \"The bar chart visualizes the top models' churn accuracy, supporting transparent model selection and reporting.\"\n",
    "    )\n",
    "    try:\n",
    "        print(\"Champion Model Leaderboard:\")\n",
    "        display(churn_leaderboard)\n",
    "        print(\"\\nChampion Model Details:\")\n",
    "        champion = churn_leaderboard.iloc[0]\n",
    "        print(champion)\n",
    "        plt.figure(figsize=(7,3))\n",
    "        plt.bar(churn_leaderboard['Model'], churn_leaderboard['Churn_Accuracy'], color='#59A14F')\n",
    "        plt.title(\"Top Models by Churn Accuracy\")\n",
    "        plt.ylabel(\"Churn Accuracy\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Error displaying champion leaderboard:\", e)\n",
    "\n",
    "# --- Run all summaries in order ---\n",
    "section2_data_overview()\n",
    "section3_missing_values()\n",
    "section4_churn_distribution()\n",
    "section5_feature_types()\n",
    "section6_correlation_matrix()\n",
    "section7_high_corr_pairs()\n",
    "section8_class_imbalance()\n",
    "section9_baseline_performance()\n",
    "section10_leaderboard()\n",
    "section11_feature_importance()\n",
    "section12_champion_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849ef8e7",
   "metadata": {},
   "source": [
    "# 11 Final Summary of Model Development and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39fc8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SECTION & VISUALIZATION SUMMARY FOR CHURN MODELING NOTEBOOK ===\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Data Overview ---\n",
    "print(\"## 1. Data Overview\")\n",
    "print(\"Summary: Loads and previews the raw churn dataset, showing sample records and basic structure.\")\n",
    "\n",
    "print(\"\\nSample Data Table:\")\n",
    "display(df.head(10))\n",
    "print(\"This table shows the first 10 rows of the dataset, providing a quick look at the data's structure and feature types.\")\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "df['churn'].value_counts().plot(kind='bar', color=['lightblue', 'salmon'])\n",
    "plt.title('Churn Distribution')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"This bar chart visualizes the distribution of the target variable (churn), highlighting class imbalance.\")\n",
    "\n",
    "# --- 2. Descriptive Statistics ---\n",
    "print(\"\\n## 2. Descriptive Statistics\")\n",
    "print(\"Summary: Presents descriptive statistics for numerical and categorical features.\")\n",
    "\n",
    "print(\"\\nNumerical Feature Summary:\")\n",
    "display(df.describe().T)\n",
    "print(\"This table summarizes the mean, std, min, and max for each numerical feature.\")\n",
    "\n",
    "print(\"\\nCategorical Feature Summary:\")\n",
    "display(df.select_dtypes(include='object').describe().T)\n",
    "print(\"This table summarizes the count, unique values, and top categories for each categorical feature.\")\n",
    "\n",
    "# --- 3. Missing Values Analysis ---\n",
    "print(\"\\n## 3. Missing Values Analysis\")\n",
    "print(\"Summary: Identifies missing values in the dataset.\")\n",
    "\n",
    "missing = df.isnull().sum()\n",
    "missing_nonzero = missing[missing > 0]\n",
    "if not missing_nonzero.empty:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    missing_nonzero.sort_values(ascending=False).plot(kind='bar', color='orange')\n",
    "    plt.title('Missing Values per Feature')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"This bar chart shows the number of missing values for each feature, helping prioritize data cleaning.\")\n",
    "else:\n",
    "    print(\"No missing values detected in the dataset.\")\n",
    "    print(\"This indicates the dataset is complete and does not require missing value imputation.\")\n",
    "\n",
    "# --- 4. Feature Correlation ---\n",
    "print(\"\\n## 4. Feature Correlation\")\n",
    "print(\"Summary: Examines correlations between numerical features and churn.\")\n",
    "\n",
    "corr = df.corr(numeric_only=True)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr[['churn']].sort_values('churn', ascending=False), annot=True, cmap='coolwarm', cbar=False)\n",
    "plt.title('Correlation with Churn')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"This heatmap displays the correlation of each numerical feature with churn, highlighting predictive features.\")\n",
    "\n",
    "# --- 5. Feature Encoding & Class Imbalance ---\n",
    "print(\"\\n## 5. Feature Encoding & Class Imbalance\")\n",
    "print(\"Summary: Shows the effect of encoding and the class distribution after balancing.\")\n",
    "\n",
    "print(\"\\nEncoded Feature Sample:\")\n",
    "display(X.head(10))\n",
    "print(\"This table shows the first 10 rows of the feature matrix after encoding categorical variables.\")\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "y_train.value_counts().plot(kind='bar', color=['lightblue', 'salmon'])\n",
    "plt.title('Class Distribution (Train Set)')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"This bar chart shows the class distribution in the training set before balancing.\")\n",
    "\n",
    "# Only plot SMOTE distribution if y_train_smote is defined\n",
    "if 'y_train_smote' in locals() and y_train_smote is not None:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    y_train_smote.value_counts().plot(kind='bar', color=['lightgreen', 'orange'])\n",
    "    plt.title('Class Distribution after SMOTE')\n",
    "    plt.xlabel('Churn')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"This bar chart shows the class distribution after applying SMOTE, demonstrating class balancing.\")\n",
    "else:\n",
    "    print(\"SMOTE-balanced training labels (y_train_smote) are not available in this environment.\")\n",
    "    print(\"Skipping SMOTE class distribution plot.\")\n",
    "\n",
    "# --- 6. Baseline Model Performance ---\n",
    "print(\"\\n## 6. Baseline Model Performance\")\n",
    "print(\"Summary: Compares baseline models using original and balanced data.\")\n",
    "\n",
    "print(\"\\nBaseline Model Results:\")\n",
    "display(baseline_results)\n",
    "print(\"This table summarizes the performance of baseline models (e.g., Logistic Regression, kNN, Decision Tree) on the original data.\")\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "baseline_results['F1_Weighted'].plot(kind='bar', color='skyblue')\n",
    "plt.title('Baseline Model F1 Weighted Scores')\n",
    "plt.ylabel('F1 Weighted')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"This bar chart compares the F1 Weighted scores of baseline models, highlighting the best performer.\")\n",
    "\n",
    "# --- 7. SMOTE Model Performance ---\n",
    "print(\"\\n## 7. SMOTE Model Performance\")\n",
    "print(\"Summary: Evaluates models trained on SMOTE-balanced data.\")\n",
    "\n",
    "print(\"\\nSMOTE Model Results:\")\n",
    "display(balanced_results)\n",
    "print(\"This table summarizes the performance of baseline models after SMOTE balancing.\")\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "balanced_results['F1_Weighted'].plot(kind='bar', color='orange')\n",
    "plt.title('SMOTE Model F1 Weighted Scores')\n",
    "plt.ylabel('F1 Weighted')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"This bar chart compares the F1 Weighted scores of models trained on SMOTE-balanced data.\")\n",
    "\n",
    "# --- 8. Feature Importance ---\n",
    "print(\"\\n## 8. Feature Importance\")\n",
    "print(\"Summary: Shows the most important features for the champion model.\")\n",
    "\n",
    "print(\"\\nFeature Importance Table:\")\n",
    "display(feature_importance_df.head(10))\n",
    "print(\"This table lists the top 10 features ranked by importance in the champion model.\")\n",
    "\n",
    "# Defensive check for required columns before plotting\n",
    "if (\n",
    "    isinstance(feature_importance_df, pd.DataFrame)\n",
    "    and 'importance' in feature_importance_df.columns\n",
    "    and 'feature' in feature_importance_df.columns\n",
    "):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.barplot(x='importance', y='feature', data=feature_importance_df.head(10), palette='viridis')\n",
    "    plt.title('Top 10 Feature Importances')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"This bar chart visualizes the top 10 most important features for predicting churn.\")\n",
    "else:\n",
    "    print(\"feature_importance_df does not contain the required columns 'importance' and 'feature'. Skipping feature importance plot.\")\n",
    "\n",
    "# --- 9. Champion Model Leaderboard ---\n",
    "print(\"\\n## 9. Champion Model Leaderboard\")\n",
    "print(\"Summary: Displays the leaderboard of all models evaluated, sorted by Accuracy_1 score (churn=1 prediction accuracy).\")\n",
    "\n",
    "print(\"\\nChampion Model Leaderboard:\")\n",
    "display(churn_leaderboard)\n",
    "print(\"This table ranks all models by Accuracy_1 score, helping identify the best predictor of churn.\")\n",
    "\n",
    "# Defensive check for 'Model' column before plotting\n",
    "if (\n",
    "    isinstance(churn_leaderboard, pd.DataFrame)\n",
    "    and 'Model' in churn_leaderboard.columns\n",
    "    and 'F1_Weighted' in churn_leaderboard.columns\n",
    "):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    churn_leaderboard.head(10).plot(x='Model', y='F1_Weighted', kind='bar', color='gold', legend=False)\n",
    "    plt.title('Top 10 Models by F1 Weighted Score')\n",
    "    plt.ylabel('F1 Weighted')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"This bar chart shows the top 10 models by F1 Weighted score, highlighting the champion model.\")\n",
    "elif (\n",
    "    isinstance(churn_leaderboard, pd.DataFrame)\n",
    "    and churn_leaderboard.index.name == 'Model'\n",
    "    and 'F1_Weighted' in churn_leaderboard.columns\n",
    "):\n",
    "    # If 'Model' is the index, use it for plotting\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    churn_leaderboard.head(10).reset_index().plot(x='Model', y='F1_Weighted', kind='bar', color='gold', legend=False)\n",
    "    plt.title('Top 10 Models by F1 Weighted Score')\n",
    "    plt.ylabel('F1 Weighted')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"This bar chart shows the top 10 models by F1 Weighted score, highlighting the champion model.\")\n",
    "else:\n",
    "    print(\"churn_leaderboard does not contain a 'Model' column or index. Skipping leaderboard plot.\")\n",
    "\n",
    "# --- 10. Advanced Model & Ensemble Performance ---\n",
    "print(\"\\n## 10. Advanced Model & Ensemble Performance\")\n",
    "print(\"Summary: Compares advanced models and ensemble methods for churn prediction.\")\n",
    "\n",
    "print(\"\\nAdvanced Model Results:\")\n",
    "display(advanced_results)\n",
    "print(\"This table summarizes the performance of advanced models (Random Forest, Gradient Boosting, XGBoost) with optimal balancing.\")\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "advanced_results['F1_Weighted'].plot(kind='bar', color='purple')\n",
    "plt.title('Advanced Model F1 Weighted Scores')\n",
    "plt.ylabel('F1 Weighted')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"This bar chart compares the F1 Weighted scores of advanced models.\")\n",
    "\n",
    "# Only display and plot ensemble results if available\n",
    "if 'ensemble_results_df' in locals() and isinstance(ensemble_results_df, pd.DataFrame):\n",
    "    print(\"\\nEnsemble Model Results:\")\n",
    "    display(ensemble_results_df)\n",
    "    print(\"This table summarizes the performance of ensemble models, showing the benefit of combining top performers.\")\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    ensemble_results_df['F1_Weighted'].plot(kind='bar', color='teal')\n",
    "    plt.title('Ensemble Model F1 Weighted Scores')\n",
    "    plt.ylabel('F1 Weighted')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"This bar chart compares the F1 Weighted scores of ensemble models, demonstrating the potential for improved performance.\")\n",
    "else:\n",
    "    print(\"ensemble_results_df is not available in this environment. Skipping ensemble results table and plot.\")\n",
    "\n",
    "# --- END OF SUMMARY ---\n",
    "print(\"\\n--- End of Section & Visualization Summary ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce28646",
   "metadata": {},
   "source": [
    "# 13 Key Takeaways from the Churn Modeling Workflow\n",
    "\n",
    "1. **Choosing Biased Models and Leaders Based on Churn=1 Accuracy:**  \n",
    "   In some experiments, we prioritized models that were biased toward predicting churn (class 1) and selected leaders based on their accuracy in identifying churned customers. The benefit of this approach is that it can maximize the detection of at-risk customers, which is often the primary business goal in churn prevention. However, the risk is that these models may over-predict churn, leading to higher false positive rates and unnecessary retention offers to customers who would not have left. In our experiments, this strategy improved recall for churn but sometimes reduced overall precision and F1 scores, highlighting the trade-off between aggressive churn detection and balanced model performance. The choice of metric and model bias should be aligned with business priorities and the cost of false positives versus false negatives.\n",
    "\n",
    "2. **Data Quality is High:**  \n",
    "   The dataset contains no missing values, allowing for robust analysis without the need for imputation or data cleaning.\n",
    "\n",
    "3. **Churn is Imbalanced:**  \n",
    "   The target variable (churn) is imbalanced, with a significantly higher proportion of non-churned customers. This necessitates the use of balancing techniques for fair model evaluation.\n",
    "\n",
    "4. **Descriptive Statistics Reveal Key Patterns:**  \n",
    "   Numerical and categorical summaries highlight important differences between churned and non-churned customers, guiding feature selection and engineering.\n",
    "\n",
    "5. **Feature Correlation Identifies Predictors:**  \n",
    "   Several features show strong correlation with churn, providing valuable signals for model training and interpretation.\n",
    "\n",
    "6. **Encoding and Preprocessing are Essential:**  \n",
    "   Proper encoding of categorical variables and scaling of numerical features are critical steps that improve model performance and comparability.\n",
    "\n",
    "7. **SMOTE Balancing Improves Minority Class Detection:**  \n",
    "   Applying SMOTE to the training data successfully balances the classes, leading to improved recall and F1 scores for the minority (churn) class.\n",
    "\n",
    "8. **Baseline Models Set a Performance Benchmark:**  \n",
    "   Logistic Regression, kNN, and Decision Tree models provide a baseline for accuracy and F1 scores, highlighting the need for more advanced approaches.\n",
    "\n",
    "9. **Advanced Models Outperform Baselines:**  \n",
    "   Ensemble methods like Random Forest, Gradient Boosting, and XGBoost achieve higher F1 Weighted scores, demonstrating the value of model complexity and nonlinearity.\n",
    "\n",
    "10. **Feature Importance is Actionable:**  \n",
    "    The top features driving churn predictions are interpretable and actionable, enabling targeted business interventions.\n",
    "\n",
    "11. **Champion Model Leaderboard Guides Selection:**  \n",
    "    A comprehensive leaderboard ranks all models by F1 Weighted score, making it easy to identify and deploy the best-performing solution.\n",
    "\n",
    "12. **Ensemble Models Offer Additional Gains:**  \n",
    "    Combining top models in an ensemble further boosts performance and robustness, especially for challenging cases.\n",
    "\n",
    "13. **Business Value is Clear:**  \n",
    "    The workflow provides a transparent, reproducible, and actionable approach to churn prediction, supporting data-driven retention strategies and measurable business impact."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
